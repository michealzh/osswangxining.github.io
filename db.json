{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/images/hdfs1.jpg","path":"images/hdfs1.jpg","modified":1,"renderable":0},{"_id":"source/images/docker-network-perf.jpg","path":"images/docker-network-perf.jpg","modified":1,"renderable":0},{"_id":"source/images/hdfs-read.jpg","path":"images/hdfs-read.jpg","modified":1,"renderable":0},{"_id":"source/images/hdfs-write.jpg","path":"images/hdfs-write.jpg","modified":1,"renderable":0},{"_id":"source/images/slider.png","path":"images/slider.png","modified":1,"renderable":0},{"_id":"source/images/yarn-dev2.png","path":"images/yarn-dev2.png","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/build.gradle","path":"samplecodes/ServiceDiscoveryLoadBalancerSample/build.gradle","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/gradlew","path":"samplecodes/ServiceDiscoveryLoadBalancerSample/gradlew","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/mvnw","path":"samplecodes/ServiceDiscoveryLoadBalancerSample/mvnw","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/pom.xml","path":"samplecodes/ServiceDiscoveryLoadBalancerSample/pom.xml","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/mvnw.cmd","path":"samplecodes/ServiceDiscoveryLoadBalancerSample/mvnw.cmd","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/gradlew.bat","path":"samplecodes/ServiceDiscoveryLoadBalancerSample/gradlew.bat","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/build.gradle","path":"samplecodes/ServiceRegistryConsulDistributedTrace/build.gradle","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/gradlew","path":"samplecodes/ServiceRegistryConsulDistributedTrace/gradlew","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/gradlew.bat","path":"samplecodes/ServiceRegistryConsulDistributedTrace/gradlew.bat","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/mvnw","path":"samplecodes/ServiceRegistryConsulDistributedTrace/mvnw","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/pom.xml","path":"samplecodes/ServiceRegistryConsulDistributedTrace/pom.xml","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/mvnw.cmd","path":"samplecodes/ServiceRegistryConsulDistributedTrace/mvnw.cmd","modified":1,"renderable":0},{"_id":"source/samplecodes/hbaseclient/HBaseSample.java","path":"samplecodes/hbaseclient/HBaseSample.java","modified":1,"renderable":0},{"_id":"source/images/yarn-dev3.png","path":"images/yarn-dev3.png","modified":1,"renderable":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":1,"renderable":1},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/gs-spring-boot-0.1.0.jar.original","path":"samplecodes/ServiceRegistryConsulDistributedTrace/target/gs-spring-boot-0.1.0.jar.original","modified":1,"renderable":0},{"_id":"source/images/yarn-dev1.png","path":"images/yarn-dev1.png","modified":1,"renderable":0},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":1,"renderable":1},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/gradle/wrapper/gradle-wrapper.properties","path":"samplecodes/ServiceDiscoveryLoadBalancerSample/gradle/wrapper/gradle-wrapper.properties","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/gradle/wrapper/gradle-wrapper.jar","path":"samplecodes/ServiceDiscoveryLoadBalancerSample/gradle/wrapper/gradle-wrapper.jar","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/target/classes/application.properties","path":"samplecodes/ServiceDiscoveryLoadBalancerSample/target/classes/application.properties","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/gradle/wrapper/gradle-wrapper.properties","path":"samplecodes/ServiceRegistryConsulDistributedTrace/gradle/wrapper/gradle-wrapper.properties","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/gradle/wrapper/gradle-wrapper.jar","path":"samplecodes/ServiceRegistryConsulDistributedTrace/gradle/wrapper/gradle-wrapper.jar","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/application.properties","path":"samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/application.properties","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/maven-archiver/pom.properties","path":"samplecodes/ServiceRegistryConsulDistributedTrace/target/maven-archiver/pom.properties","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/surefire-reports/hello.HelloControllerTest.txt","path":"samplecodes/ServiceRegistryConsulDistributedTrace/target/surefire-reports/hello.HelloControllerTest.txt","modified":1,"renderable":0},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":1,"renderable":1},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/surefire-reports/TEST-hello.HelloControllerTest.xml","path":"samplecodes/ServiceRegistryConsulDistributedTrace/target/surefire-reports/TEST-hello.HelloControllerTest.xml","modified":1,"renderable":0},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":1,"renderable":1},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/src/main/java/application.properties","path":"samplecodes/ServiceDiscoveryLoadBalancerSample/src/main/java/application.properties","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/target/classes/META-INF/MANIFEST.MF","path":"samplecodes/ServiceDiscoveryLoadBalancerSample/target/classes/META-INF/MANIFEST.MF","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/target/classes/hello/Application.class","path":"samplecodes/ServiceDiscoveryLoadBalancerSample/target/classes/hello/Application.class","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/target/classes/hello/HelloController.class","path":"samplecodes/ServiceDiscoveryLoadBalancerSample/target/classes/hello/HelloController.class","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/target/test-classes/hello/HelloControllerIT.class","path":"samplecodes/ServiceDiscoveryLoadBalancerSample/target/test-classes/hello/HelloControllerIT.class","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/target/classes/hello/SayHelloConfiguration.class","path":"samplecodes/ServiceDiscoveryLoadBalancerSample/target/classes/hello/SayHelloConfiguration.class","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/target/test-classes/hello/HelloControllerTest.class","path":"samplecodes/ServiceDiscoveryLoadBalancerSample/target/test-classes/hello/HelloControllerTest.class","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/src/main/java/application.properties","path":"samplecodes/ServiceRegistryConsulDistributedTrace/src/main/java/application.properties","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/META-INF/MANIFEST.MF","path":"samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/META-INF/MANIFEST.MF","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/hello/Application$1.class","path":"samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/hello/Application$1.class","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/hello/Application.class","path":"samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/hello/Application.class","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/hello/HelloController.class","path":"samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/hello/HelloController.class","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/hello/HystrixController$1.class","path":"samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/hello/HystrixController$1.class","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/hello/HystrixController.class","path":"samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/hello/HystrixController.class","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/hello/SampleBackground.class","path":"samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/hello/SampleBackground.class","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/hello/HomeController.class","path":"samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/hello/HomeController.class","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/hystrix/CommandHelloWorld$1.class","path":"samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/hystrix/CommandHelloWorld$1.class","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/hello/SampleController.class","path":"samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/hello/SampleController.class","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/hello/SampleController$1.class","path":"samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/hello/SampleController$1.class","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/hystrix/CommandHelloWorld.class","path":"samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/hystrix/CommandHelloWorld.class","modified":1,"renderable":0},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/src/test/java/hello/HelloControllerIT.java","path":"samplecodes/ServiceDiscoveryLoadBalancerSample/src/test/java/hello/HelloControllerIT.java","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/src/test/java/hello/HelloControllerTest.java","path":"samplecodes/ServiceDiscoveryLoadBalancerSample/src/test/java/hello/HelloControllerTest.java","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/src/main/java/hello/Application.java","path":"samplecodes/ServiceDiscoveryLoadBalancerSample/src/main/java/hello/Application.java","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/src/main/java/hello/HelloController.java","path":"samplecodes/ServiceDiscoveryLoadBalancerSample/src/main/java/hello/HelloController.java","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/src/main/java/hello/SayHelloConfiguration.java","path":"samplecodes/ServiceDiscoveryLoadBalancerSample/src/main/java/hello/SayHelloConfiguration.java","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/src/main/java/hello/Application.java","path":"samplecodes/ServiceRegistryConsulDistributedTrace/src/main/java/hello/Application.java","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/src/main/java/hello/HelloController.java","path":"samplecodes/ServiceRegistryConsulDistributedTrace/src/main/java/hello/HelloController.java","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/src/main/java/hello/HystrixController.java","path":"samplecodes/ServiceRegistryConsulDistributedTrace/src/main/java/hello/HystrixController.java","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/src/main/java/hello/SampleBackground.java","path":"samplecodes/ServiceRegistryConsulDistributedTrace/src/main/java/hello/SampleBackground.java","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/src/main/java/hello/SampleController.java","path":"samplecodes/ServiceRegistryConsulDistributedTrace/src/main/java/hello/SampleController.java","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/src/main/java/hello/HomeController.java","path":"samplecodes/ServiceRegistryConsulDistributedTrace/src/main/java/hello/HomeController.java","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/src/main/java/hystrix/CommandHelloWorld.java","path":"samplecodes/ServiceRegistryConsulDistributedTrace/src/main/java/hystrix/CommandHelloWorld.java","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/target/maven-status/maven-compiler-plugin/testCompile/default-testCompile/createdFiles.lst","path":"samplecodes/ServiceDiscoveryLoadBalancerSample/target/maven-status/maven-compiler-plugin/testCompile/default-testCompile/createdFiles.lst","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/target/maven-status/maven-compiler-plugin/compile/default-compile/createdFiles.lst","path":"samplecodes/ServiceDiscoveryLoadBalancerSample/target/maven-status/maven-compiler-plugin/compile/default-compile/createdFiles.lst","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/maven-status/maven-compiler-plugin/testCompile/default-testCompile/createdFiles.lst","path":"samplecodes/ServiceRegistryConsulDistributedTrace/target/maven-status/maven-compiler-plugin/testCompile/default-testCompile/createdFiles.lst","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/maven-status/maven-compiler-plugin/compile/default-compile/createdFiles.lst","path":"samplecodes/ServiceRegistryConsulDistributedTrace/target/maven-status/maven-compiler-plugin/compile/default-compile/createdFiles.lst","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/maven-status/maven-compiler-plugin/testCompile/default-testCompile/inputFiles.lst","path":"samplecodes/ServiceRegistryConsulDistributedTrace/target/maven-status/maven-compiler-plugin/testCompile/default-testCompile/inputFiles.lst","modified":1,"renderable":0},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":1,"renderable":1},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/target/maven-status/maven-compiler-plugin/testCompile/default-testCompile/inputFiles.lst","path":"samplecodes/ServiceDiscoveryLoadBalancerSample/target/maven-status/maven-compiler-plugin/testCompile/default-testCompile/inputFiles.lst","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/target/maven-status/maven-compiler-plugin/compile/default-compile/inputFiles.lst","path":"samplecodes/ServiceDiscoveryLoadBalancerSample/target/maven-status/maven-compiler-plugin/compile/default-compile/inputFiles.lst","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/maven-status/maven-compiler-plugin/compile/default-compile/inputFiles.lst","path":"samplecodes/ServiceRegistryConsulDistributedTrace/target/maven-status/maven-compiler-plugin/compile/default-compile/inputFiles.lst","modified":1,"renderable":0},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":1,"renderable":1},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/target/classes/com/netflix/client/http/HttpResponse.class","path":"samplecodes/ServiceDiscoveryLoadBalancerSample/target/classes/com/netflix/client/http/HttpResponse.class","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/target/classes/META-INF/maven/org.springframework/gs-spring-boot/pom.properties","path":"samplecodes/ServiceDiscoveryLoadBalancerSample/target/classes/META-INF/maven/org.springframework/gs-spring-boot/pom.properties","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/target/classes/META-INF/maven/org.springframework/gs-spring-boot/pom.xml","path":"samplecodes/ServiceDiscoveryLoadBalancerSample/target/classes/META-INF/maven/org.springframework/gs-spring-boot/pom.xml","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/META-INF/maven/org.springframework/gs-spring-boot/pom.properties","path":"samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/META-INF/maven/org.springframework/gs-spring-boot/pom.properties","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/META-INF/maven/org.springframework/gs-spring-boot/pom.xml","path":"samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/META-INF/maven/org.springframework/gs-spring-boot/pom.xml","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/src/main/java/com/netflix/client/http/HttpResponse.java","path":"samplecodes/ServiceDiscoveryLoadBalancerSample/src/main/java/com/netflix/client/http/HttpResponse.java","modified":1,"renderable":0},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/gs-spring-boot-0.1.0.jar","path":"samplecodes/ServiceRegistryConsulDistributedTrace/target/gs-spring-boot-0.1.0.jar","modified":1,"renderable":0}],"Cache":[{"_id":"source/.DS_Store","hash":"023ca5f96010068a6d88e5ac0f2ac47a5fa364e2","modified":1494236706000},{"_id":"themes/next/.DS_Store","hash":"7b7e696bc43ee40d5d5228b7b81bb9c5434ec88b","modified":1494227821000},{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1490291568000},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1490291568000},{"_id":"themes/next/.gitignore","hash":"5f09fca02e030b7676c1d312cd88ce8fbccf381c","modified":1490291568000},{"_id":"themes/next/.hound.yml","hash":"b76daa84c9ca3ad292c78412603370a367cc2bc3","modified":1490291568000},{"_id":"themes/next/.gitattributes","hash":"44bd4729c74ccb88110804f41746fec07bf487d4","modified":1490291568000},{"_id":"themes/next/.javascript_ignore","hash":"f9ea3c5395f8feb225a24e2c32baa79afda30c16","modified":1490291568000},{"_id":"themes/next/LICENSE","hash":"f293bcfcdc06c0b77ba13570bb8af55eb5c059fd","modified":1490291568000},{"_id":"themes/next/README.en.md","hash":"4ece25ee5f64447cd522e54cb0fffd9a375f0bd4","modified":1490291568000},{"_id":"themes/next/.jshintrc","hash":"9928f81bd822f6a8d67fdbc909b517178533bca9","modified":1490291568000},{"_id":"themes/next/.stylintrc","hash":"b28e24704a5d8de08346c45286574c8e76cc109f","modified":1490291568000},{"_id":"themes/next/.travis.yml","hash":"c42d9608c8c7fe90de7b1581a8dc3886e90c179e","modified":1490291568000},{"_id":"themes/next/bower.json","hash":"5abc236d9cc2512f5457ed57c1fba76669eb7399","modified":1490291568000},{"_id":"themes/next/README.md","hash":"500b5606eb6a09c979d16128f8b00f4bf9bc95ac","modified":1490291568000},{"_id":"themes/next/_config.yml","hash":"1c968a94862f9c739e5d38b839f1c632dca79a4a","modified":1494253468000},{"_id":"themes/next/gulpfile.coffee","hash":"031bffc483e417b20e90eceb6cf358e7596d2e69","modified":1490291568000},{"_id":"themes/next/package.json","hash":"7e87b2621104b39a30488654c2a8a0c6a563574b","modified":1490291568000},{"_id":"source/_posts/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1494236560000},{"_id":"source/_posts/README.md","hash":"a2e52cf2e2a213a4bf4f4dacc449368e6c70bd5a","modified":1494252560000},{"_id":"source/_posts/consul.md","hash":"4de2a315da3b283faa3c97284a20dbc3bfde4d9c","modified":1494250273000},{"_id":"source/_posts/Hystrix.md","hash":"8aaf6f1ddf4a83a57ea8abcca9ff07169413c16e","modified":1494250305000},{"_id":"source/_posts/gateway.md","hash":"c66cfc2df0c15acc4402cd316c707fbbc8c52137","modified":1494250279000},{"_id":"source/_posts/kafka.md","hash":"90071b6ddae3259ef63ae702901e83dc65b280cd","modified":1494250314000},{"_id":"source/_posts/hbase.md","hash":"8b28e77b4d5995fbbe407a6862d6adb63fea6453","modified":1494250286000},{"_id":"source/_posts/hdfs.md","hash":"5a1a11709620abc408d31865d2f4f3d373a253fd","modified":1494250294000},{"_id":"source/_posts/mongo.md","hash":"522f802eb45206aa5e226b085a561ca21965edb8","modified":1494250322000},{"_id":"source/_posts/kubernetes.md","hash":"a3c4573f74972bdc462d773296a4b3e059afbf36","modified":1494250143000},{"_id":"source/_posts/redis.md","hash":"21093770601e7cce0328b387408a2187001229f3","modified":1494250327000},{"_id":"source/_posts/running-spark-on-yarn.md","hash":"1bdc2583e80ac669d1e9758a4ab743aede827d8e","modified":1494250341000},{"_id":"source/_posts/spark.md","hash":"5719890ef66f986b2a8362e78d319fe14c223155","modified":1494250363000},{"_id":"source/_posts/sgg.md","hash":"b26355a8db948a5a75c78c5e1769170f6003376e","modified":1494250356000},{"_id":"source/_posts/yarn-appdev.md","hash":"160e95156c6a47b8c007d2de30d6fd418a4ac7c9","modified":1494250374000},{"_id":"source/_posts/yarn.md","hash":"f9544c727b547e796a4128ce9a58c3ae11c61811","modified":1494250386000},{"_id":"source/categories/index.md","hash":"e80c28979398a0be7415c6607a424b7417e734c3","modified":1494253048000},{"_id":"source/_posts/zipkin.md","hash":"15d7ad5213c04ef4bee967cd3526a2eab90034f5","modified":1494250421000},{"_id":"source/about/index.md","hash":"735eeeffd5ae3eff4f6240842336a3b2bd71e7b6","modified":1494251953000},{"_id":"source/images/hdfs1.jpg","hash":"d381fbecb914a7785b6ef74d7d8ee23e41ace452","modified":1490536361000},{"_id":"source/samplecodes/.DS_Store","hash":"f289bd0c554f09dd7ea7e1d804f2997973f512ee","modified":1494236671000},{"_id":"source/tags/index.md","hash":"ec13ad4f972e0e9bc811b0a15d0384911c264644","modified":1494253033000},{"_id":"source/images/docker-network-perf.jpg","hash":"dcc351005d9bbeea021b010681f1247895e43c5e","modified":1492765905000},{"_id":"source/images/hdfs-read.jpg","hash":"d0b0511f74f19adf21de3bbd0532e649069b7b1c","modified":1490537493000},{"_id":"source/images/hdfs-write.jpg","hash":"0482dc43f508920abb89fb9113ac6d11bfd9c717","modified":1490537413000},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"fdd63b77472612337309eb93ec415a059b90756b","modified":1490291568000},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"3b5eafd32abb718e56ccf8d1cee0607ad8ce611d","modified":1490291568000},{"_id":"source/images/slider.png","hash":"9ba5c6fa28b8cd21cdb22fd45641009922b3e13d","modified":1490793826000},{"_id":"source/images/yarn-dev2.png","hash":"38bd74730eebb3ec9461c1e87c86368d569ad701","modified":1490868886000},{"_id":"themes/next/languages/de.yml","hash":"306db8c865630f32c6b6260ade9d3209fbec8011","modified":1490291568000},{"_id":"themes/next/languages/fr-FR.yml","hash":"24180322c83587a153cea110e74e96eacc3355ad","modified":1490291568000},{"_id":"themes/next/languages/default.yml","hash":"4cc6aeb1ac09a58330e494c8771773758ab354af","modified":1490291568000},{"_id":"themes/next/languages/en.yml","hash":"e7def07a709ef55684490b700a06998c67f35f39","modified":1490291568000},{"_id":"themes/next/languages/id.yml","hash":"2835ea80dadf093fcf47edd957680973f1fb6b85","modified":1490291568000},{"_id":"themes/next/languages/ko.yml","hash":"be150543379150f78329815af427bf152c0e9431","modified":1490291568000},{"_id":"themes/next/languages/ja.yml","hash":"1c3a05ab80a6f8be63268b66da6f19da7aa2c638","modified":1490291568000},{"_id":"themes/next/languages/pt-BR.yml","hash":"958e49571818a34fdf4af3232a07a024050f8f4e","modified":1490291568000},{"_id":"themes/next/languages/pt.yml","hash":"36c8f60dacbe5d27d84d0e0d6974d7679f928da0","modified":1490291568000},{"_id":"themes/next/languages/ru.yml","hash":"7462c3017dae88e5f80ff308db0b95baf960c83f","modified":1490291568000},{"_id":"themes/next/languages/zh-Hans.yml","hash":"3c0c7dfd0256457ee24df9e9879226c58cb084b5","modified":1490291568000},{"_id":"themes/next/languages/zh-hk.yml","hash":"1c917997413bf566cb79e0975789f3c9c9128ccd","modified":1490291568000},{"_id":"themes/next/languages/zh-tw.yml","hash":"0b2c18aa76570364003c8d1cd429fa158ae89022","modified":1490291568000},{"_id":"themes/next/layout/archive.swig","hash":"b5b59d70fc1563f482fa07afd435752774ad5981","modified":1490291568000},{"_id":"themes/next/layout/category.swig","hash":"6422d196ceaff4220d54b8af770e7e957f3364ad","modified":1490291568000},{"_id":"themes/next/layout/index.swig","hash":"427d0b95b854e311ae363088ab39a393bf8fdc8b","modified":1490291568000},{"_id":"themes/next/layout/_layout.swig","hash":"909d68b164227fe7601d82e2303bf574eb754172","modified":1490291568000},{"_id":"themes/next/layout/post.swig","hash":"e2e512142961ddfe77eba29eaa88f4a2ee43ae18","modified":1490291568000},{"_id":"themes/next/scripts/merge-configs.js","hash":"13c8b3a2d9fce06c2488820d9248d190c8100e0a","modified":1490291568000},{"_id":"themes/next/layout/page.swig","hash":"3727fab9dadb967e9c2204edca787dc72264674a","modified":1490291568000},{"_id":"themes/next/scripts/merge.js","hash":"9130dabe6a674c54b535f322b17d75fe6081472f","modified":1490291568000},{"_id":"themes/next/layout/schedule.swig","hash":"234dc8c3b9e276e7811c69011efd5d560519ef19","modified":1490291568000},{"_id":"themes/next/layout/tag.swig","hash":"07cf49c49c39a14dfbe9ce8e7d7eea3d4d0a4911","modified":1490291568000},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1490291568000},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1490291568000},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1490291568000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/.classpath","hash":"82ef1892b55f32506a74f8266cc69f5c0c3f275a","modified":1488361281000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/.gitignore","hash":"deca8b979c4147a1d8af858e15b32fb47ae0ef8d","modified":1488984167000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/.project","hash":"f3d185523bb9e5669cdf640223781fa0d892817d","modified":1488629400000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/build.gradle","hash":"03952c793a85387ba0fa1042694fad98d1a98d72","modified":1488361264000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/gradlew","hash":"6409d6256df6b2f9e2142183b4c6408823a10f6a","modified":1488361264000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/mvnw","hash":"dc153403a872c675192ab8e5eb7d2fa472cdf54f","modified":1488361264000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/pom.xml","hash":"31e8378ff4c448f1102508a2db5a7afeb7bd8e19","modified":1488618933000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/mvnw.cmd","hash":"385dfa8b0d6db3e26e0fec1ffd5078051d1ebbbd","modified":1488361264000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/gradlew.bat","hash":"8751d7831ca6cd1cad48e1475a79596b54b48994","modified":1488361264000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/.classpath","hash":"82ef1892b55f32506a74f8266cc69f5c0c3f275a","modified":1488361281000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/.gitignore","hash":"deca8b979c4147a1d8af858e15b32fb47ae0ef8d","modified":1488984206000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/.project","hash":"48b8531d7ce3d57d49515dada462d33095e84c90","modified":1488640926000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/build.gradle","hash":"03952c793a85387ba0fa1042694fad98d1a98d72","modified":1488361264000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/gradlew","hash":"6409d6256df6b2f9e2142183b4c6408823a10f6a","modified":1488361264000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/gradlew.bat","hash":"8751d7831ca6cd1cad48e1475a79596b54b48994","modified":1488361264000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/mvnw","hash":"dc153403a872c675192ab8e5eb7d2fa472cdf54f","modified":1488361264000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/pom.xml","hash":"3783f66dacd688adef5a07c8637994d77f8a2fb9","modified":1488786250000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/mvnw.cmd","hash":"385dfa8b0d6db3e26e0fec1ffd5078051d1ebbbd","modified":1488361264000},{"_id":"source/samplecodes/hbaseclient/HBaseSample.java","hash":"a82bd074443770aac9f7a3e7424cf5c40b9751e0","modified":1493802089000},{"_id":"source/images/yarn-dev3.png","hash":"8005b57f7661cf4b5b745e7dbb82f460557fa6a8","modified":1490872493000},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1490291568000},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1490291568000},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1490291568000},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"5864f5567ba5efeabcf6ea355013c0b603ee07f2","modified":1490291568000},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"b16fcbf0efd20c018d7545257a8533c497ea7647","modified":1490291568000},{"_id":"themes/next/layout/_macro/post.swig","hash":"640b431eccbbd27f10c6781f33db5ea9a6e064de","modified":1490291568000},{"_id":"themes/next/layout/_macro/reward.swig","hash":"37e5b7c42ec17b9b6b786c5512bcc481a21c974e","modified":1490291568000},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"911b99ba0445b2c07373128d87a4ef2eb7de341a","modified":1490291568000},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"14e785adeb0e671ba0ff9a553e6f0d8def6c670c","modified":1490291568000},{"_id":"themes/next/layout/_partials/footer.swig","hash":"7172c6053118b7c291a56a7860128a652ae66b83","modified":1490291568000},{"_id":"themes/next/layout/_partials/comments.swig","hash":"1c7d3c975e499b9aa3119d6724b030b7b00fc87e","modified":1490291568000},{"_id":"themes/next/layout/_partials/header.swig","hash":"a1ffbb691dfad3eaf2832a11766e58a179003b8b","modified":1490291568000},{"_id":"themes/next/layout/_partials/head.swig","hash":"a0eafe24d1dae30c790ae35612154b3ffbbd5cce","modified":1490291568000},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1490291568000},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"1efd925d34a5d4ba2dc0838d9c86ba911e705fc9","modified":1490291568000},{"_id":"themes/next/layout/_partials/search.swig","hash":"9dbd378e94abfcb3f864a5b8dbbf18d212ca2ee0","modified":1490291568000},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1490291568000},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"7c04a42319d728be356746363aff8ea247791d24","modified":1490291568000},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1490291568000},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1490291568000},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1490291568000},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1490291568000},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"9de352a32865869e7ed6863db271c46db5853e5a","modified":1490291568000},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1490291568000},{"_id":"themes/next/scripts/tags/button.js","hash":"62e6dbeb53d07627a048132c79630b45d9a8f2cc","modified":1490291568000},{"_id":"themes/next/scripts/tags/exturl.js","hash":"8d7e60f60779bde050d20fd76f6fdc36fc85e06d","modified":1490291568000},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1490291568000},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1490291568000},{"_id":"themes/next/scripts/tags/note.js","hash":"6752925eedbdb939d8ec4d11bdfb75199f18dd70","modified":1490291568000},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1490291568000},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1490291568000},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"90035272fa31a3f65b3c0e2cb8a633876ef457dc","modified":1490291568000},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1490291568000},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1490291568000},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1490291568000},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1490291568000},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1490291568000},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1490291568000},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1490291568000},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1490291568000},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1490291568000},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1490291568000},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1490291568000},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1490291568000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/.settings/org.eclipse.core.resources.prefs","hash":"200185d1276e5d2c34857dc1d3e5b014ac0389be","modified":1488361281000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/.settings/org.eclipse.jdt.core.prefs","hash":"e1d8a5e5b0495ab00929407c30e150aa3b5949e5","modified":1488361281000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/.settings/org.eclipse.wst.common.project.facet.core.xml","hash":"632c8b8d948358902f748deceee787111310afde","modified":1488361281000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/.settings/org.eclipse.m2e.core.prefs","hash":"fdc827aee8edc9b9a55077f16f0811b7a13d3c8e","modified":1488361264000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/.settings/org.eclipse.core.resources.prefs","hash":"200185d1276e5d2c34857dc1d3e5b014ac0389be","modified":1488361281000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/.settings/org.eclipse.jdt.core.prefs","hash":"e1d8a5e5b0495ab00929407c30e150aa3b5949e5","modified":1488361281000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/.settings/org.eclipse.wst.common.project.facet.core.xml","hash":"632c8b8d948358902f748deceee787111310afde","modified":1488361281000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/.settings/org.eclipse.m2e.core.prefs","hash":"fdc827aee8edc9b9a55077f16f0811b7a13d3c8e","modified":1488361264000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/gs-spring-boot-0.1.0.jar.original","hash":"2a7619c2216392a0a3a3cb5fe2f8a69e194f4a1f","modified":1488642778000},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1490291568000},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1490291568000},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1490291568000},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1490291568000},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1490291568000},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1490291568000},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1490291568000},{"_id":"source/images/yarn-dev1.png","hash":"fdbeac79b3d99c307f8f53886e156449799ae0af","modified":1490867146000},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1490291568000},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1490291568000},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"2d1075f4cabcb3956b7b84a8e210f5a66f0a5562","modified":1490291568000},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1490291568000},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1490291568000},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1490291568000},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1490291568000},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1490291568000},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1490291568000},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"63315fcf210799f894208c9f512737096df84962","modified":1490291568000},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"18e7bef8923d83ea42df6c97405e515a876cede4","modified":1490291568000},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1490291568000},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"394d008e5e94575280407ad8a1607a028026cbc3","modified":1490291568000},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"deda6a814ed48debc694c4e0c466f06c127163d0","modified":1490291568000},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"5d9943d74cc2e0a91badcf4f755c6de77eab193a","modified":1490291568000},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"3358d11b9a26185a2d36c96049e4340e701646e4","modified":1490291568000},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1490291568000},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"a652f202bd5b30c648c228ab8f0e997eb4928e44","modified":1490291568000},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"92dc60821307fc9769bea9b2d60adaeb798342af","modified":1490291568000},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"c3971fd154d781088e1cc665035f8561a4098f4c","modified":1490291568000},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"0e3378f7c39b2b0f69638290873ede6b6b6825c0","modified":1490291568000},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"c316758546dc9ba6c60cb4d852c17ca6bb6d6724","modified":1490291568000},{"_id":"themes/next/layout/_third-party/comments/gentie.swig","hash":"03592d1d731592103a41ebb87437fe4b0a4c78ca","modified":1490291568000},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1490291568000},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"abb92620197a16ed2c0775edf18a0f044a82256e","modified":1490291568000},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"7240f2e5ec7115f8abbbc4c9ef73d4bed180fdc7","modified":1490291568000},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1490291568000},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"af9dd8a4aed7d06cf47b363eebff48850888566c","modified":1490291568000},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"c747fb5c6b1f500e8f0c583e44195878b66e4e29","modified":1490291568000},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"f4dbd4c896e6510ded8ebe05394c28f8a86e71bf","modified":1490291568000},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1490291568000},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1490291568000},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1490291568000},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1490291568000},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1490291568000},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"715d5b40dc52f319fe4bff0325beb874774d9bd9","modified":1490291568000},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"78a83c38f69a8747bb74e420e6c9eeef1ea76525","modified":1490291568000},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"06f432f328a5b8a9ef0dbd5301b002aba600b4ce","modified":1490291568000},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"c8d35a6b9e3bff6d8fdb66de853065af9d37562d","modified":1490291568000},{"_id":"themes/next/source/css/_variables/base.styl","hash":"28a7f84242ca816a6452a0a79669ca963d824607","modified":1490291568000},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"aab7be0a6e2724b3faa9338db93c19556c559625","modified":1490291568000},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1490291568000},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1490291568000},{"_id":"themes/next/source/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1490291568000},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1490291568000},{"_id":"themes/next/source/js/src/motion.js","hash":"269414e84df544a4ccb88519f6abae4943db3c67","modified":1490291568000},{"_id":"themes/next/source/js/src/post-details.js","hash":"af7a417dd1cb02465a7b98211653e7c6192e6d55","modified":1490291568000},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1490291568000},{"_id":"themes/next/source/js/src/utils.js","hash":"e13c9ccf70d593bdf3b8cc1d768f595abd610e6e","modified":1490291568000},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1490291568000},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1490291568000},{"_id":"themes/next/source/lib/fancybox/.gitattributes","hash":"2db21acfbd457452462f71cc4048a943ee61b8e0","modified":1490291568000},{"_id":"themes/next/source/lib/fancybox/.bower.json","hash":"cc40a9b11e52348e554c84e4a5c058056f6b7aeb","modified":1490291568000},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1490291568000},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1490291568000},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1490291568000},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1490291568000},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1490291568000},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1490291568000},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1490291568000},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1490291568000},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1490291568000},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1490291568000},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1490291568000},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1490291568000},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1490291568000},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1490291568000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1490291568000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1490291568000},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"5b38ae00297ffc07f433c632c3dbf7bde4cdf39a","modified":1490291568000},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1490291568000},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1490291568000},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1490291568000},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1490291568000},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1490291568000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/.mvn/wrapper/maven-wrapper.jar","hash":"7bad9d340cf3f615bf4c6125ddc3adf7ddfa8c62","modified":1488361264000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/.mvn/wrapper/maven-wrapper.properties","hash":"5a2bee75d4d2d934a799fdfb0e3ee87dc842ef4f","modified":1488361264000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/gradle/wrapper/gradle-wrapper.properties","hash":"da7a40ec47afa7b379847a640f34498a5963c021","modified":1488361264000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/gradle/wrapper/gradle-wrapper.jar","hash":"d5f2cff8bfce6bd848ee3dceb06393502f78ca7c","modified":1488361264000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/target/classes/application.properties","hash":"d39c4c518fc727c3204f5b4af0c2052c84cc372d","modified":1488633045000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/target/classes/application.yml","hash":"0e5b90c0d0d5af42280774d5fe2134fd5ce72d91","modified":1488633029000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/.mvn/wrapper/maven-wrapper.properties","hash":"5a2bee75d4d2d934a799fdfb0e3ee87dc842ef4f","modified":1488361264000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/gradle/wrapper/gradle-wrapper.properties","hash":"da7a40ec47afa7b379847a640f34498a5963c021","modified":1488361264000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/.mvn/wrapper/maven-wrapper.jar","hash":"7bad9d340cf3f615bf4c6125ddc3adf7ddfa8c62","modified":1488361264000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/gradle/wrapper/gradle-wrapper.jar","hash":"d5f2cff8bfce6bd848ee3dceb06393502f78ca7c","modified":1488361264000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/application.properties","hash":"58ab3507069966ad6e1dfb16e0e90bad38ca93a8","modified":1488983529000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/maven-archiver/pom.properties","hash":"97cc625c20dbe6c32a1a0b36f4d5495bce425f1f","modified":1488642778000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/surefire-reports/hello.HelloControllerTest.txt","hash":"5eaa2dc12d314452c54ca418d5248addb86c8413","modified":1488642744000},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1490291568000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/surefire-reports/TEST-hello.HelloControllerTest.xml","hash":"09f94b22c9caa95d1191b0b64c233a72229f1cbf","modified":1488642744000},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1490291568000},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"ba698f49dd3a868c95b240d802f5b1b24ff287e4","modified":1490291568000},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"2186be20e317505cd31886f1291429cc21f76703","modified":1490291568000},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"7804e31c44717c9a9ddf0f8482b9b9c1a0f74538","modified":1490291568000},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"9c25c75311e1bd4d68df031d3f2ae6d141a90766","modified":1490291568000},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1490291568000},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"013619c472c7e4b08311c464fcbe9fcf5edde603","modified":1490291568000},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"ef089a407c90e58eca10c49bc47ec978f96e03ba","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"59ad08bcc6fe9793594869ac2b4c525021453e78","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"0dfb4b3ba3180d7285e66f270e1d3fa0f132c3d2","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"a6bb5256be6195e76addbda12f4ed7c662d65e7a","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"711c8830886619d4f4a0598b0cde5499dce50c62","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1490291568000},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1490291568000},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"82bbaa6322764779a1ac2e2c8390ce901c7972e2","modified":1490291568000},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1490291568000},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1490291568000},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1490291568000},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1490291568000},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1490291568000},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1490291568000},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1490291568000},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"fda14bc35be2e1b332809b55b3d07155a833dbf4","modified":1490291568000},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1490291568000},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1490291568000},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"c4ed249798296f60bda02351fe6404fb3ef2126f","modified":1490291568000},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"215de948be49bcf14f06d500cef9f7035e406a43","modified":1490291568000},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"1eb34b9c1f6d541605ff23333eeb133e1c4daf17","modified":1490291568000},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1490291568000},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"e3e23751d4ad24e8714b425d768cf68e37de7ded","modified":1490291568000},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"69ecd6c97e7cdfd822ac8102b45ad0ede85050db","modified":1490291568000},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"79da92119bc246fe05d1626ac98426a83ec90a94","modified":1490291568000},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1490291568000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1490291568000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1490291568000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1490291568000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1490291568000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1490291568000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1490291568000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1490291568000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1490291568000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1490291568000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1490291568000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1490291568000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1490291568000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1490291568000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1490291568000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1490291568000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/src/main/java/application.properties","hash":"d39c4c518fc727c3204f5b4af0c2052c84cc372d","modified":1488633045000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/src/main/java/application.yml","hash":"0e5b90c0d0d5af42280774d5fe2134fd5ce72d91","modified":1488633029000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/target/classes/META-INF/MANIFEST.MF","hash":"003fdcf3d4b181a73be0b14b65008bb758cd33f0","modified":1493024455000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/target/classes/META-INF/additional-spring-configuration-metadata.json","hash":"93f91030ff286a6d0ee05797fe7537d697b5b626","modified":1488633038000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/target/classes/hello/Application.class","hash":"3ef9d7ae48139349aeff37b7a1debff5374fa968","modified":1493024453000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/target/classes/hello/HelloController.class","hash":"4564cd80ccb185103fb12dc454ab49b51358baaa","modified":1493024453000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/target/test-classes/hello/HelloControllerIT.class","hash":"46de139e76abc742b6d33f96fcfee432f71448cc","modified":1493024453000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/target/classes/hello/SayHelloConfiguration.class","hash":"76ef5018599bd2f04430b424c157de9ac31f4aeb","modified":1493024453000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/target/test-classes/hello/HelloControllerTest.class","hash":"970f65ee3a42ab78b07d892807f5dcd302374522","modified":1493024453000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/src/main/java/application.properties","hash":"58ab3507069966ad6e1dfb16e0e90bad38ca93a8","modified":1488983529000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/META-INF/MANIFEST.MF","hash":"003fdcf3d4b181a73be0b14b65008bb758cd33f0","modified":1493024456000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/hello/Application$1.class","hash":"a21c55923caeed353b720026efdfb160e4c0521b","modified":1493024455000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/hello/Application.class","hash":"2079d5dac2e6b6fd4ad69da3e83c761ee90a633e","modified":1493024455000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/hello/HelloController.class","hash":"446b67307f0cd55ac9bb993d89a9db830380694a","modified":1493024455000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/hello/HystrixController$1.class","hash":"55812cca915ebd7001355ba3297c660284360d5f","modified":1493024455000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/hello/HystrixController.class","hash":"d064e2a1daafb600d3b9c420960576c6c4023fd7","modified":1493024455000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/hello/SampleBackground.class","hash":"66ee5a734b67cf985590f4b5901c4252853ddfcf","modified":1493024455000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/hello/HomeController.class","hash":"027f77c5f843d67cff78f56d4059fea74dd77c6f","modified":1493024455000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/hystrix/CommandHelloWorld$1.class","hash":"bdc4fd71fc7fb824880c72c0e9e2ff38cabca408","modified":1493024455000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/hello/SampleController.class","hash":"a064378586960c458f3a25e6800795d68994f8f7","modified":1493024455000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/hello/SampleController$1.class","hash":"e6b24addbb9cfbfa91f5af24a1c3552f84fbbf26","modified":1493024455000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/hystrix/CommandHelloWorld.class","hash":"7c353b7bf0945d26341249d5c6cf7781497a98f1","modified":1493024455000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1490291568000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1490291568000},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"8994ffcce84deac0471532f270f97c44fea54dc0","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"8a2421cb9005352905fae9d41a847ae56957247e","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"755b04edbbfbdd981a783edb09c9cc34cb79cea7","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"7778920dd105fa4de3a7ab206eeba30b1a7bac45","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"8fae54591877a73dff0b29b2be2e8935e3c63575","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"f54367c0feda6986c030cc4d15a0ca6ceea14bcb","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"beccb53dcd658136fb91a0c5678dea8f37d6e0b6","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"b25132fe6a7ad67059a2c3afc60feabb479bdd75","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"a5d8617a24d7cb6c5ad91ea621183ca2c0917331","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"b9a2e76f019a5941191f1263b54aef7b69c48789","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"e792c8dc41561c96d128e9b421187f1c3dc978a0","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"963105a531403d7aad6d9e5e23e3bfabb8ec065a","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"2e7ec9aaa3293941106b1bdd09055246aa3c3dc6","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"8c0276883398651336853d5ec0e9da267a00dd86","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"5f6ea57aabfa30a437059bf8352f1ad829dbd4ff","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"7690b9596ec3a49befbe529a5a2649abec0faf76","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"a2ec22ef4a6817bbb2abe8660fcd99fe4ca0cc5e","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"234facd038f144bd0fe09a31ed1357c5d74c517f","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"1b3cc9f4e5a7f6e05b4100e9990b37b20d4a2005","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"b8969e1654eec89a0fd10d88b337fee9cb03cd44","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"74d0ba86f698165d13402670382a822c8736a556","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"dd310c2d999185e881db007360176ee2f811df10","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"fd42777b9125fd8969dc39d4f15473e2b91b4142","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/third-party/gentie.styl","hash":"586a3ec0f1015e7207cd6a2474362e068c341744","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"d4e6d8d7b34dc69994593c208f875ae8f7e8a3ae","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"42348219db93a85d2ee23cb06cebd4d8ab121726","modified":1490291568000},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1490291568000},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"173490e21bece35a34858e8e534cf86e34561350","modified":1490291568000},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1490291568000},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1490291568000},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1490291568000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1490291568000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1490291568000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1490291568000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1490291568000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1490291568000},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1490291568000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1490291568000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1490291568000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/src/main/java/META-INF/additional-spring-configuration-metadata.json","hash":"93f91030ff286a6d0ee05797fe7537d697b5b626","modified":1488633038000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/src/test/java/hello/HelloControllerIT.java","hash":"2dd5e0100a223911441ef68be6d7f7a9d311a141","modified":1488361264000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/src/test/java/hello/HelloControllerTest.java","hash":"b41dfe898d427ea7023da52c94d3ef3631f23e59","modified":1488361264000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/src/main/java/hello/Application.java","hash":"1d90950b3b75cdb9d7de623d414c55c5355d3243","modified":1488632609000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/src/main/java/hello/HelloController.java","hash":"2359b4ff00a161b7ea7e7962f8de667123cfc29f","modified":1488633602000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/src/main/java/hello/SayHelloConfiguration.java","hash":"112803c240bcaf74efdcbdb84559bd7c5ca2cecc","modified":1488633277000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/src/main/java/hello/Application.java","hash":"0d64abfb605cc3dd6588a2d6556f65af5098da8b","modified":1488879053000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/src/main/java/hello/HelloController.java","hash":"6aff8151be6e43c0cbe449fbd5e19e8533ad9e00","modified":1488641070000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/src/main/java/hello/HystrixController.java","hash":"ccbd7212d455ffbe0f65e61d7aab0d75414d28b9","modified":1488881441000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/src/main/java/hello/SampleBackground.java","hash":"6dbef45799032627487d6a3978d956e387577f7f","modified":1488645053000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/src/main/java/hello/SampleController.java","hash":"c57e518ba99b9dc4d87f903ec01853d65dc3923a","modified":1488645724000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/src/main/java/hello/HomeController.java","hash":"03d68150f5240ea0e49e3455d747c1dfbb640655","modified":1488728401000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/src/main/java/hystrix/CommandHelloWorld.java","hash":"aa2cd43624588007222dc286e2185ca06eb996b5","modified":1488879080000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/target/maven-status/maven-compiler-plugin/testCompile/default-testCompile/createdFiles.lst","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1488618938000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/target/maven-status/maven-compiler-plugin/compile/default-compile/createdFiles.lst","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1488618872000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/maven-status/maven-compiler-plugin/testCompile/default-testCompile/createdFiles.lst","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1488642777000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/maven-status/maven-compiler-plugin/compile/default-compile/createdFiles.lst","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1488645583000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/maven-status/maven-compiler-plugin/testCompile/default-testCompile/inputFiles.lst","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1488646043000},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1490291568000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/target/maven-status/maven-compiler-plugin/testCompile/default-testCompile/inputFiles.lst","hash":"cc7190c8429f9aff8bcf103081c69cf3132eb44d","modified":1488629217000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/target/maven-status/maven-compiler-plugin/compile/default-compile/inputFiles.lst","hash":"a05c96347f70a4e889b77e4805bd0ddc6037720b","modified":1488629217000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/maven-status/maven-compiler-plugin/compile/default-compile/inputFiles.lst","hash":"81a935ef6ab71f364f2158f821a32d85e163b3d3","modified":1488646043000},{"_id":"themes/next/source/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1490291568000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1490291568000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/target/classes/com/netflix/client/http/HttpResponse.class","hash":"59b820efc55c0a4181d65e9c9037ce25ff28e2e2","modified":1493024453000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/target/classes/META-INF/maven/org.springframework/gs-spring-boot/pom.properties","hash":"e4a189d71f8d6c282d15fcd8cd36e5bb7a907159","modified":1493024455000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/target/classes/META-INF/maven/org.springframework/gs-spring-boot/pom.xml","hash":"31e8378ff4c448f1102508a2db5a7afeb7bd8e19","modified":1493024455000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/META-INF/maven/org.springframework/gs-spring-boot/pom.properties","hash":"15e5b27da40a0ac8f53ed6ce39bb76694aa9c305","modified":1493024456000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/classes/META-INF/maven/org.springframework/gs-spring-boot/pom.xml","hash":"3783f66dacd688adef5a07c8637994d77f8a2fb9","modified":1493024456000},{"_id":"source/samplecodes/ServiceDiscoveryLoadBalancerSample/src/main/java/com/netflix/client/http/HttpResponse.java","hash":"3d06e30f1526df8993885f32464e76c7f3f470e8","modified":1488633515000},{"_id":"source/samplecodes/ServiceRegistryConsulDistributedTrace/target/gs-spring-boot-0.1.0.jar","hash":"5857649655f5fc23ad49cf8d3b6cbb4ca3bdfd86","modified":1488642778000}],"Category":[{"name":"分布式","_id":"cj2g8ok3m0004dl72uzerqh8o"}],"Data":[],"Page":[{"title":"categories","date":"2017-05-08T14:11:35.000Z","type":"categories","comments":0,"_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2017-05-08 22:11:35\ntype: \"categories\"\ncomments: false\n---\n","updated":"2017-05-08T14:17:28.000Z","path":"categories/index.html","layout":"page","_id":"cj2g8ok3i0001dl72x4wv0k78","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"about","date":"2017-05-08T13:59:13.000Z","_content":"","source":"about/index.md","raw":"---\ntitle: about\ndate: 2017-05-08 21:59:13\n---\n","updated":"2017-05-08T13:59:13.000Z","path":"about/index.html","comments":1,"layout":"page","_id":"cj2g8ok3l0003dl72coltfz2t","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"tags","date":"2017-05-08T14:11:46.000Z","type":"tags","comments":0,"_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2017-05-08 22:11:46\ntype: \"tags\"\ncomments: false\n---\n","updated":"2017-05-08T14:17:13.000Z","path":"tags/index.html","layout":"page","_id":"cj2g8ok3q0007dl72m82e3di4","content":"","site":{"data":{}},"excerpt":"","more":""},{"_content":"say-hello:\n ribbon:\n  okhttp:\n    enabled: true","source":"samplecodes/ServiceDiscoveryLoadBalancerSample/target/classes/application.yml","raw":"say-hello:\n ribbon:\n  okhttp:\n    enabled: true","date":"2017-05-08T09:44:25.000Z","updated":"2017-03-04T13:10:29.000Z","path":"samplecodes/ServiceDiscoveryLoadBalancerSample/target/classes/application.json","layout":"false","title":"","comments":1,"_id":"cj2g8okc0000pdl72f4tjry5b","content":"{\"say-hello\":{\"ribbon\":{\"okhttp\":{\"enabled\":true}}}}","site":{"data":{}},"excerpt":"","more":"{\"say-hello\":{\"ribbon\":{\"okhttp\":{\"enabled\":true}}}}"},{"_content":"say-hello:\n ribbon:\n  okhttp:\n    enabled: true","source":"samplecodes/ServiceDiscoveryLoadBalancerSample/src/main/java/application.yml","raw":"say-hello:\n ribbon:\n  okhttp:\n    enabled: true","date":"2017-05-08T09:44:25.000Z","updated":"2017-03-04T13:10:29.000Z","path":"samplecodes/ServiceDiscoveryLoadBalancerSample/src/main/java/application.json","layout":"false","title":"","comments":1,"_id":"cj2g8okc8000qdl72mph7l8ze","content":"{\"say-hello\":{\"ribbon\":{\"okhttp\":{\"enabled\":true}}}}","site":{"data":{}},"excerpt":"","more":"{\"say-hello\":{\"ribbon\":{\"okhttp\":{\"enabled\":true}}}}"},{"_content":"{\"properties\": [{\n  \"name\": \"say-hello.ribbon.okhttp.enabled\",\n  \"type\": \"java.lang.String\",\n  \"description\": \"A description for 'say-hello.ribbon.okhttp.enabled'\"\n}]}","source":"samplecodes/ServiceDiscoveryLoadBalancerSample/target/classes/META-INF/additional-spring-configuration-metadata.json","raw":"{\"properties\": [{\n  \"name\": \"say-hello.ribbon.okhttp.enabled\",\n  \"type\": \"java.lang.String\",\n  \"description\": \"A description for 'say-hello.ribbon.okhttp.enabled'\"\n}]}","date":"2017-05-08T09:44:25.000Z","updated":"2017-03-04T13:10:38.000Z","path":"samplecodes/ServiceDiscoveryLoadBalancerSample/target/classes/META-INF/additional-spring-configuration-metadata.json","layout":"false","title":"","comments":1,"_id":"cj2g8okc9000rdl72gwbpey7t","content":"{\"properties\":[{\"name\":\"say-hello.ribbon.okhttp.enabled\",\"type\":\"java.lang.String\",\"description\":\"A description for 'say-hello.ribbon.okhttp.enabled'\"}]}","site":{"data":{}},"excerpt":"","more":"{\"properties\":[{\"name\":\"say-hello.ribbon.okhttp.enabled\",\"type\":\"java.lang.String\",\"description\":\"A description for 'say-hello.ribbon.okhttp.enabled'\"}]}"},{"_content":"{\"properties\": [{\n  \"name\": \"say-hello.ribbon.okhttp.enabled\",\n  \"type\": \"java.lang.String\",\n  \"description\": \"A description for 'say-hello.ribbon.okhttp.enabled'\"\n}]}","source":"samplecodes/ServiceDiscoveryLoadBalancerSample/src/main/java/META-INF/additional-spring-configuration-metadata.json","raw":"{\"properties\": [{\n  \"name\": \"say-hello.ribbon.okhttp.enabled\",\n  \"type\": \"java.lang.String\",\n  \"description\": \"A description for 'say-hello.ribbon.okhttp.enabled'\"\n}]}","date":"2017-05-08T09:44:25.000Z","updated":"2017-03-04T13:10:38.000Z","path":"samplecodes/ServiceDiscoveryLoadBalancerSample/src/main/java/META-INF/additional-spring-configuration-metadata.json","layout":"false","title":"","comments":1,"_id":"cj2g8okcu000sdl726za1rm0a","content":"{\"properties\":[{\"name\":\"say-hello.ribbon.okhttp.enabled\",\"type\":\"java.lang.String\",\"description\":\"A description for 'say-hello.ribbon.okhttp.enabled'\"}]}","site":{"data":{}},"excerpt":"","more":"{\"properties\":[{\"name\":\"say-hello.ribbon.okhttp.enabled\",\"type\":\"java.lang.String\",\"description\":\"A description for 'say-hello.ribbon.okhttp.enabled'\"}]}"}],"Post":[{"title":"分布式架构","_content":"\n### 1. 分布式配置管理\n  - Consul\n  - Archaius\n  - Kubernetes ConfigMap & Secrets\n\n配置的集中管理：采用consul的KV，将所有微服务的application.properties中的配置内容存入consul。\n\n配置的动态管理：采用archaius，将consul上的配置信息读到spring的PropertySource和archaius的PollResult中，当修改了配置信息后，经常改变的值通过DynamicFactory来获取，不经常改变的值可以通过其他方式获取. 大部分情况下，修改了consul上的配置信息后，相应的项目不需要重启，也会读到最新的值。\n\n### 2. 服务注册与发现\n  - [Consul](/2017/03/08/consul/)\n  - Eureka\n  - [Kubernetes Service](kubernetes.md#service) & Ingress Resource\n\n### 3. 负载平衡\n  - Netflix Ribbon（Spring Cloud）\n  - [Kubernetes Service](kubernetes.md#service)\n\n  [Client Side Load Balancing](consul.md)\n\n### 4. API网关与智能路由\n  - Netflix Zuul（SpringCloud）\n  - [Kubernetes Service](kubernetes.md#service) &Ingress Resource\n\n  [Gateway](gateway.md)\n\n### 5. 分布式服务弹性与容错\n - 弹性服务\n - 服务降级\n - 线程池/信号隔离\n - 快速解决依赖隔离\n\n [Hystrix架构设计](Hystrix.md)\n\n### 6. 日志管理\n  - ELK Stack（LogStash -> ES -> Kibana）\n\n### 7. 分布式跟踪\n  - Zipkin\n  - SpringCloud Sleuth\n\n  [Zipkin](zipkin) is a distributed tracing system. It helps gather timing data needed to troubleshoot latency problems in microservice architectures. It manages both the collection and lookup of this data. Zipkin’s design is based on the Google Dapper paper.\n\n  Applications are instrumented to report timing data to Zipkin. The Zipkin UI also presents a Dependency diagram showing how many traced requests went through each application. If you are troubleshooting latency problems or errors, you can filter or sort all traces based on the application, length of trace, annotation, or timestamp. Once you select a trace, you can see the percentage of the total trace time each span takes which allows you to identify the problem application.\n\n### 8. 监控与度量\n  - Application/Infrastructure monitoring using StatsD + Graphite + Grafana\n\n  [StatsD + Graphite + Grafana](sgg.md)\n\n### 9. 服务安全\n  - SpringCloud Security\n\n### 10. Auto Scaling\n  - Kubernetes Health Check、SelfHealing、Autoscaling\n\n### 11. 打包部署和调度部署\n  - Spring Boot；\n  - Docker／Rkt、Kubernetes Scheduler&Deployment\n\n### 12. 任务工作管理\n  - Spring Batch\n  - Kubernetes Jobs&Scheduled Jobs\n\n\n## 分布式存储\n#### 1.持久化 - 分布式文件系统\n- [HDFS分布式文件系统](hdfs.md)\n\n#### 2.持久化 - 分布式数据库\n- [传统关系型数据库集群,如MySQL Cluster]\n- [Mongo](mongo.md)\n- [Cassandra,HBase](hbase.md)\n\n#### 3.非持久化 - 分布式缓存/消息系统\n- [Kafka](kafka.md)\n- [Redis]\n\n## 分布式计算框架\n  - [YARN分布式计算框架](yarn.md)\n  - [YARN应用开发的几种方式](yarn-appdev.md)\n  - [Running Spark on YARN](running-spark-on-yarn.md)\n\n### Spark Big Data Analytics\n  - [Spark](spark.md)\n","source":"_posts/README.md","raw":"---\ntitle: 分布式架构\ncategories: 分布式\ntags:\n  - 分布式\n  - 架构设计\n---\n\n### 1. 分布式配置管理\n  - Consul\n  - Archaius\n  - Kubernetes ConfigMap & Secrets\n\n配置的集中管理：采用consul的KV，将所有微服务的application.properties中的配置内容存入consul。\n\n配置的动态管理：采用archaius，将consul上的配置信息读到spring的PropertySource和archaius的PollResult中，当修改了配置信息后，经常改变的值通过DynamicFactory来获取，不经常改变的值可以通过其他方式获取. 大部分情况下，修改了consul上的配置信息后，相应的项目不需要重启，也会读到最新的值。\n\n### 2. 服务注册与发现\n  - [Consul](/2017/03/08/consul/)\n  - Eureka\n  - [Kubernetes Service](kubernetes.md#service) & Ingress Resource\n\n### 3. 负载平衡\n  - Netflix Ribbon（Spring Cloud）\n  - [Kubernetes Service](kubernetes.md#service)\n\n  [Client Side Load Balancing](consul.md)\n\n### 4. API网关与智能路由\n  - Netflix Zuul（SpringCloud）\n  - [Kubernetes Service](kubernetes.md#service) &Ingress Resource\n\n  [Gateway](gateway.md)\n\n### 5. 分布式服务弹性与容错\n - 弹性服务\n - 服务降级\n - 线程池/信号隔离\n - 快速解决依赖隔离\n\n [Hystrix架构设计](Hystrix.md)\n\n### 6. 日志管理\n  - ELK Stack（LogStash -> ES -> Kibana）\n\n### 7. 分布式跟踪\n  - Zipkin\n  - SpringCloud Sleuth\n\n  [Zipkin](zipkin) is a distributed tracing system. It helps gather timing data needed to troubleshoot latency problems in microservice architectures. It manages both the collection and lookup of this data. Zipkin’s design is based on the Google Dapper paper.\n\n  Applications are instrumented to report timing data to Zipkin. The Zipkin UI also presents a Dependency diagram showing how many traced requests went through each application. If you are troubleshooting latency problems or errors, you can filter or sort all traces based on the application, length of trace, annotation, or timestamp. Once you select a trace, you can see the percentage of the total trace time each span takes which allows you to identify the problem application.\n\n### 8. 监控与度量\n  - Application/Infrastructure monitoring using StatsD + Graphite + Grafana\n\n  [StatsD + Graphite + Grafana](sgg.md)\n\n### 9. 服务安全\n  - SpringCloud Security\n\n### 10. Auto Scaling\n  - Kubernetes Health Check、SelfHealing、Autoscaling\n\n### 11. 打包部署和调度部署\n  - Spring Boot；\n  - Docker／Rkt、Kubernetes Scheduler&Deployment\n\n### 12. 任务工作管理\n  - Spring Batch\n  - Kubernetes Jobs&Scheduled Jobs\n\n\n## 分布式存储\n#### 1.持久化 - 分布式文件系统\n- [HDFS分布式文件系统](hdfs.md)\n\n#### 2.持久化 - 分布式数据库\n- [传统关系型数据库集群,如MySQL Cluster]\n- [Mongo](mongo.md)\n- [Cassandra,HBase](hbase.md)\n\n#### 3.非持久化 - 分布式缓存/消息系统\n- [Kafka](kafka.md)\n- [Redis]\n\n## 分布式计算框架\n  - [YARN分布式计算框架](yarn.md)\n  - [YARN应用开发的几种方式](yarn-appdev.md)\n  - [Running Spark on YARN](running-spark-on-yarn.md)\n\n### Spark Big Data Analytics\n  - [Spark](spark.md)\n","slug":"README","published":1,"date":"2017-05-04T09:22:19.000Z","updated":"2017-05-08T14:09:20.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj2g8ok3e0000dl72g85xmbzs","content":"<h3 id=\"1-分布式配置管理\"><a href=\"#1-分布式配置管理\" class=\"headerlink\" title=\"1. 分布式配置管理\"></a>1. 分布式配置管理</h3><ul>\n<li>Consul</li>\n<li>Archaius</li>\n<li>Kubernetes ConfigMap &amp; Secrets</li>\n</ul>\n<p>配置的集中管理：采用consul的KV，将所有微服务的application.properties中的配置内容存入consul。</p>\n<p>配置的动态管理：采用archaius，将consul上的配置信息读到spring的PropertySource和archaius的PollResult中，当修改了配置信息后，经常改变的值通过DynamicFactory来获取，不经常改变的值可以通过其他方式获取. 大部分情况下，修改了consul上的配置信息后，相应的项目不需要重启，也会读到最新的值。</p>\n<h3 id=\"2-服务注册与发现\"><a href=\"#2-服务注册与发现\" class=\"headerlink\" title=\"2. 服务注册与发现\"></a>2. 服务注册与发现</h3><ul>\n<li><a href=\"/2017/03/08/consul/\">Consul</a></li>\n<li>Eureka</li>\n<li><a href=\"kubernetes.md#service\">Kubernetes Service</a> &amp; Ingress Resource</li>\n</ul>\n<h3 id=\"3-负载平衡\"><a href=\"#3-负载平衡\" class=\"headerlink\" title=\"3. 负载平衡\"></a>3. 负载平衡</h3><ul>\n<li>Netflix Ribbon（Spring Cloud）</li>\n<li><p><a href=\"kubernetes.md#service\">Kubernetes Service</a></p>\n<p><a href=\"consul.md\">Client Side Load Balancing</a></p>\n</li>\n</ul>\n<h3 id=\"4-API网关与智能路由\"><a href=\"#4-API网关与智能路由\" class=\"headerlink\" title=\"4. API网关与智能路由\"></a>4. API网关与智能路由</h3><ul>\n<li>Netflix Zuul（SpringCloud）</li>\n<li><p><a href=\"kubernetes.md#service\">Kubernetes Service</a> &amp;Ingress Resource</p>\n<p><a href=\"gateway.md\">Gateway</a></p>\n</li>\n</ul>\n<h3 id=\"5-分布式服务弹性与容错\"><a href=\"#5-分布式服务弹性与容错\" class=\"headerlink\" title=\"5. 分布式服务弹性与容错\"></a>5. 分布式服务弹性与容错</h3><ul>\n<li>弹性服务</li>\n<li>服务降级</li>\n<li>线程池/信号隔离</li>\n<li><p>快速解决依赖隔离</p>\n<p><a href=\"Hystrix.md\">Hystrix架构设计</a></p>\n</li>\n</ul>\n<h3 id=\"6-日志管理\"><a href=\"#6-日志管理\" class=\"headerlink\" title=\"6. 日志管理\"></a>6. 日志管理</h3><ul>\n<li>ELK Stack（LogStash -&gt; ES -&gt; Kibana）</li>\n</ul>\n<h3 id=\"7-分布式跟踪\"><a href=\"#7-分布式跟踪\" class=\"headerlink\" title=\"7. 分布式跟踪\"></a>7. 分布式跟踪</h3><ul>\n<li>Zipkin</li>\n<li><p>SpringCloud Sleuth</p>\n<p><a href=\"zipkin\">Zipkin</a> is a distributed tracing system. It helps gather timing data needed to troubleshoot latency problems in microservice architectures. It manages both the collection and lookup of this data. Zipkin’s design is based on the Google Dapper paper.</p>\n<p>Applications are instrumented to report timing data to Zipkin. The Zipkin UI also presents a Dependency diagram showing how many traced requests went through each application. If you are troubleshooting latency problems or errors, you can filter or sort all traces based on the application, length of trace, annotation, or timestamp. Once you select a trace, you can see the percentage of the total trace time each span takes which allows you to identify the problem application.</p>\n</li>\n</ul>\n<h3 id=\"8-监控与度量\"><a href=\"#8-监控与度量\" class=\"headerlink\" title=\"8. 监控与度量\"></a>8. 监控与度量</h3><ul>\n<li><p>Application/Infrastructure monitoring using StatsD + Graphite + Grafana</p>\n<p><a href=\"sgg.md\">StatsD + Graphite + Grafana</a></p>\n</li>\n</ul>\n<h3 id=\"9-服务安全\"><a href=\"#9-服务安全\" class=\"headerlink\" title=\"9. 服务安全\"></a>9. 服务安全</h3><ul>\n<li>SpringCloud Security</li>\n</ul>\n<h3 id=\"10-Auto-Scaling\"><a href=\"#10-Auto-Scaling\" class=\"headerlink\" title=\"10. Auto Scaling\"></a>10. Auto Scaling</h3><ul>\n<li>Kubernetes Health Check、SelfHealing、Autoscaling</li>\n</ul>\n<h3 id=\"11-打包部署和调度部署\"><a href=\"#11-打包部署和调度部署\" class=\"headerlink\" title=\"11. 打包部署和调度部署\"></a>11. 打包部署和调度部署</h3><ul>\n<li>Spring Boot；</li>\n<li>Docker／Rkt、Kubernetes Scheduler&amp;Deployment</li>\n</ul>\n<h3 id=\"12-任务工作管理\"><a href=\"#12-任务工作管理\" class=\"headerlink\" title=\"12. 任务工作管理\"></a>12. 任务工作管理</h3><ul>\n<li>Spring Batch</li>\n<li>Kubernetes Jobs&amp;Scheduled Jobs</li>\n</ul>\n<h2 id=\"分布式存储\"><a href=\"#分布式存储\" class=\"headerlink\" title=\"分布式存储\"></a>分布式存储</h2><h4 id=\"1-持久化-分布式文件系统\"><a href=\"#1-持久化-分布式文件系统\" class=\"headerlink\" title=\"1.持久化 - 分布式文件系统\"></a>1.持久化 - 分布式文件系统</h4><ul>\n<li><a href=\"hdfs.md\">HDFS分布式文件系统</a></li>\n</ul>\n<h4 id=\"2-持久化-分布式数据库\"><a href=\"#2-持久化-分布式数据库\" class=\"headerlink\" title=\"2.持久化 - 分布式数据库\"></a>2.持久化 - 分布式数据库</h4><ul>\n<li>[传统关系型数据库集群,如MySQL Cluster]</li>\n<li><a href=\"mongo.md\">Mongo</a></li>\n<li><a href=\"hbase.md\">Cassandra,HBase</a></li>\n</ul>\n<h4 id=\"3-非持久化-分布式缓存-消息系统\"><a href=\"#3-非持久化-分布式缓存-消息系统\" class=\"headerlink\" title=\"3.非持久化 - 分布式缓存/消息系统\"></a>3.非持久化 - 分布式缓存/消息系统</h4><ul>\n<li><a href=\"kafka.md\">Kafka</a></li>\n<li>[Redis]</li>\n</ul>\n<h2 id=\"分布式计算框架\"><a href=\"#分布式计算框架\" class=\"headerlink\" title=\"分布式计算框架\"></a>分布式计算框架</h2><ul>\n<li><a href=\"yarn.md\">YARN分布式计算框架</a></li>\n<li><a href=\"yarn-appdev.md\">YARN应用开发的几种方式</a></li>\n<li><a href=\"running-spark-on-yarn.md\">Running Spark on YARN</a></li>\n</ul>\n<h3 id=\"Spark-Big-Data-Analytics\"><a href=\"#Spark-Big-Data-Analytics\" class=\"headerlink\" title=\"Spark Big Data Analytics\"></a>Spark Big Data Analytics</h3><ul>\n<li><a href=\"spark.md\">Spark</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"1-分布式配置管理\"><a href=\"#1-分布式配置管理\" class=\"headerlink\" title=\"1. 分布式配置管理\"></a>1. 分布式配置管理</h3><ul>\n<li>Consul</li>\n<li>Archaius</li>\n<li>Kubernetes ConfigMap &amp; Secrets</li>\n</ul>\n<p>配置的集中管理：采用consul的KV，将所有微服务的application.properties中的配置内容存入consul。</p>\n<p>配置的动态管理：采用archaius，将consul上的配置信息读到spring的PropertySource和archaius的PollResult中，当修改了配置信息后，经常改变的值通过DynamicFactory来获取，不经常改变的值可以通过其他方式获取. 大部分情况下，修改了consul上的配置信息后，相应的项目不需要重启，也会读到最新的值。</p>\n<h3 id=\"2-服务注册与发现\"><a href=\"#2-服务注册与发现\" class=\"headerlink\" title=\"2. 服务注册与发现\"></a>2. 服务注册与发现</h3><ul>\n<li><a href=\"/2017/03/08/consul/\">Consul</a></li>\n<li>Eureka</li>\n<li><a href=\"kubernetes.md#service\">Kubernetes Service</a> &amp; Ingress Resource</li>\n</ul>\n<h3 id=\"3-负载平衡\"><a href=\"#3-负载平衡\" class=\"headerlink\" title=\"3. 负载平衡\"></a>3. 负载平衡</h3><ul>\n<li>Netflix Ribbon（Spring Cloud）</li>\n<li><p><a href=\"kubernetes.md#service\">Kubernetes Service</a></p>\n<p><a href=\"consul.md\">Client Side Load Balancing</a></p>\n</li>\n</ul>\n<h3 id=\"4-API网关与智能路由\"><a href=\"#4-API网关与智能路由\" class=\"headerlink\" title=\"4. API网关与智能路由\"></a>4. API网关与智能路由</h3><ul>\n<li>Netflix Zuul（SpringCloud）</li>\n<li><p><a href=\"kubernetes.md#service\">Kubernetes Service</a> &amp;Ingress Resource</p>\n<p><a href=\"gateway.md\">Gateway</a></p>\n</li>\n</ul>\n<h3 id=\"5-分布式服务弹性与容错\"><a href=\"#5-分布式服务弹性与容错\" class=\"headerlink\" title=\"5. 分布式服务弹性与容错\"></a>5. 分布式服务弹性与容错</h3><ul>\n<li>弹性服务</li>\n<li>服务降级</li>\n<li>线程池/信号隔离</li>\n<li><p>快速解决依赖隔离</p>\n<p><a href=\"Hystrix.md\">Hystrix架构设计</a></p>\n</li>\n</ul>\n<h3 id=\"6-日志管理\"><a href=\"#6-日志管理\" class=\"headerlink\" title=\"6. 日志管理\"></a>6. 日志管理</h3><ul>\n<li>ELK Stack（LogStash -&gt; ES -&gt; Kibana）</li>\n</ul>\n<h3 id=\"7-分布式跟踪\"><a href=\"#7-分布式跟踪\" class=\"headerlink\" title=\"7. 分布式跟踪\"></a>7. 分布式跟踪</h3><ul>\n<li>Zipkin</li>\n<li><p>SpringCloud Sleuth</p>\n<p><a href=\"zipkin\">Zipkin</a> is a distributed tracing system. It helps gather timing data needed to troubleshoot latency problems in microservice architectures. It manages both the collection and lookup of this data. Zipkin’s design is based on the Google Dapper paper.</p>\n<p>Applications are instrumented to report timing data to Zipkin. The Zipkin UI also presents a Dependency diagram showing how many traced requests went through each application. If you are troubleshooting latency problems or errors, you can filter or sort all traces based on the application, length of trace, annotation, or timestamp. Once you select a trace, you can see the percentage of the total trace time each span takes which allows you to identify the problem application.</p>\n</li>\n</ul>\n<h3 id=\"8-监控与度量\"><a href=\"#8-监控与度量\" class=\"headerlink\" title=\"8. 监控与度量\"></a>8. 监控与度量</h3><ul>\n<li><p>Application/Infrastructure monitoring using StatsD + Graphite + Grafana</p>\n<p><a href=\"sgg.md\">StatsD + Graphite + Grafana</a></p>\n</li>\n</ul>\n<h3 id=\"9-服务安全\"><a href=\"#9-服务安全\" class=\"headerlink\" title=\"9. 服务安全\"></a>9. 服务安全</h3><ul>\n<li>SpringCloud Security</li>\n</ul>\n<h3 id=\"10-Auto-Scaling\"><a href=\"#10-Auto-Scaling\" class=\"headerlink\" title=\"10. Auto Scaling\"></a>10. Auto Scaling</h3><ul>\n<li>Kubernetes Health Check、SelfHealing、Autoscaling</li>\n</ul>\n<h3 id=\"11-打包部署和调度部署\"><a href=\"#11-打包部署和调度部署\" class=\"headerlink\" title=\"11. 打包部署和调度部署\"></a>11. 打包部署和调度部署</h3><ul>\n<li>Spring Boot；</li>\n<li>Docker／Rkt、Kubernetes Scheduler&amp;Deployment</li>\n</ul>\n<h3 id=\"12-任务工作管理\"><a href=\"#12-任务工作管理\" class=\"headerlink\" title=\"12. 任务工作管理\"></a>12. 任务工作管理</h3><ul>\n<li>Spring Batch</li>\n<li>Kubernetes Jobs&amp;Scheduled Jobs</li>\n</ul>\n<h2 id=\"分布式存储\"><a href=\"#分布式存储\" class=\"headerlink\" title=\"分布式存储\"></a>分布式存储</h2><h4 id=\"1-持久化-分布式文件系统\"><a href=\"#1-持久化-分布式文件系统\" class=\"headerlink\" title=\"1.持久化 - 分布式文件系统\"></a>1.持久化 - 分布式文件系统</h4><ul>\n<li><a href=\"hdfs.md\">HDFS分布式文件系统</a></li>\n</ul>\n<h4 id=\"2-持久化-分布式数据库\"><a href=\"#2-持久化-分布式数据库\" class=\"headerlink\" title=\"2.持久化 - 分布式数据库\"></a>2.持久化 - 分布式数据库</h4><ul>\n<li>[传统关系型数据库集群,如MySQL Cluster]</li>\n<li><a href=\"mongo.md\">Mongo</a></li>\n<li><a href=\"hbase.md\">Cassandra,HBase</a></li>\n</ul>\n<h4 id=\"3-非持久化-分布式缓存-消息系统\"><a href=\"#3-非持久化-分布式缓存-消息系统\" class=\"headerlink\" title=\"3.非持久化 - 分布式缓存/消息系统\"></a>3.非持久化 - 分布式缓存/消息系统</h4><ul>\n<li><a href=\"kafka.md\">Kafka</a></li>\n<li>[Redis]</li>\n</ul>\n<h2 id=\"分布式计算框架\"><a href=\"#分布式计算框架\" class=\"headerlink\" title=\"分布式计算框架\"></a>分布式计算框架</h2><ul>\n<li><a href=\"yarn.md\">YARN分布式计算框架</a></li>\n<li><a href=\"yarn-appdev.md\">YARN应用开发的几种方式</a></li>\n<li><a href=\"running-spark-on-yarn.md\">Running Spark on YARN</a></li>\n</ul>\n<h3 id=\"Spark-Big-Data-Analytics\"><a href=\"#Spark-Big-Data-Analytics\" class=\"headerlink\" title=\"Spark Big Data Analytics\"></a>Spark Big Data Analytics</h3><ul>\n<li><a href=\"spark.md\">Spark</a></li>\n</ul>\n"},{"title":"Consul","_content":"\n### Consul 服务注册管理\n#### 启动Consul Docker\n\n```\ndocker run -d -p 8400:8400 -p 8500:8500/tcp -p 8600:53/udp -e 'CONSUL_LOCAL_CONFIG={\"acl_datacenter\":\"dc1\",\"acl_default_policy”:\"write\",\"acl_down_policy\":\"extend-cache\",\"acl_master_token\":\"the_one_ring\",\"bootstrap_expect\":1,\"datacenter\":\"dc1\",\"data_dir\":\"/usr/local/bin/consul.d/data\",\"server\":true}' consul agent -server -bind=127.0.0.1 -client=0.0.0.0\n```\n\nor\n\n```\ndocker run -d --name myconsul -p 8400:8400 -p 8500:8500/tcp -p 8600:53/udp -e 'CONSUL_LOCAL_CONFIG={\"acl_datacenter\":\"dc1\",\"acl_default_policy\":\"allow\",\"acl_down_policy\":\"extend-cache\",\"acl_master_token\":\"the_one_ring\",\"bootstrap_expect\":1,\"datacenter\":\"dc1\",\"data_dir\":\"/usr/local/bin/consul.d/data\",\"server\":true}' consul agent -server -bind=127.0.0.1 -client=0.0.0.0 -ui\n```\n\n#### 1. 注册服务:\n\nhttp://{IP}:8500/v1/agent/service/register\n\nPUT\n```\n{\n    \"id\": \"Analytics_Job_Free_JobID0001\",\n    \"name\": \"Analytics_Job_Free_JobID0001\",\n    \"tags\": [\n        \"RTI\"\n    ]\n}\n```\n\n#### 2. 注销服务：\n\nhttp://{IP}:8500/v1/agent/service/deregister/jetty\n\n\n#### 3. 注册check\n\nhttp://{IP}:8500/v1/agent/check/register\n\nPUT\n```\n{  \n            \"http\": \"http://192.168.1.200:8080/health?appId=app001\",  \n            \"interval\": “20s\",\n            \"id\": \"app001\",\n              \"name\": \"Analytics YARN Application 001\",\n            \"applicationId\":\"app001\",\n            \"service_id\":\"Analytics_Job_Free_JobID0001\"\n        }\n\n{  \n            \"http\": \"http://192.168.1.200:8080/health?appId=app002\",  \n            \"interval\": “20s\",\n            \"id\": \"app002\",\n              \"name\": \"Analytics YARN Application 002\",\n            \"applicationId\":\"app002”,\n        \"status\": \"passing\",\n            \"service_id\":\"Analytics_Job_Free_JobID0001\"\n        }\n```\n#### 4. 注销check\n\nhttp://{IP}:8500/v1/agent/check/deregister/app002\n\n\n### 例子\n\n```\n<dependency>\n\t\t\t<groupId>org.springframework.cloud</groupId>\n\t\t\t<artifactId>spring-cloud-starter-consul-discovery</artifactId>\n\t\t\t<version>1.1.2.RELEASE</version>\n\t\t</dependency\n```\n\napplication.properties\n```\nserver.port=9955  \n\nspring.application.name=SampleClient\nspring.cloud.consul.host=127.0.0.1\nspring.cloud.consul.port=8500\nspring.cloud.consul.enabled=true\nspring.cloud.consul.discovery.register=false\nspring.cloud.consul.discovery.enabled=true\nspring.cloud.consul.discovery.instanceId=tomcat1\nspring.cloud.consul.discovery.serviceName=tomcat1  \nspring.cloud.consul.discovery.hostname=127.0.0.1\nspring.cloud.consul.discovery.port=${server.port}\nspring.cloud.consul.discovery.healthCheckUrl=http://127.0.0.1:9955/health  \nspring.cloud.consul.discovery.healthCheckInterval=10s  \nspring.cloud.consul.discovery.tags=dev\n```\n\napplication.yml\n```\nsay-hello:\n ribbon:\n  okhttp:\n    enabled: true\n```  \nEnable\n```\n@SpringBootApplication\n@EnableDiscoveryClient\n@RibbonClient(name = \"say-hello\", configuration = SayHelloConfiguration.class)\npublic class Application {\n```\n\nFull code\n```\npackage hello;\n\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.cloud.client.discovery.DiscoveryClient;\nimport org.springframework.cloud.client.loadbalancer.LoadBalanced;\nimport org.springframework.cloud.client.loadbalancer.LoadBalancerClient;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.RestController;\nimport org.springframework.web.client.RestTemplate;\n\n@RestController\npublic class HelloController {\n\n  @Autowired\n  private LoadBalancerClient loadBalancer;\n  @Autowired\n  private DiscoveryClient discoveryClient;\n\n  @LoadBalanced\n  @Bean\n  RestTemplate restTemplate() {\n    return new RestTemplate();\n  }\n\n  @Autowired\n  RestTemplate restTemplate;\n\n  /**\n   * 从所有服务中选择一个服务（轮询）\n   */\n  @RequestMapping(\"/discover\")\n  public Object discover() {\n    // return loadBalancer.choose(\"application\").getUri().toString();\n    String greeting = this.restTemplate.getForObject(\"http://application\", String.class);\n    return String.format(\"%s!\", greeting);\n  }\n\n  @RequestMapping(\"/d\")\n  public Object d() {\n    return loadBalancer.choose(\"application\").getUri().toString();\n\n  }\n\n  /**\n   * 获取所有服务\n   */\n  @RequestMapping(\"/services\")\n  public Object services() {\n    return discoveryClient.getInstances(\"application\").stream().findFirst().get().getUri();\n  }\n\n}\n\n```\n","source":"_posts/consul.md","raw":"---\ntitle: Consul\n---\n\n### Consul 服务注册管理\n#### 启动Consul Docker\n\n```\ndocker run -d -p 8400:8400 -p 8500:8500/tcp -p 8600:53/udp -e 'CONSUL_LOCAL_CONFIG={\"acl_datacenter\":\"dc1\",\"acl_default_policy”:\"write\",\"acl_down_policy\":\"extend-cache\",\"acl_master_token\":\"the_one_ring\",\"bootstrap_expect\":1,\"datacenter\":\"dc1\",\"data_dir\":\"/usr/local/bin/consul.d/data\",\"server\":true}' consul agent -server -bind=127.0.0.1 -client=0.0.0.0\n```\n\nor\n\n```\ndocker run -d --name myconsul -p 8400:8400 -p 8500:8500/tcp -p 8600:53/udp -e 'CONSUL_LOCAL_CONFIG={\"acl_datacenter\":\"dc1\",\"acl_default_policy\":\"allow\",\"acl_down_policy\":\"extend-cache\",\"acl_master_token\":\"the_one_ring\",\"bootstrap_expect\":1,\"datacenter\":\"dc1\",\"data_dir\":\"/usr/local/bin/consul.d/data\",\"server\":true}' consul agent -server -bind=127.0.0.1 -client=0.0.0.0 -ui\n```\n\n#### 1. 注册服务:\n\nhttp://{IP}:8500/v1/agent/service/register\n\nPUT\n```\n{\n    \"id\": \"Analytics_Job_Free_JobID0001\",\n    \"name\": \"Analytics_Job_Free_JobID0001\",\n    \"tags\": [\n        \"RTI\"\n    ]\n}\n```\n\n#### 2. 注销服务：\n\nhttp://{IP}:8500/v1/agent/service/deregister/jetty\n\n\n#### 3. 注册check\n\nhttp://{IP}:8500/v1/agent/check/register\n\nPUT\n```\n{  \n            \"http\": \"http://192.168.1.200:8080/health?appId=app001\",  \n            \"interval\": “20s\",\n            \"id\": \"app001\",\n              \"name\": \"Analytics YARN Application 001\",\n            \"applicationId\":\"app001\",\n            \"service_id\":\"Analytics_Job_Free_JobID0001\"\n        }\n\n{  \n            \"http\": \"http://192.168.1.200:8080/health?appId=app002\",  \n            \"interval\": “20s\",\n            \"id\": \"app002\",\n              \"name\": \"Analytics YARN Application 002\",\n            \"applicationId\":\"app002”,\n        \"status\": \"passing\",\n            \"service_id\":\"Analytics_Job_Free_JobID0001\"\n        }\n```\n#### 4. 注销check\n\nhttp://{IP}:8500/v1/agent/check/deregister/app002\n\n\n### 例子\n\n```\n<dependency>\n\t\t\t<groupId>org.springframework.cloud</groupId>\n\t\t\t<artifactId>spring-cloud-starter-consul-discovery</artifactId>\n\t\t\t<version>1.1.2.RELEASE</version>\n\t\t</dependency\n```\n\napplication.properties\n```\nserver.port=9955  \n\nspring.application.name=SampleClient\nspring.cloud.consul.host=127.0.0.1\nspring.cloud.consul.port=8500\nspring.cloud.consul.enabled=true\nspring.cloud.consul.discovery.register=false\nspring.cloud.consul.discovery.enabled=true\nspring.cloud.consul.discovery.instanceId=tomcat1\nspring.cloud.consul.discovery.serviceName=tomcat1  \nspring.cloud.consul.discovery.hostname=127.0.0.1\nspring.cloud.consul.discovery.port=${server.port}\nspring.cloud.consul.discovery.healthCheckUrl=http://127.0.0.1:9955/health  \nspring.cloud.consul.discovery.healthCheckInterval=10s  \nspring.cloud.consul.discovery.tags=dev\n```\n\napplication.yml\n```\nsay-hello:\n ribbon:\n  okhttp:\n    enabled: true\n```  \nEnable\n```\n@SpringBootApplication\n@EnableDiscoveryClient\n@RibbonClient(name = \"say-hello\", configuration = SayHelloConfiguration.class)\npublic class Application {\n```\n\nFull code\n```\npackage hello;\n\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.cloud.client.discovery.DiscoveryClient;\nimport org.springframework.cloud.client.loadbalancer.LoadBalanced;\nimport org.springframework.cloud.client.loadbalancer.LoadBalancerClient;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.RestController;\nimport org.springframework.web.client.RestTemplate;\n\n@RestController\npublic class HelloController {\n\n  @Autowired\n  private LoadBalancerClient loadBalancer;\n  @Autowired\n  private DiscoveryClient discoveryClient;\n\n  @LoadBalanced\n  @Bean\n  RestTemplate restTemplate() {\n    return new RestTemplate();\n  }\n\n  @Autowired\n  RestTemplate restTemplate;\n\n  /**\n   * 从所有服务中选择一个服务（轮询）\n   */\n  @RequestMapping(\"/discover\")\n  public Object discover() {\n    // return loadBalancer.choose(\"application\").getUri().toString();\n    String greeting = this.restTemplate.getForObject(\"http://application\", String.class);\n    return String.format(\"%s!\", greeting);\n  }\n\n  @RequestMapping(\"/d\")\n  public Object d() {\n    return loadBalancer.choose(\"application\").getUri().toString();\n\n  }\n\n  /**\n   * 获取所有服务\n   */\n  @RequestMapping(\"/services\")\n  public Object services() {\n    return discoveryClient.getInstances(\"application\").stream().findFirst().get().getUri();\n  }\n\n}\n\n```\n","slug":"consul","published":1,"date":"2017-03-08T14:36:51.000Z","updated":"2017-05-08T13:31:13.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj2g8ok3j0002dl72ucyf52pu","content":"<h3 id=\"Consul-服务注册管理\"><a href=\"#Consul-服务注册管理\" class=\"headerlink\" title=\"Consul 服务注册管理\"></a>Consul 服务注册管理</h3><h4 id=\"启动Consul-Docker\"><a href=\"#启动Consul-Docker\" class=\"headerlink\" title=\"启动Consul Docker\"></a>启动Consul Docker</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker run -d -p 8400:8400 -p 8500:8500/tcp -p 8600:53/udp -e &apos;CONSUL_LOCAL_CONFIG=&#123;&quot;acl_datacenter&quot;:&quot;dc1&quot;,&quot;acl_default_policy”:&quot;write&quot;,&quot;acl_down_policy&quot;:&quot;extend-cache&quot;,&quot;acl_master_token&quot;:&quot;the_one_ring&quot;,&quot;bootstrap_expect&quot;:1,&quot;datacenter&quot;:&quot;dc1&quot;,&quot;data_dir&quot;:&quot;/usr/local/bin/consul.d/data&quot;,&quot;server&quot;:true&#125;&apos; consul agent -server -bind=127.0.0.1 -client=0.0.0.0</div></pre></td></tr></table></figure>\n<p>or</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker run -d --name myconsul -p 8400:8400 -p 8500:8500/tcp -p 8600:53/udp -e &apos;CONSUL_LOCAL_CONFIG=&#123;&quot;acl_datacenter&quot;:&quot;dc1&quot;,&quot;acl_default_policy&quot;:&quot;allow&quot;,&quot;acl_down_policy&quot;:&quot;extend-cache&quot;,&quot;acl_master_token&quot;:&quot;the_one_ring&quot;,&quot;bootstrap_expect&quot;:1,&quot;datacenter&quot;:&quot;dc1&quot;,&quot;data_dir&quot;:&quot;/usr/local/bin/consul.d/data&quot;,&quot;server&quot;:true&#125;&apos; consul agent -server -bind=127.0.0.1 -client=0.0.0.0 -ui</div></pre></td></tr></table></figure>\n<h4 id=\"1-注册服务\"><a href=\"#1-注册服务\" class=\"headerlink\" title=\"1. 注册服务:\"></a>1. 注册服务:</h4><p><a href=\"http://{IP}:8500/v1/agent/service/register\" target=\"_blank\" rel=\"external\">http://{IP}:8500/v1/agent/service/register</a></p>\n<p>PUT<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">    &quot;id&quot;: &quot;Analytics_Job_Free_JobID0001&quot;,</div><div class=\"line\">    &quot;name&quot;: &quot;Analytics_Job_Free_JobID0001&quot;,</div><div class=\"line\">    &quot;tags&quot;: [</div><div class=\"line\">        &quot;RTI&quot;</div><div class=\"line\">    ]</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h4 id=\"2-注销服务：\"><a href=\"#2-注销服务：\" class=\"headerlink\" title=\"2. 注销服务：\"></a>2. 注销服务：</h4><p><a href=\"http://{IP}:8500/v1/agent/service/deregister/jetty\" target=\"_blank\" rel=\"external\">http://{IP}:8500/v1/agent/service/deregister/jetty</a></p>\n<h4 id=\"3-注册check\"><a href=\"#3-注册check\" class=\"headerlink\" title=\"3. 注册check\"></a>3. 注册check</h4><p><a href=\"http://{IP}:8500/v1/agent/check/register\" target=\"_blank\" rel=\"external\">http://{IP}:8500/v1/agent/check/register</a></p>\n<p>PUT<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;  </div><div class=\"line\">            &quot;http&quot;: &quot;http://192.168.1.200:8080/health?appId=app001&quot;,  </div><div class=\"line\">            &quot;interval&quot;: “20s&quot;,</div><div class=\"line\">            &quot;id&quot;: &quot;app001&quot;,</div><div class=\"line\">              &quot;name&quot;: &quot;Analytics YARN Application 001&quot;,</div><div class=\"line\">            &quot;applicationId&quot;:&quot;app001&quot;,</div><div class=\"line\">            &quot;service_id&quot;:&quot;Analytics_Job_Free_JobID0001&quot;</div><div class=\"line\">        &#125;</div><div class=\"line\"></div><div class=\"line\">&#123;  </div><div class=\"line\">            &quot;http&quot;: &quot;http://192.168.1.200:8080/health?appId=app002&quot;,  </div><div class=\"line\">            &quot;interval&quot;: “20s&quot;,</div><div class=\"line\">            &quot;id&quot;: &quot;app002&quot;,</div><div class=\"line\">              &quot;name&quot;: &quot;Analytics YARN Application 002&quot;,</div><div class=\"line\">            &quot;applicationId&quot;:&quot;app002”,</div><div class=\"line\">        &quot;status&quot;: &quot;passing&quot;,</div><div class=\"line\">            &quot;service_id&quot;:&quot;Analytics_Job_Free_JobID0001&quot;</div><div class=\"line\">        &#125;</div></pre></td></tr></table></figure></p>\n<h4 id=\"4-注销check\"><a href=\"#4-注销check\" class=\"headerlink\" title=\"4. 注销check\"></a>4. 注销check</h4><p><a href=\"http://{IP}:8500/v1/agent/check/deregister/app002\" target=\"_blank\" rel=\"external\">http://{IP}:8500/v1/agent/check/deregister/app002</a></p>\n<h3 id=\"例子\"><a href=\"#例子\" class=\"headerlink\" title=\"例子\"></a>例子</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;dependency&gt;</div><div class=\"line\">\t\t\t&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class=\"line\">\t\t\t&lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt;</div><div class=\"line\">\t\t\t&lt;version&gt;1.1.2.RELEASE&lt;/version&gt;</div><div class=\"line\">\t\t&lt;/dependency</div></pre></td></tr></table></figure>\n<p>application.properties<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">server.port=9955  </div><div class=\"line\"></div><div class=\"line\">spring.application.name=SampleClient</div><div class=\"line\">spring.cloud.consul.host=127.0.0.1</div><div class=\"line\">spring.cloud.consul.port=8500</div><div class=\"line\">spring.cloud.consul.enabled=true</div><div class=\"line\">spring.cloud.consul.discovery.register=false</div><div class=\"line\">spring.cloud.consul.discovery.enabled=true</div><div class=\"line\">spring.cloud.consul.discovery.instanceId=tomcat1</div><div class=\"line\">spring.cloud.consul.discovery.serviceName=tomcat1  </div><div class=\"line\">spring.cloud.consul.discovery.hostname=127.0.0.1</div><div class=\"line\">spring.cloud.consul.discovery.port=$&#123;server.port&#125;</div><div class=\"line\">spring.cloud.consul.discovery.healthCheckUrl=http://127.0.0.1:9955/health  </div><div class=\"line\">spring.cloud.consul.discovery.healthCheckInterval=10s  </div><div class=\"line\">spring.cloud.consul.discovery.tags=dev</div></pre></td></tr></table></figure></p>\n<p>application.yml<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">say-hello:</div><div class=\"line\"> ribbon:</div><div class=\"line\">  okhttp:</div><div class=\"line\">    enabled: true</div><div class=\"line\">```  </div><div class=\"line\">Enable</div></pre></td></tr></table></figure></p>\n<p>@SpringBootApplication<br>@EnableDiscoveryClient<br>@RibbonClient(name = “say-hello”, configuration = SayHelloConfiguration.class)<br>public class Application {<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">Full code</div></pre></td></tr></table></figure></p>\n<p>package hello;</p>\n<p>import org.springframework.beans.factory.annotation.Autowired;<br>import org.springframework.cloud.client.discovery.DiscoveryClient;<br>import org.springframework.cloud.client.loadbalancer.LoadBalanced;<br>import org.springframework.cloud.client.loadbalancer.LoadBalancerClient;<br>import org.springframework.context.annotation.Bean;<br>import org.springframework.web.bind.annotation.RequestMapping;<br>import org.springframework.web.bind.annotation.RestController;<br>import org.springframework.web.client.RestTemplate;</p>\n<p>@RestController<br>public class HelloController {</p>\n<p>  @Autowired<br>  private LoadBalancerClient loadBalancer;<br>  @Autowired<br>  private DiscoveryClient discoveryClient;</p>\n<p>  @LoadBalanced<br>  @Bean<br>  RestTemplate restTemplate() {<br>    return new RestTemplate();<br>  }</p>\n<p>  @Autowired<br>  RestTemplate restTemplate;</p>\n<p>  /**</p>\n<ul>\n<li><p>从所有服务中选择一个服务（轮询）<br>*/<br>@RequestMapping(“/discover”)<br>public Object discover() {<br>// return loadBalancer.choose(“application”).getUri().toString();<br>String greeting = this.restTemplate.getForObject(“<a href=\"http://application\" target=\"_blank\" rel=\"external\">http://application</a>“, String.class);<br>return String.format(“%s!”, greeting);<br>}</p>\n<p>@RequestMapping(“/d”)<br>public Object d() {<br>return loadBalancer.choose(“application”).getUri().toString();</p>\n<p>}</p>\n<p>/**</p>\n</li>\n<li>获取所有服务<br>*/<br>@RequestMapping(“/services”)<br>public Object services() {<br>return discoveryClient.getInstances(“application”).stream().findFirst().get().getUri();<br>}</li>\n</ul>\n<p>}</p>\n<p>```</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"Consul-服务注册管理\"><a href=\"#Consul-服务注册管理\" class=\"headerlink\" title=\"Consul 服务注册管理\"></a>Consul 服务注册管理</h3><h4 id=\"启动Consul-Docker\"><a href=\"#启动Consul-Docker\" class=\"headerlink\" title=\"启动Consul Docker\"></a>启动Consul Docker</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker run -d -p 8400:8400 -p 8500:8500/tcp -p 8600:53/udp -e &apos;CONSUL_LOCAL_CONFIG=&#123;&quot;acl_datacenter&quot;:&quot;dc1&quot;,&quot;acl_default_policy”:&quot;write&quot;,&quot;acl_down_policy&quot;:&quot;extend-cache&quot;,&quot;acl_master_token&quot;:&quot;the_one_ring&quot;,&quot;bootstrap_expect&quot;:1,&quot;datacenter&quot;:&quot;dc1&quot;,&quot;data_dir&quot;:&quot;/usr/local/bin/consul.d/data&quot;,&quot;server&quot;:true&#125;&apos; consul agent -server -bind=127.0.0.1 -client=0.0.0.0</div></pre></td></tr></table></figure>\n<p>or</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker run -d --name myconsul -p 8400:8400 -p 8500:8500/tcp -p 8600:53/udp -e &apos;CONSUL_LOCAL_CONFIG=&#123;&quot;acl_datacenter&quot;:&quot;dc1&quot;,&quot;acl_default_policy&quot;:&quot;allow&quot;,&quot;acl_down_policy&quot;:&quot;extend-cache&quot;,&quot;acl_master_token&quot;:&quot;the_one_ring&quot;,&quot;bootstrap_expect&quot;:1,&quot;datacenter&quot;:&quot;dc1&quot;,&quot;data_dir&quot;:&quot;/usr/local/bin/consul.d/data&quot;,&quot;server&quot;:true&#125;&apos; consul agent -server -bind=127.0.0.1 -client=0.0.0.0 -ui</div></pre></td></tr></table></figure>\n<h4 id=\"1-注册服务\"><a href=\"#1-注册服务\" class=\"headerlink\" title=\"1. 注册服务:\"></a>1. 注册服务:</h4><p><a href=\"http://{IP}:8500/v1/agent/service/register\" target=\"_blank\" rel=\"external\">http://{IP}:8500/v1/agent/service/register</a></p>\n<p>PUT<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">    &quot;id&quot;: &quot;Analytics_Job_Free_JobID0001&quot;,</div><div class=\"line\">    &quot;name&quot;: &quot;Analytics_Job_Free_JobID0001&quot;,</div><div class=\"line\">    &quot;tags&quot;: [</div><div class=\"line\">        &quot;RTI&quot;</div><div class=\"line\">    ]</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h4 id=\"2-注销服务：\"><a href=\"#2-注销服务：\" class=\"headerlink\" title=\"2. 注销服务：\"></a>2. 注销服务：</h4><p><a href=\"http://{IP}:8500/v1/agent/service/deregister/jetty\" target=\"_blank\" rel=\"external\">http://{IP}:8500/v1/agent/service/deregister/jetty</a></p>\n<h4 id=\"3-注册check\"><a href=\"#3-注册check\" class=\"headerlink\" title=\"3. 注册check\"></a>3. 注册check</h4><p><a href=\"http://{IP}:8500/v1/agent/check/register\" target=\"_blank\" rel=\"external\">http://{IP}:8500/v1/agent/check/register</a></p>\n<p>PUT<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;  </div><div class=\"line\">            &quot;http&quot;: &quot;http://192.168.1.200:8080/health?appId=app001&quot;,  </div><div class=\"line\">            &quot;interval&quot;: “20s&quot;,</div><div class=\"line\">            &quot;id&quot;: &quot;app001&quot;,</div><div class=\"line\">              &quot;name&quot;: &quot;Analytics YARN Application 001&quot;,</div><div class=\"line\">            &quot;applicationId&quot;:&quot;app001&quot;,</div><div class=\"line\">            &quot;service_id&quot;:&quot;Analytics_Job_Free_JobID0001&quot;</div><div class=\"line\">        &#125;</div><div class=\"line\"></div><div class=\"line\">&#123;  </div><div class=\"line\">            &quot;http&quot;: &quot;http://192.168.1.200:8080/health?appId=app002&quot;,  </div><div class=\"line\">            &quot;interval&quot;: “20s&quot;,</div><div class=\"line\">            &quot;id&quot;: &quot;app002&quot;,</div><div class=\"line\">              &quot;name&quot;: &quot;Analytics YARN Application 002&quot;,</div><div class=\"line\">            &quot;applicationId&quot;:&quot;app002”,</div><div class=\"line\">        &quot;status&quot;: &quot;passing&quot;,</div><div class=\"line\">            &quot;service_id&quot;:&quot;Analytics_Job_Free_JobID0001&quot;</div><div class=\"line\">        &#125;</div></pre></td></tr></table></figure></p>\n<h4 id=\"4-注销check\"><a href=\"#4-注销check\" class=\"headerlink\" title=\"4. 注销check\"></a>4. 注销check</h4><p><a href=\"http://{IP}:8500/v1/agent/check/deregister/app002\" target=\"_blank\" rel=\"external\">http://{IP}:8500/v1/agent/check/deregister/app002</a></p>\n<h3 id=\"例子\"><a href=\"#例子\" class=\"headerlink\" title=\"例子\"></a>例子</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;dependency&gt;</div><div class=\"line\">\t\t\t&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class=\"line\">\t\t\t&lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt;</div><div class=\"line\">\t\t\t&lt;version&gt;1.1.2.RELEASE&lt;/version&gt;</div><div class=\"line\">\t\t&lt;/dependency</div></pre></td></tr></table></figure>\n<p>application.properties<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">server.port=9955  </div><div class=\"line\"></div><div class=\"line\">spring.application.name=SampleClient</div><div class=\"line\">spring.cloud.consul.host=127.0.0.1</div><div class=\"line\">spring.cloud.consul.port=8500</div><div class=\"line\">spring.cloud.consul.enabled=true</div><div class=\"line\">spring.cloud.consul.discovery.register=false</div><div class=\"line\">spring.cloud.consul.discovery.enabled=true</div><div class=\"line\">spring.cloud.consul.discovery.instanceId=tomcat1</div><div class=\"line\">spring.cloud.consul.discovery.serviceName=tomcat1  </div><div class=\"line\">spring.cloud.consul.discovery.hostname=127.0.0.1</div><div class=\"line\">spring.cloud.consul.discovery.port=$&#123;server.port&#125;</div><div class=\"line\">spring.cloud.consul.discovery.healthCheckUrl=http://127.0.0.1:9955/health  </div><div class=\"line\">spring.cloud.consul.discovery.healthCheckInterval=10s  </div><div class=\"line\">spring.cloud.consul.discovery.tags=dev</div></pre></td></tr></table></figure></p>\n<p>application.yml<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">say-hello:</div><div class=\"line\"> ribbon:</div><div class=\"line\">  okhttp:</div><div class=\"line\">    enabled: true</div><div class=\"line\">```  </div><div class=\"line\">Enable</div></pre></td></tr></table></figure></p>\n<p>@SpringBootApplication<br>@EnableDiscoveryClient<br>@RibbonClient(name = “say-hello”, configuration = SayHelloConfiguration.class)<br>public class Application {<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">Full code</div></pre></td></tr></table></figure></p>\n<p>package hello;</p>\n<p>import org.springframework.beans.factory.annotation.Autowired;<br>import org.springframework.cloud.client.discovery.DiscoveryClient;<br>import org.springframework.cloud.client.loadbalancer.LoadBalanced;<br>import org.springframework.cloud.client.loadbalancer.LoadBalancerClient;<br>import org.springframework.context.annotation.Bean;<br>import org.springframework.web.bind.annotation.RequestMapping;<br>import org.springframework.web.bind.annotation.RestController;<br>import org.springframework.web.client.RestTemplate;</p>\n<p>@RestController<br>public class HelloController {</p>\n<p>  @Autowired<br>  private LoadBalancerClient loadBalancer;<br>  @Autowired<br>  private DiscoveryClient discoveryClient;</p>\n<p>  @LoadBalanced<br>  @Bean<br>  RestTemplate restTemplate() {<br>    return new RestTemplate();<br>  }</p>\n<p>  @Autowired<br>  RestTemplate restTemplate;</p>\n<p>  /**</p>\n<ul>\n<li><p>从所有服务中选择一个服务（轮询）<br>*/<br>@RequestMapping(“/discover”)<br>public Object discover() {<br>// return loadBalancer.choose(“application”).getUri().toString();<br>String greeting = this.restTemplate.getForObject(“<a href=\"http://application\" target=\"_blank\" rel=\"external\">http://application</a>“, String.class);<br>return String.format(“%s!”, greeting);<br>}</p>\n<p>@RequestMapping(“/d”)<br>public Object d() {<br>return loadBalancer.choose(“application”).getUri().toString();</p>\n<p>}</p>\n<p>/**</p>\n</li>\n<li>获取所有服务<br>*/<br>@RequestMapping(“/services”)<br>public Object services() {<br>return discoveryClient.getInstances(“application”).stream().findFirst().get().getUri();<br>}</li>\n</ul>\n<p>}</p>\n<p>```</p>\n"},{"title":"Gateway","_content":"\n![zuul](https://camo.githubusercontent.com/4eb7754152028cdebd5c09d1c6f5acc7683f0094/687474703a2f2f6e6574666c69782e6769746875622e696f2f7a75756c2f696d616765732f7a75756c2d726571756573742d6c6966656379636c652e706e67)\n","source":"_posts/gateway.md","raw":"---\ntitle: Gateway\n---\n\n![zuul](https://camo.githubusercontent.com/4eb7754152028cdebd5c09d1c6f5acc7683f0094/687474703a2f2f6e6574666c69782e6769746875622e696f2f7a75756c2f696d616765732f7a75756c2d726571756573742d6c6966656379636c652e706e67)\n","slug":"gateway","published":1,"date":"2017-05-04T07:40:07.000Z","updated":"2017-05-08T13:31:19.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj2g8ok3p0006dl72imxlzpr1","content":"<p><img src=\"https://camo.githubusercontent.com/4eb7754152028cdebd5c09d1c6f5acc7683f0094/687474703a2f2f6e6574666c69782e6769746875622e696f2f7a75756c2f696d616765732f7a75756c2d726571756573742d6c6966656379636c652e706e67\" alt=\"zuul\"></p>\n","site":{"data":{}},"excerpt":"","more":"<p><img src=\"https://camo.githubusercontent.com/4eb7754152028cdebd5c09d1c6f5acc7683f0094/687474703a2f2f6e6574666c69782e6769746875622e696f2f7a75756c2f696d616765732f7a75756c2d726571756573742d6c6966656379636c652e706e67\" alt=\"zuul\"></p>\n"},{"title":"分布式服务弹性框架","_content":"\n### Overview\n在复杂的分布式 架构 的应用程序有很多的依赖，都会不可避免地在某些时候失败。高并发的依赖失败时如果没有隔离措施，当前应用服务就有被拖垮的风险。\nHystrix 是Netflix开源的一个针对分布式系统的延迟和容错库，由Java写成。\n```Example\n例如:一个依赖30个SOA服务的系统,每个服务99.99%可用。\n99.99%的30次方 ≈ 99.7%\n0.3% 意味着一亿次请求 会有 3,000,00次失败\n换算成时间大约每月有2个小时服务不稳定.\n随着服务依赖数量的变多，服务不稳定的概率会成指数性提高.\n解决问题方案:对依赖做隔离,Hystrix就是处理依赖隔离的框架,同时也是可以帮我们做依赖服务的治理和监控.\n\n```\n\n1）Hystrix使用命令模式HystrixCommand(Command)包装依赖调用逻辑，每个命令在单独线程中/信号 授权 下执行\n\n2）提供熔断器组件,可以自动运行或手动调用,停止当前依赖一段时间(10秒)，熔断器默认 错误 率阈值为50%,超过将自动运行。\n\n3）可配置依赖调用 超时 时间,超时时间一般设为比99.5%平均时间略高即可.当调用超时时，直接返回或执行fallback逻辑。\n\n4）为每个依赖提供一个小的线程池（或信号），如果线程池已满调用将被立即拒绝，默认不采用排队.加速失败判定时间。\n\n5）依赖调用结果分:成功，失败（抛出 异常 ），超时，线程拒绝，短路。 请求失败(异常，拒绝，超时，短路)时执行fallback(降级)逻辑。\n\n![依赖架构](https://github.com/Netflix/Hystrix/wiki/images/soa-4-isolation-640.png)\n### 设计思想\nHystrixCommand.execute方法实际上是调用了HystrixCommand.queue().get()，而queue方法除了最终调用run之外，还需要为run方法提供超时和异常等保护功能，外部也不能直接调用非安全的run方法.\n\n1.Hystrix可以为分布式服务提供弹性保护\n\n2.Hystrix通过命令模式封装调用，来实现弹性保护，继承HystrixCommand并且实现run方法，就完成了最简单的封装。\n\n3.实现getFallBack方法可以为熔断或者异常提供后备处理方法。\n\n![Command设计模式](http://img2.tuicool.com/JrQNFzN.png!web)\n```Sample\npublic class CommandHelloWorld extends HystrixCommand<String> {\n\n  private final String name;\n\n  public CommandHelloWorld(String name) {\n    super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"HelloServiceGroup\"))\n        .andCommandPropertiesDefaults(HystrixCommandProperties.Setter().withExecutionTimeoutInMilliseconds(500)));\n    this.name = name;\n  }\n\n  @Override\n  protected String run() throws InterruptedException {\n    Thread.sleep(600);\n\n    return \"Hello \" + name + \"!\";\n  }\n\n  @Override\n  protected String getFallback() {\n    return String.format(\"[FallBack]Hello %s!\", name);\n  }\n}\n```\n\nEnable Hystrix in Spring Boot Application\n```\n@EnableHystrix\n@EnableHystrixDashboard\npublic class Application {\n```\n### How It works\n\n![9个步骤](https://github.com/Netflix/Hystrix/wiki/images/hystrix-command-flow-chart.png)\n\n流程说明:\n- 1:每次调用创建一个新的HystrixCommand,把依赖调用封装在run()方法中.\n- 2:执行execute()/queue做同步或异步调用.\n- 3:判断熔断器(circuit-breaker)是否打开,如果打开跳到步骤8,进行降级策略,如果关闭进入步骤.\n- 4:判断线程池/队列/信号量是否跑满，如果跑满进入降级步骤8,否则继续后续步骤.\n- 5:调用HystrixCommand的run方法.运行依赖逻辑\n - 5a:依赖逻辑调用超时,进入步骤8.\n- 6:判断逻辑是否调用成功\n - 6a:返回成功调用结果\n - 6b:调用出错，进入步骤8.\n- 7:计算熔断器状态,所有的运行状态(成功, 失败, 拒绝,超时)上报给熔断器，用于统计从而判断熔断器状态.\n- 8:getFallback()降级逻辑.\n  以下四种情况将触发getFallback调用：\n (1):run()方法抛出非HystrixBadRequestException异常。\n (2):run()方法调用超时\n (3):熔断器开启拦截调用\n (4):线程池/队列/信号量是否跑满\n - 8a:没有实现getFallback的Command将直接抛出异常\n - 8b:fallback降级逻辑调用成功直接返回\n - 8c:降级逻辑调用失败抛出异常\n- 9:返回执行成功结果\n\n### Circuit Breaker 流程架构和统计\n每个熔断器默认维护10个bucket,每秒一个bucket,每个blucket记录成功,失败,超时,拒绝的状态，\n默认错误超过50%且10秒内超过20个请求进行中断拦截.\n\n![](https://github.com/Netflix/Hystrix/wiki/images/circuit-breaker-640.png)\n\n### 隔离(Isolation)分析\n#### 线程隔离\n\n把执行依赖代码的线程与请求线程(如:jetty线程)分离，请求线程可以自由控制离开的时间(异步过程)。\n通过线程池大小可以控制并发量，当线程池饱和时可以提前拒绝服务,防止依赖问题扩散。\n线上建议线程池不要设置过大，否则大量堵塞线程有可能会拖慢服务器。\n- 线程隔离的优点:\n\n  - 使用线程可以完全隔离第三方代码,请求线程可以快速放回。当一个失败的依赖再次变成可用时，线程池将清理，并立即恢复可用，而不是一个长时间的恢复。\n - 可以完全模拟异步调用，方便异步编程。\n\n- 线程隔离的缺点:\n\n  - 线程池的主要缺点是它增加了cpu，因为每个命令的执行涉及到排队(默认使用SynchronousQueue避免排队)，调度和上下文切换。\n  - 对使用ThreadLocal等依赖线程状态的代码增加复杂性，需要手动传递和清理线程状态。\n\n  - NOTE: Netflix公司内部认为线程隔离开销足够小，不会造成重大的成本或性能的影响。\n  - Netflix 内部API 每天100亿的HystrixCommand依赖请求使用线程隔，每个应用大约40多个线程池，每个线程池大约5-20个线程。      \n\n#### 信号隔离\n信号隔离也可以用于限制并发访问，防止阻塞扩散, 与线程隔离最大不同在于执行依赖代码的线程依然是请求线程（该线程需要通过信号申请）.\n\n如果客户端是可信的且可以快速返回，可以使用信号隔离替换线程隔离,降低开销.\n信号量的大小可以动态调整, 线程池大小不可以.\n\n线程隔离与信号隔离区别如下图:\n\n![](https://github.com/Netflix/Hystrix/wiki/images/isolation-options-640.png)\n\n### Monitor Dashboard\n\nDocker Image for this dashboard:\n\n$ docker run -d -p 7979:7979 kennedyoliveira/hystrix-dashboard hystrix-dashboard\n\n在Hystrix Dashboard中输入Hystrix Stream: http://localhost:8080/hystrix.stream\n\n#### Hystrix 指标流(Hystrix Metrics Stream)\nTo enable the Hystrix metrics stream include a dependency on spring-boot-starter-actuator. This will expose the /hystrix.stream as a management endpoint.\n\n使Hystrix指标流包括依赖于spring-boot-starter-actuator。这将使/hystrix.stream流作为一个管理端点。\n```\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-actuator</artifactId>\n    </dependency>\n```\n#### 断路器: Hystrix 仪表盘(Circuit Breaker: Hystrix Dashboard)\n\nHystrix的主要作用是会采集每一个HystrixCommand的信息指标,把每一个断路器的信息指标显示的Hystrix仪表盘上。\n运行Hystrix仪表板需要在spring boot主类上标注@EnableHystrixDashboard。然后访问/hystrix查看仪表盘，在hystrix客户端应用使用/hystrix.stream监控。\n\n![dashboard](https://github.com/Netflix/Hystrix/wiki/images/dashboard-annoted-circuit-640.png)\n","source":"_posts/Hystrix.md","raw":"---\ntitle: 分布式服务弹性框架\n---\n\n### Overview\n在复杂的分布式 架构 的应用程序有很多的依赖，都会不可避免地在某些时候失败。高并发的依赖失败时如果没有隔离措施，当前应用服务就有被拖垮的风险。\nHystrix 是Netflix开源的一个针对分布式系统的延迟和容错库，由Java写成。\n```Example\n例如:一个依赖30个SOA服务的系统,每个服务99.99%可用。\n99.99%的30次方 ≈ 99.7%\n0.3% 意味着一亿次请求 会有 3,000,00次失败\n换算成时间大约每月有2个小时服务不稳定.\n随着服务依赖数量的变多，服务不稳定的概率会成指数性提高.\n解决问题方案:对依赖做隔离,Hystrix就是处理依赖隔离的框架,同时也是可以帮我们做依赖服务的治理和监控.\n\n```\n\n1）Hystrix使用命令模式HystrixCommand(Command)包装依赖调用逻辑，每个命令在单独线程中/信号 授权 下执行\n\n2）提供熔断器组件,可以自动运行或手动调用,停止当前依赖一段时间(10秒)，熔断器默认 错误 率阈值为50%,超过将自动运行。\n\n3）可配置依赖调用 超时 时间,超时时间一般设为比99.5%平均时间略高即可.当调用超时时，直接返回或执行fallback逻辑。\n\n4）为每个依赖提供一个小的线程池（或信号），如果线程池已满调用将被立即拒绝，默认不采用排队.加速失败判定时间。\n\n5）依赖调用结果分:成功，失败（抛出 异常 ），超时，线程拒绝，短路。 请求失败(异常，拒绝，超时，短路)时执行fallback(降级)逻辑。\n\n![依赖架构](https://github.com/Netflix/Hystrix/wiki/images/soa-4-isolation-640.png)\n### 设计思想\nHystrixCommand.execute方法实际上是调用了HystrixCommand.queue().get()，而queue方法除了最终调用run之外，还需要为run方法提供超时和异常等保护功能，外部也不能直接调用非安全的run方法.\n\n1.Hystrix可以为分布式服务提供弹性保护\n\n2.Hystrix通过命令模式封装调用，来实现弹性保护，继承HystrixCommand并且实现run方法，就完成了最简单的封装。\n\n3.实现getFallBack方法可以为熔断或者异常提供后备处理方法。\n\n![Command设计模式](http://img2.tuicool.com/JrQNFzN.png!web)\n```Sample\npublic class CommandHelloWorld extends HystrixCommand<String> {\n\n  private final String name;\n\n  public CommandHelloWorld(String name) {\n    super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"HelloServiceGroup\"))\n        .andCommandPropertiesDefaults(HystrixCommandProperties.Setter().withExecutionTimeoutInMilliseconds(500)));\n    this.name = name;\n  }\n\n  @Override\n  protected String run() throws InterruptedException {\n    Thread.sleep(600);\n\n    return \"Hello \" + name + \"!\";\n  }\n\n  @Override\n  protected String getFallback() {\n    return String.format(\"[FallBack]Hello %s!\", name);\n  }\n}\n```\n\nEnable Hystrix in Spring Boot Application\n```\n@EnableHystrix\n@EnableHystrixDashboard\npublic class Application {\n```\n### How It works\n\n![9个步骤](https://github.com/Netflix/Hystrix/wiki/images/hystrix-command-flow-chart.png)\n\n流程说明:\n- 1:每次调用创建一个新的HystrixCommand,把依赖调用封装在run()方法中.\n- 2:执行execute()/queue做同步或异步调用.\n- 3:判断熔断器(circuit-breaker)是否打开,如果打开跳到步骤8,进行降级策略,如果关闭进入步骤.\n- 4:判断线程池/队列/信号量是否跑满，如果跑满进入降级步骤8,否则继续后续步骤.\n- 5:调用HystrixCommand的run方法.运行依赖逻辑\n - 5a:依赖逻辑调用超时,进入步骤8.\n- 6:判断逻辑是否调用成功\n - 6a:返回成功调用结果\n - 6b:调用出错，进入步骤8.\n- 7:计算熔断器状态,所有的运行状态(成功, 失败, 拒绝,超时)上报给熔断器，用于统计从而判断熔断器状态.\n- 8:getFallback()降级逻辑.\n  以下四种情况将触发getFallback调用：\n (1):run()方法抛出非HystrixBadRequestException异常。\n (2):run()方法调用超时\n (3):熔断器开启拦截调用\n (4):线程池/队列/信号量是否跑满\n - 8a:没有实现getFallback的Command将直接抛出异常\n - 8b:fallback降级逻辑调用成功直接返回\n - 8c:降级逻辑调用失败抛出异常\n- 9:返回执行成功结果\n\n### Circuit Breaker 流程架构和统计\n每个熔断器默认维护10个bucket,每秒一个bucket,每个blucket记录成功,失败,超时,拒绝的状态，\n默认错误超过50%且10秒内超过20个请求进行中断拦截.\n\n![](https://github.com/Netflix/Hystrix/wiki/images/circuit-breaker-640.png)\n\n### 隔离(Isolation)分析\n#### 线程隔离\n\n把执行依赖代码的线程与请求线程(如:jetty线程)分离，请求线程可以自由控制离开的时间(异步过程)。\n通过线程池大小可以控制并发量，当线程池饱和时可以提前拒绝服务,防止依赖问题扩散。\n线上建议线程池不要设置过大，否则大量堵塞线程有可能会拖慢服务器。\n- 线程隔离的优点:\n\n  - 使用线程可以完全隔离第三方代码,请求线程可以快速放回。当一个失败的依赖再次变成可用时，线程池将清理，并立即恢复可用，而不是一个长时间的恢复。\n - 可以完全模拟异步调用，方便异步编程。\n\n- 线程隔离的缺点:\n\n  - 线程池的主要缺点是它增加了cpu，因为每个命令的执行涉及到排队(默认使用SynchronousQueue避免排队)，调度和上下文切换。\n  - 对使用ThreadLocal等依赖线程状态的代码增加复杂性，需要手动传递和清理线程状态。\n\n  - NOTE: Netflix公司内部认为线程隔离开销足够小，不会造成重大的成本或性能的影响。\n  - Netflix 内部API 每天100亿的HystrixCommand依赖请求使用线程隔，每个应用大约40多个线程池，每个线程池大约5-20个线程。      \n\n#### 信号隔离\n信号隔离也可以用于限制并发访问，防止阻塞扩散, 与线程隔离最大不同在于执行依赖代码的线程依然是请求线程（该线程需要通过信号申请）.\n\n如果客户端是可信的且可以快速返回，可以使用信号隔离替换线程隔离,降低开销.\n信号量的大小可以动态调整, 线程池大小不可以.\n\n线程隔离与信号隔离区别如下图:\n\n![](https://github.com/Netflix/Hystrix/wiki/images/isolation-options-640.png)\n\n### Monitor Dashboard\n\nDocker Image for this dashboard:\n\n$ docker run -d -p 7979:7979 kennedyoliveira/hystrix-dashboard hystrix-dashboard\n\n在Hystrix Dashboard中输入Hystrix Stream: http://localhost:8080/hystrix.stream\n\n#### Hystrix 指标流(Hystrix Metrics Stream)\nTo enable the Hystrix metrics stream include a dependency on spring-boot-starter-actuator. This will expose the /hystrix.stream as a management endpoint.\n\n使Hystrix指标流包括依赖于spring-boot-starter-actuator。这将使/hystrix.stream流作为一个管理端点。\n```\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-actuator</artifactId>\n    </dependency>\n```\n#### 断路器: Hystrix 仪表盘(Circuit Breaker: Hystrix Dashboard)\n\nHystrix的主要作用是会采集每一个HystrixCommand的信息指标,把每一个断路器的信息指标显示的Hystrix仪表盘上。\n运行Hystrix仪表板需要在spring boot主类上标注@EnableHystrixDashboard。然后访问/hystrix查看仪表盘，在hystrix客户端应用使用/hystrix.stream监控。\n\n![dashboard](https://github.com/Netflix/Hystrix/wiki/images/dashboard-annoted-circuit-640.png)\n","slug":"Hystrix","published":1,"date":"2017-03-07T16:20:17.000Z","updated":"2017-05-08T13:31:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj2g8ok3s0008dl72aoj7trp5","content":"<h3 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h3><p>在复杂的分布式 架构 的应用程序有很多的依赖，都会不可避免地在某些时候失败。高并发的依赖失败时如果没有隔离措施，当前应用服务就有被拖垮的风险。<br>Hystrix 是Netflix开源的一个针对分布式系统的延迟和容错库，由Java写成。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">例如:一个依赖30个SOA服务的系统,每个服务99.99%可用。</div><div class=\"line\">99.99%的30次方 ≈ 99.7%</div><div class=\"line\">0.3% 意味着一亿次请求 会有 3,000,00次失败</div><div class=\"line\">换算成时间大约每月有2个小时服务不稳定.</div><div class=\"line\">随着服务依赖数量的变多，服务不稳定的概率会成指数性提高.</div><div class=\"line\">解决问题方案:对依赖做隔离,Hystrix就是处理依赖隔离的框架,同时也是可以帮我们做依赖服务的治理和监控.</div></pre></td></tr></table></figure></p>\n<p>1）Hystrix使用命令模式HystrixCommand(Command)包装依赖调用逻辑，每个命令在单独线程中/信号 授权 下执行</p>\n<p>2）提供熔断器组件,可以自动运行或手动调用,停止当前依赖一段时间(10秒)，熔断器默认 错误 率阈值为50%,超过将自动运行。</p>\n<p>3）可配置依赖调用 超时 时间,超时时间一般设为比99.5%平均时间略高即可.当调用超时时，直接返回或执行fallback逻辑。</p>\n<p>4）为每个依赖提供一个小的线程池（或信号），如果线程池已满调用将被立即拒绝，默认不采用排队.加速失败判定时间。</p>\n<p>5）依赖调用结果分:成功，失败（抛出 异常 ），超时，线程拒绝，短路。 请求失败(异常，拒绝，超时，短路)时执行fallback(降级)逻辑。</p>\n<p><img src=\"https://github.com/Netflix/Hystrix/wiki/images/soa-4-isolation-640.png\" alt=\"依赖架构\"></p>\n<h3 id=\"设计思想\"><a href=\"#设计思想\" class=\"headerlink\" title=\"设计思想\"></a>设计思想</h3><p>HystrixCommand.execute方法实际上是调用了HystrixCommand.queue().get()，而queue方法除了最终调用run之外，还需要为run方法提供超时和异常等保护功能，外部也不能直接调用非安全的run方法.</p>\n<p>1.Hystrix可以为分布式服务提供弹性保护</p>\n<p>2.Hystrix通过命令模式封装调用，来实现弹性保护，继承HystrixCommand并且实现run方法，就完成了最简单的封装。</p>\n<p>3.实现getFallBack方法可以为熔断或者异常提供后备处理方法。</p>\n<p><img src=\"http://img2.tuicool.com/JrQNFzN.png!web\" alt=\"Command设计模式\"><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div></pre></td><td class=\"code\"><pre><div class=\"line\">public class CommandHelloWorld extends HystrixCommand&lt;String&gt; &#123;</div><div class=\"line\"></div><div class=\"line\">  private final String name;</div><div class=\"line\"></div><div class=\"line\">  public CommandHelloWorld(String name) &#123;</div><div class=\"line\">    super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(&quot;HelloServiceGroup&quot;))</div><div class=\"line\">        .andCommandPropertiesDefaults(HystrixCommandProperties.Setter().withExecutionTimeoutInMilliseconds(500)));</div><div class=\"line\">    this.name = name;</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  @Override</div><div class=\"line\">  protected String run() throws InterruptedException &#123;</div><div class=\"line\">    Thread.sleep(600);</div><div class=\"line\"></div><div class=\"line\">    return &quot;Hello &quot; + name + &quot;!&quot;;</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  @Override</div><div class=\"line\">  protected String getFallback() &#123;</div><div class=\"line\">    return String.format(&quot;[FallBack]Hello %s!&quot;, name);</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>Enable Hystrix in Spring Boot Application<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">@EnableHystrix</div><div class=\"line\">@EnableHystrixDashboard</div><div class=\"line\">public class Application &#123;</div></pre></td></tr></table></figure></p>\n<h3 id=\"How-It-works\"><a href=\"#How-It-works\" class=\"headerlink\" title=\"How It works\"></a>How It works</h3><p><img src=\"https://github.com/Netflix/Hystrix/wiki/images/hystrix-command-flow-chart.png\" alt=\"9个步骤\"></p>\n<p>流程说明:</p>\n<ul>\n<li>1:每次调用创建一个新的HystrixCommand,把依赖调用封装在run()方法中.</li>\n<li>2:执行execute()/queue做同步或异步调用.</li>\n<li>3:判断熔断器(circuit-breaker)是否打开,如果打开跳到步骤8,进行降级策略,如果关闭进入步骤.</li>\n<li>4:判断线程池/队列/信号量是否跑满，如果跑满进入降级步骤8,否则继续后续步骤.</li>\n<li>5:调用HystrixCommand的run方法.运行依赖逻辑<ul>\n<li>5a:依赖逻辑调用超时,进入步骤8.</li>\n</ul>\n</li>\n<li>6:判断逻辑是否调用成功<ul>\n<li>6a:返回成功调用结果</li>\n<li>6b:调用出错，进入步骤8.</li>\n</ul>\n</li>\n<li>7:计算熔断器状态,所有的运行状态(成功, 失败, 拒绝,超时)上报给熔断器，用于统计从而判断熔断器状态.</li>\n<li>8:getFallback()降级逻辑.<br>以下四种情况将触发getFallback调用：<br>(1):run()方法抛出非HystrixBadRequestException异常。<br>(2):run()方法调用超时<br>(3):熔断器开启拦截调用<br>(4):线程池/队列/信号量是否跑满<ul>\n<li>8a:没有实现getFallback的Command将直接抛出异常</li>\n<li>8b:fallback降级逻辑调用成功直接返回</li>\n<li>8c:降级逻辑调用失败抛出异常</li>\n</ul>\n</li>\n<li>9:返回执行成功结果</li>\n</ul>\n<h3 id=\"Circuit-Breaker-流程架构和统计\"><a href=\"#Circuit-Breaker-流程架构和统计\" class=\"headerlink\" title=\"Circuit Breaker 流程架构和统计\"></a>Circuit Breaker 流程架构和统计</h3><p>每个熔断器默认维护10个bucket,每秒一个bucket,每个blucket记录成功,失败,超时,拒绝的状态，<br>默认错误超过50%且10秒内超过20个请求进行中断拦截.</p>\n<p><img src=\"https://github.com/Netflix/Hystrix/wiki/images/circuit-breaker-640.png\" alt=\"\"></p>\n<h3 id=\"隔离-Isolation-分析\"><a href=\"#隔离-Isolation-分析\" class=\"headerlink\" title=\"隔离(Isolation)分析\"></a>隔离(Isolation)分析</h3><h4 id=\"线程隔离\"><a href=\"#线程隔离\" class=\"headerlink\" title=\"线程隔离\"></a>线程隔离</h4><p>把执行依赖代码的线程与请求线程(如:jetty线程)分离，请求线程可以自由控制离开的时间(异步过程)。<br>通过线程池大小可以控制并发量，当线程池饱和时可以提前拒绝服务,防止依赖问题扩散。<br>线上建议线程池不要设置过大，否则大量堵塞线程有可能会拖慢服务器。</p>\n<ul>\n<li><p>线程隔离的优点:</p>\n<ul>\n<li>使用线程可以完全隔离第三方代码,请求线程可以快速放回。当一个失败的依赖再次变成可用时，线程池将清理，并立即恢复可用，而不是一个长时间的恢复。</li>\n<li>可以完全模拟异步调用，方便异步编程。</li>\n</ul>\n</li>\n<li><p>线程隔离的缺点:</p>\n<ul>\n<li>线程池的主要缺点是它增加了cpu，因为每个命令的执行涉及到排队(默认使用SynchronousQueue避免排队)，调度和上下文切换。</li>\n<li><p>对使用ThreadLocal等依赖线程状态的代码增加复杂性，需要手动传递和清理线程状态。</p>\n</li>\n<li><p>NOTE: Netflix公司内部认为线程隔离开销足够小，不会造成重大的成本或性能的影响。</p>\n</li>\n<li>Netflix 内部API 每天100亿的HystrixCommand依赖请求使用线程隔，每个应用大约40多个线程池，每个线程池大约5-20个线程。      </li>\n</ul>\n</li>\n</ul>\n<h4 id=\"信号隔离\"><a href=\"#信号隔离\" class=\"headerlink\" title=\"信号隔离\"></a>信号隔离</h4><p>信号隔离也可以用于限制并发访问，防止阻塞扩散, 与线程隔离最大不同在于执行依赖代码的线程依然是请求线程（该线程需要通过信号申请）.</p>\n<p>如果客户端是可信的且可以快速返回，可以使用信号隔离替换线程隔离,降低开销.<br>信号量的大小可以动态调整, 线程池大小不可以.</p>\n<p>线程隔离与信号隔离区别如下图:</p>\n<p><img src=\"https://github.com/Netflix/Hystrix/wiki/images/isolation-options-640.png\" alt=\"\"></p>\n<h3 id=\"Monitor-Dashboard\"><a href=\"#Monitor-Dashboard\" class=\"headerlink\" title=\"Monitor Dashboard\"></a>Monitor Dashboard</h3><p>Docker Image for this dashboard:</p>\n<p>$ docker run -d -p 7979:7979 kennedyoliveira/hystrix-dashboard hystrix-dashboard</p>\n<p>在Hystrix Dashboard中输入Hystrix Stream: <a href=\"http://localhost:8080/hystrix.stream\" target=\"_blank\" rel=\"external\">http://localhost:8080/hystrix.stream</a></p>\n<h4 id=\"Hystrix-指标流-Hystrix-Metrics-Stream\"><a href=\"#Hystrix-指标流-Hystrix-Metrics-Stream\" class=\"headerlink\" title=\"Hystrix 指标流(Hystrix Metrics Stream)\"></a>Hystrix 指标流(Hystrix Metrics Stream)</h4><p>To enable the Hystrix metrics stream include a dependency on spring-boot-starter-actuator. This will expose the /hystrix.stream as a management endpoint.</p>\n<p>使Hystrix指标流包括依赖于spring-boot-starter-actuator。这将使/hystrix.stream流作为一个管理端点。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;dependency&gt;</div><div class=\"line\">    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class=\"line\">    &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;</div><div class=\"line\">&lt;/dependency&gt;</div></pre></td></tr></table></figure></p>\n<h4 id=\"断路器-Hystrix-仪表盘-Circuit-Breaker-Hystrix-Dashboard\"><a href=\"#断路器-Hystrix-仪表盘-Circuit-Breaker-Hystrix-Dashboard\" class=\"headerlink\" title=\"断路器: Hystrix 仪表盘(Circuit Breaker: Hystrix Dashboard)\"></a>断路器: Hystrix 仪表盘(Circuit Breaker: Hystrix Dashboard)</h4><p>Hystrix的主要作用是会采集每一个HystrixCommand的信息指标,把每一个断路器的信息指标显示的Hystrix仪表盘上。<br>运行Hystrix仪表板需要在spring boot主类上标注@EnableHystrixDashboard。然后访问/hystrix查看仪表盘，在hystrix客户端应用使用/hystrix.stream监控。</p>\n<p><img src=\"https://github.com/Netflix/Hystrix/wiki/images/dashboard-annoted-circuit-640.png\" alt=\"dashboard\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h3><p>在复杂的分布式 架构 的应用程序有很多的依赖，都会不可避免地在某些时候失败。高并发的依赖失败时如果没有隔离措施，当前应用服务就有被拖垮的风险。<br>Hystrix 是Netflix开源的一个针对分布式系统的延迟和容错库，由Java写成。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">例如:一个依赖30个SOA服务的系统,每个服务99.99%可用。</div><div class=\"line\">99.99%的30次方 ≈ 99.7%</div><div class=\"line\">0.3% 意味着一亿次请求 会有 3,000,00次失败</div><div class=\"line\">换算成时间大约每月有2个小时服务不稳定.</div><div class=\"line\">随着服务依赖数量的变多，服务不稳定的概率会成指数性提高.</div><div class=\"line\">解决问题方案:对依赖做隔离,Hystrix就是处理依赖隔离的框架,同时也是可以帮我们做依赖服务的治理和监控.</div></pre></td></tr></table></figure></p>\n<p>1）Hystrix使用命令模式HystrixCommand(Command)包装依赖调用逻辑，每个命令在单独线程中/信号 授权 下执行</p>\n<p>2）提供熔断器组件,可以自动运行或手动调用,停止当前依赖一段时间(10秒)，熔断器默认 错误 率阈值为50%,超过将自动运行。</p>\n<p>3）可配置依赖调用 超时 时间,超时时间一般设为比99.5%平均时间略高即可.当调用超时时，直接返回或执行fallback逻辑。</p>\n<p>4）为每个依赖提供一个小的线程池（或信号），如果线程池已满调用将被立即拒绝，默认不采用排队.加速失败判定时间。</p>\n<p>5）依赖调用结果分:成功，失败（抛出 异常 ），超时，线程拒绝，短路。 请求失败(异常，拒绝，超时，短路)时执行fallback(降级)逻辑。</p>\n<p><img src=\"https://github.com/Netflix/Hystrix/wiki/images/soa-4-isolation-640.png\" alt=\"依赖架构\"></p>\n<h3 id=\"设计思想\"><a href=\"#设计思想\" class=\"headerlink\" title=\"设计思想\"></a>设计思想</h3><p>HystrixCommand.execute方法实际上是调用了HystrixCommand.queue().get()，而queue方法除了最终调用run之外，还需要为run方法提供超时和异常等保护功能，外部也不能直接调用非安全的run方法.</p>\n<p>1.Hystrix可以为分布式服务提供弹性保护</p>\n<p>2.Hystrix通过命令模式封装调用，来实现弹性保护，继承HystrixCommand并且实现run方法，就完成了最简单的封装。</p>\n<p>3.实现getFallBack方法可以为熔断或者异常提供后备处理方法。</p>\n<p><img src=\"http://img2.tuicool.com/JrQNFzN.png!web\" alt=\"Command设计模式\"><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div></pre></td><td class=\"code\"><pre><div class=\"line\">public class CommandHelloWorld extends HystrixCommand&lt;String&gt; &#123;</div><div class=\"line\"></div><div class=\"line\">  private final String name;</div><div class=\"line\"></div><div class=\"line\">  public CommandHelloWorld(String name) &#123;</div><div class=\"line\">    super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(&quot;HelloServiceGroup&quot;))</div><div class=\"line\">        .andCommandPropertiesDefaults(HystrixCommandProperties.Setter().withExecutionTimeoutInMilliseconds(500)));</div><div class=\"line\">    this.name = name;</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  @Override</div><div class=\"line\">  protected String run() throws InterruptedException &#123;</div><div class=\"line\">    Thread.sleep(600);</div><div class=\"line\"></div><div class=\"line\">    return &quot;Hello &quot; + name + &quot;!&quot;;</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  @Override</div><div class=\"line\">  protected String getFallback() &#123;</div><div class=\"line\">    return String.format(&quot;[FallBack]Hello %s!&quot;, name);</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>Enable Hystrix in Spring Boot Application<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">@EnableHystrix</div><div class=\"line\">@EnableHystrixDashboard</div><div class=\"line\">public class Application &#123;</div></pre></td></tr></table></figure></p>\n<h3 id=\"How-It-works\"><a href=\"#How-It-works\" class=\"headerlink\" title=\"How It works\"></a>How It works</h3><p><img src=\"https://github.com/Netflix/Hystrix/wiki/images/hystrix-command-flow-chart.png\" alt=\"9个步骤\"></p>\n<p>流程说明:</p>\n<ul>\n<li>1:每次调用创建一个新的HystrixCommand,把依赖调用封装在run()方法中.</li>\n<li>2:执行execute()/queue做同步或异步调用.</li>\n<li>3:判断熔断器(circuit-breaker)是否打开,如果打开跳到步骤8,进行降级策略,如果关闭进入步骤.</li>\n<li>4:判断线程池/队列/信号量是否跑满，如果跑满进入降级步骤8,否则继续后续步骤.</li>\n<li>5:调用HystrixCommand的run方法.运行依赖逻辑<ul>\n<li>5a:依赖逻辑调用超时,进入步骤8.</li>\n</ul>\n</li>\n<li>6:判断逻辑是否调用成功<ul>\n<li>6a:返回成功调用结果</li>\n<li>6b:调用出错，进入步骤8.</li>\n</ul>\n</li>\n<li>7:计算熔断器状态,所有的运行状态(成功, 失败, 拒绝,超时)上报给熔断器，用于统计从而判断熔断器状态.</li>\n<li>8:getFallback()降级逻辑.<br>以下四种情况将触发getFallback调用：<br>(1):run()方法抛出非HystrixBadRequestException异常。<br>(2):run()方法调用超时<br>(3):熔断器开启拦截调用<br>(4):线程池/队列/信号量是否跑满<ul>\n<li>8a:没有实现getFallback的Command将直接抛出异常</li>\n<li>8b:fallback降级逻辑调用成功直接返回</li>\n<li>8c:降级逻辑调用失败抛出异常</li>\n</ul>\n</li>\n<li>9:返回执行成功结果</li>\n</ul>\n<h3 id=\"Circuit-Breaker-流程架构和统计\"><a href=\"#Circuit-Breaker-流程架构和统计\" class=\"headerlink\" title=\"Circuit Breaker 流程架构和统计\"></a>Circuit Breaker 流程架构和统计</h3><p>每个熔断器默认维护10个bucket,每秒一个bucket,每个blucket记录成功,失败,超时,拒绝的状态，<br>默认错误超过50%且10秒内超过20个请求进行中断拦截.</p>\n<p><img src=\"https://github.com/Netflix/Hystrix/wiki/images/circuit-breaker-640.png\" alt=\"\"></p>\n<h3 id=\"隔离-Isolation-分析\"><a href=\"#隔离-Isolation-分析\" class=\"headerlink\" title=\"隔离(Isolation)分析\"></a>隔离(Isolation)分析</h3><h4 id=\"线程隔离\"><a href=\"#线程隔离\" class=\"headerlink\" title=\"线程隔离\"></a>线程隔离</h4><p>把执行依赖代码的线程与请求线程(如:jetty线程)分离，请求线程可以自由控制离开的时间(异步过程)。<br>通过线程池大小可以控制并发量，当线程池饱和时可以提前拒绝服务,防止依赖问题扩散。<br>线上建议线程池不要设置过大，否则大量堵塞线程有可能会拖慢服务器。</p>\n<ul>\n<li><p>线程隔离的优点:</p>\n<ul>\n<li>使用线程可以完全隔离第三方代码,请求线程可以快速放回。当一个失败的依赖再次变成可用时，线程池将清理，并立即恢复可用，而不是一个长时间的恢复。</li>\n<li>可以完全模拟异步调用，方便异步编程。</li>\n</ul>\n</li>\n<li><p>线程隔离的缺点:</p>\n<ul>\n<li>线程池的主要缺点是它增加了cpu，因为每个命令的执行涉及到排队(默认使用SynchronousQueue避免排队)，调度和上下文切换。</li>\n<li><p>对使用ThreadLocal等依赖线程状态的代码增加复杂性，需要手动传递和清理线程状态。</p>\n</li>\n<li><p>NOTE: Netflix公司内部认为线程隔离开销足够小，不会造成重大的成本或性能的影响。</p>\n</li>\n<li>Netflix 内部API 每天100亿的HystrixCommand依赖请求使用线程隔，每个应用大约40多个线程池，每个线程池大约5-20个线程。      </li>\n</ul>\n</li>\n</ul>\n<h4 id=\"信号隔离\"><a href=\"#信号隔离\" class=\"headerlink\" title=\"信号隔离\"></a>信号隔离</h4><p>信号隔离也可以用于限制并发访问，防止阻塞扩散, 与线程隔离最大不同在于执行依赖代码的线程依然是请求线程（该线程需要通过信号申请）.</p>\n<p>如果客户端是可信的且可以快速返回，可以使用信号隔离替换线程隔离,降低开销.<br>信号量的大小可以动态调整, 线程池大小不可以.</p>\n<p>线程隔离与信号隔离区别如下图:</p>\n<p><img src=\"https://github.com/Netflix/Hystrix/wiki/images/isolation-options-640.png\" alt=\"\"></p>\n<h3 id=\"Monitor-Dashboard\"><a href=\"#Monitor-Dashboard\" class=\"headerlink\" title=\"Monitor Dashboard\"></a>Monitor Dashboard</h3><p>Docker Image for this dashboard:</p>\n<p>$ docker run -d -p 7979:7979 kennedyoliveira/hystrix-dashboard hystrix-dashboard</p>\n<p>在Hystrix Dashboard中输入Hystrix Stream: <a href=\"http://localhost:8080/hystrix.stream\" target=\"_blank\" rel=\"external\">http://localhost:8080/hystrix.stream</a></p>\n<h4 id=\"Hystrix-指标流-Hystrix-Metrics-Stream\"><a href=\"#Hystrix-指标流-Hystrix-Metrics-Stream\" class=\"headerlink\" title=\"Hystrix 指标流(Hystrix Metrics Stream)\"></a>Hystrix 指标流(Hystrix Metrics Stream)</h4><p>To enable the Hystrix metrics stream include a dependency on spring-boot-starter-actuator. This will expose the /hystrix.stream as a management endpoint.</p>\n<p>使Hystrix指标流包括依赖于spring-boot-starter-actuator。这将使/hystrix.stream流作为一个管理端点。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;dependency&gt;</div><div class=\"line\">    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class=\"line\">    &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;</div><div class=\"line\">&lt;/dependency&gt;</div></pre></td></tr></table></figure></p>\n<h4 id=\"断路器-Hystrix-仪表盘-Circuit-Breaker-Hystrix-Dashboard\"><a href=\"#断路器-Hystrix-仪表盘-Circuit-Breaker-Hystrix-Dashboard\" class=\"headerlink\" title=\"断路器: Hystrix 仪表盘(Circuit Breaker: Hystrix Dashboard)\"></a>断路器: Hystrix 仪表盘(Circuit Breaker: Hystrix Dashboard)</h4><p>Hystrix的主要作用是会采集每一个HystrixCommand的信息指标,把每一个断路器的信息指标显示的Hystrix仪表盘上。<br>运行Hystrix仪表板需要在spring boot主类上标注@EnableHystrixDashboard。然后访问/hystrix查看仪表盘，在hystrix客户端应用使用/hystrix.stream监控。</p>\n<p><img src=\"https://github.com/Netflix/Hystrix/wiki/images/dashboard-annoted-circuit-640.png\" alt=\"dashboard\"></p>\n"},{"title":"Kafka","_content":"\n![](http://kafka.apache.org/images/logo.png)\n\n### kafka\n\n1. Kafka Connect\n    - Overview (http://kafka.apache.org/documentation/#connect)\n    - User Guide\n    - Connector Development Guide\n\n2. Kafka Streams\n\n    - Overview\n    - Core Concepts\n    - Architecture\n    ![](http://kafka.apache.org/0102/images/streams-architecture-overview.jpg)\n    - Developer Guide\n        - Low-Level Processor API\n        - High-Level Streams DSL\n        - Application Configuration and Execution\n    - Upgrade Guide and API Changes\n","source":"_posts/kafka.md","raw":"---\ntitle: Kafka\n---\n\n![](http://kafka.apache.org/images/logo.png)\n\n### kafka\n\n1. Kafka Connect\n    - Overview (http://kafka.apache.org/documentation/#connect)\n    - User Guide\n    - Connector Development Guide\n\n2. Kafka Streams\n\n    - Overview\n    - Core Concepts\n    - Architecture\n    ![](http://kafka.apache.org/0102/images/streams-architecture-overview.jpg)\n    - Developer Guide\n        - Low-Level Processor API\n        - High-Level Streams DSL\n        - Application Configuration and Execution\n    - Upgrade Guide and API Changes\n","slug":"kafka","published":1,"date":"2017-03-31T16:29:17.000Z","updated":"2017-05-08T13:31:54.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj2g8ok3u0009dl726ae76s39","content":"<p><img src=\"http://kafka.apache.org/images/logo.png\" alt=\"\"></p>\n<h3 id=\"kafka\"><a href=\"#kafka\" class=\"headerlink\" title=\"kafka\"></a>kafka</h3><ol>\n<li><p>Kafka Connect</p>\n<ul>\n<li>Overview (<a href=\"http://kafka.apache.org/documentation/#connect\" target=\"_blank\" rel=\"external\">http://kafka.apache.org/documentation/#connect</a>)</li>\n<li>User Guide</li>\n<li>Connector Development Guide</li>\n</ul>\n</li>\n<li><p>Kafka Streams</p>\n<ul>\n<li>Overview</li>\n<li>Core Concepts</li>\n<li>Architecture<br><img src=\"http://kafka.apache.org/0102/images/streams-architecture-overview.jpg\" alt=\"\"></li>\n<li>Developer Guide<ul>\n<li>Low-Level Processor API</li>\n<li>High-Level Streams DSL</li>\n<li>Application Configuration and Execution</li>\n</ul>\n</li>\n<li>Upgrade Guide and API Changes</li>\n</ul>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<p><img src=\"http://kafka.apache.org/images/logo.png\" alt=\"\"></p>\n<h3 id=\"kafka\"><a href=\"#kafka\" class=\"headerlink\" title=\"kafka\"></a>kafka</h3><ol>\n<li><p>Kafka Connect</p>\n<ul>\n<li>Overview (<a href=\"http://kafka.apache.org/documentation/#connect\" target=\"_blank\" rel=\"external\">http://kafka.apache.org/documentation/#connect</a>)</li>\n<li>User Guide</li>\n<li>Connector Development Guide</li>\n</ul>\n</li>\n<li><p>Kafka Streams</p>\n<ul>\n<li>Overview</li>\n<li>Core Concepts</li>\n<li>Architecture<br><img src=\"http://kafka.apache.org/0102/images/streams-architecture-overview.jpg\" alt=\"\"></li>\n<li>Developer Guide<ul>\n<li>Low-Level Processor API</li>\n<li>High-Level Streams DSL</li>\n<li>Application Configuration and Execution</li>\n</ul>\n</li>\n<li>Upgrade Guide and API Changes</li>\n</ul>\n</li>\n</ol>\n"},{"title":"HDFS","_content":"\n## 简介\nHDFS（Hadoop Distributed File System ）Hadoop分布式文件系统。是根据google发表的论文翻版的。论文为GFS（Google File System）Google 文件系统（中文，英文）。\n\nHDFS有很多特点：\n-    ① 保存多个副本，且提供容错机制，副本丢失或宕机自动恢复。默认存3份。\n-    ② 运行在廉价的机器上。\n-    ③ 适合大数据的处理。多大？多小？HDFS默认会将文件分割成block，64M为1个block。然后将block按键值对存储在HDFS上，并将键值对的映射存到内存中。如果小文件太多，那内存的负担会很重。\n\n![hdfs1](images/hdfs1.jpg)\n如上图所示，HDFS也是按照Master和Slave的结构。分NameNode、SecondaryNameNode、DataNode这几个角色。\n\n- NameNode：是Master节点，是大领导。管理数据块映射；处理客户端的读写请求；配置副本策略；管理HDFS的名称空间；\n- SecondaryNameNode：是一个小弟，分担大哥namenode的工作量；是NameNode的冷备份；合并fsimage和fsedits然后再发给namenode。\n- DataNode：Slave节点，奴隶，干活的。负责存储client发来的数据块block；执行数据块的读写操作。\n- 热备份：b是a的热备份，如果a坏掉。那么b马上运行代替a的工作。\n- 冷备份：b是a的冷备份，如果a坏掉。那么b不能马上代替a工作。但是b上存储a的一些信息，减少a坏掉之后的损失。\n- fsimage:元数据镜像文件（文件系统的目录树。）\n- edits：元数据的操作日志（针对文件系统做的修改操作记录）\n\nNamenode内存中存储的是=fsimage+edits。\n\nSecondaryNameNode负责定时默认1小时，从namenode上，获取fsimage和edits来进行合并，然后再发送给namenode。减少namenode的工作量。\n\n## HDFS写操作\n有一个文件FileA，100M大小。Client将FileA写入到HDFS上。HDFS按默认配置。HDFS分布在三个机架上Rack1，Rack2，Rack3。\n![hdfs-write](images/hdfs-write.jpg)\n- a. Client将FileA按64M分块。分成两块，block1和Block2;\n- b. Client向nameNode发送写数据请求，如图蓝色虚线①------>。\n- c. NameNode节点，记录block信息。并返回可用的DataNode，如粉色虚线②--------->。\n\n    Block1: host2,host1,host3\n\n    Block2: host7,host8,host4\n\n    原理：\n\n        NameNode具有RackAware机架感知功能，这个可以配置。\n        若client为DataNode节点，那存储block时，规则为：副本1，同client的节点上；副本2，不同机架节点上；副本3，同第二个副本机架的另一个节点上；其他副本随机挑选。\n        若client不为DataNode节点，那存储block时，规则为：副本1，随机选择一个节点上；副本2，不同副本1，机架上；副本3，同副本2相同的另一个节点上；其他副本随机挑选。\n\n- d. client向DataNode发送block1；发送过程是以流式写入。\n\n    流式写入过程，\n\n        1>将64M的block1按64k的package划分;\n\n        2>然后将第一个package发送给host2;\n\n        3>host2接收完后，将第一个package发送给host1，同时client想host2发送第二个package；\n\n        4>host1接收完第一个package后，发送给host3，同时接收host2发来的第二个package。\n\n        5>以此类推，如图红线实线所示，直到将block1发送完毕。\n\n        6>host2,host1,host3向NameNode，host2向Client发送通知，说“消息发送完了”。如图粉红颜色实线所示。\n\n        7>client收到host2发来的消息后，向namenode发送消息，说我写完了。这样就真完成了。如图黄色粗实线\n\n        8>发送完block1后，再向host7，host8，host4发送block2，如图蓝色实线所示。\n\n        9>发送完block2后，host7,host8,host4向NameNode，host7向Client发送通知，如图浅绿色实线所示。\n\n        10>client向NameNode发送消息，说我写完了，如图黄色粗实线。。。这样就完毕了。\n\n分析，通过写过程，我们可以了解到：\n\n    ①写1T文件，我们需要3T的存储，3T的网络流量贷款。\n\n    ②在执行读或写的过程中，NameNode和DataNode通过HeartBeat进行保存通信，确定DataNode活着。如果发现DataNode死掉了，就将死掉的DataNode上的数据，放到其他节点去。读取时，要读其他节点去。\n\n    ③挂掉一个节点，没关系，还有其他节点可以备份；甚至，挂掉某一个机架，也没关系；其他机架上，也有备份。\n\n## HDFS读操作\n![hdfs-read](images/hdfs-read.jpg)\n\n读操作就简单一些了，如图所示，client要从datanode上，读取FileA。而FileA由block1和block2组成。\n\n\n\n那么，读操作流程为：\n\na. client向namenode发送读请求。\n\nb. namenode查看Metadata信息，返回fileA的block的位置。\n\n    block1:host2,host1,host3\n\n    block2:host7,host8,host4\n\nc. block的位置是有先后顺序的，先读block1，再读block2。而且block1去host2上读取；然后block2，去host7上读取；\n\n\n\n上面例子中，client位于机架外，那么如果client位于机架内某个DataNode上，例如,client是host6。那么读取的时候，遵循的规律是：\n\n优选读取本机架上的数据。\n\n\n## HDFS中常用到的命令\n1、hadoop fs\n```\nhadoop fs -ls /\nhadoop fs -lsr\nhadoop fs -mkdir /user/hadoop\nhadoop fs -put a.txt /user/hadoop/\nhadoop fs -get /user/hadoop/a.txt /\nhadoop fs -cp src dst\nhadoop fs -mv src dst\nhadoop fs -cat /user/hadoop/a.txt\nhadoop fs -rm /user/hadoop/a.txt\nhadoop fs -rmr /user/hadoop/a.txt\nhadoop fs -text /user/hadoop/a.txt\nhadoop fs -copyFromLocal localsrc dst 与hadoop fs -put功能类似。\nhadoop fs -moveFromLocal localsrc dst 将本地文件上传到hdfs，同时删除本地文件。\n```\n2、hadoop fsadmin\n```\nhadoop dfsadmin -report\nhadoop dfsadmin -safemode enter | leave | get | wait\nhadoop dfsadmin -setBalancerBandwidth 1000\n```\n\n3、hadoop fsck\n\n4、start-balancer.sh\n","source":"_posts/hdfs.md","raw":"---\ntitle: HDFS\n---\n\n## 简介\nHDFS（Hadoop Distributed File System ）Hadoop分布式文件系统。是根据google发表的论文翻版的。论文为GFS（Google File System）Google 文件系统（中文，英文）。\n\nHDFS有很多特点：\n-    ① 保存多个副本，且提供容错机制，副本丢失或宕机自动恢复。默认存3份。\n-    ② 运行在廉价的机器上。\n-    ③ 适合大数据的处理。多大？多小？HDFS默认会将文件分割成block，64M为1个block。然后将block按键值对存储在HDFS上，并将键值对的映射存到内存中。如果小文件太多，那内存的负担会很重。\n\n![hdfs1](images/hdfs1.jpg)\n如上图所示，HDFS也是按照Master和Slave的结构。分NameNode、SecondaryNameNode、DataNode这几个角色。\n\n- NameNode：是Master节点，是大领导。管理数据块映射；处理客户端的读写请求；配置副本策略；管理HDFS的名称空间；\n- SecondaryNameNode：是一个小弟，分担大哥namenode的工作量；是NameNode的冷备份；合并fsimage和fsedits然后再发给namenode。\n- DataNode：Slave节点，奴隶，干活的。负责存储client发来的数据块block；执行数据块的读写操作。\n- 热备份：b是a的热备份，如果a坏掉。那么b马上运行代替a的工作。\n- 冷备份：b是a的冷备份，如果a坏掉。那么b不能马上代替a工作。但是b上存储a的一些信息，减少a坏掉之后的损失。\n- fsimage:元数据镜像文件（文件系统的目录树。）\n- edits：元数据的操作日志（针对文件系统做的修改操作记录）\n\nNamenode内存中存储的是=fsimage+edits。\n\nSecondaryNameNode负责定时默认1小时，从namenode上，获取fsimage和edits来进行合并，然后再发送给namenode。减少namenode的工作量。\n\n## HDFS写操作\n有一个文件FileA，100M大小。Client将FileA写入到HDFS上。HDFS按默认配置。HDFS分布在三个机架上Rack1，Rack2，Rack3。\n![hdfs-write](images/hdfs-write.jpg)\n- a. Client将FileA按64M分块。分成两块，block1和Block2;\n- b. Client向nameNode发送写数据请求，如图蓝色虚线①------>。\n- c. NameNode节点，记录block信息。并返回可用的DataNode，如粉色虚线②--------->。\n\n    Block1: host2,host1,host3\n\n    Block2: host7,host8,host4\n\n    原理：\n\n        NameNode具有RackAware机架感知功能，这个可以配置。\n        若client为DataNode节点，那存储block时，规则为：副本1，同client的节点上；副本2，不同机架节点上；副本3，同第二个副本机架的另一个节点上；其他副本随机挑选。\n        若client不为DataNode节点，那存储block时，规则为：副本1，随机选择一个节点上；副本2，不同副本1，机架上；副本3，同副本2相同的另一个节点上；其他副本随机挑选。\n\n- d. client向DataNode发送block1；发送过程是以流式写入。\n\n    流式写入过程，\n\n        1>将64M的block1按64k的package划分;\n\n        2>然后将第一个package发送给host2;\n\n        3>host2接收完后，将第一个package发送给host1，同时client想host2发送第二个package；\n\n        4>host1接收完第一个package后，发送给host3，同时接收host2发来的第二个package。\n\n        5>以此类推，如图红线实线所示，直到将block1发送完毕。\n\n        6>host2,host1,host3向NameNode，host2向Client发送通知，说“消息发送完了”。如图粉红颜色实线所示。\n\n        7>client收到host2发来的消息后，向namenode发送消息，说我写完了。这样就真完成了。如图黄色粗实线\n\n        8>发送完block1后，再向host7，host8，host4发送block2，如图蓝色实线所示。\n\n        9>发送完block2后，host7,host8,host4向NameNode，host7向Client发送通知，如图浅绿色实线所示。\n\n        10>client向NameNode发送消息，说我写完了，如图黄色粗实线。。。这样就完毕了。\n\n分析，通过写过程，我们可以了解到：\n\n    ①写1T文件，我们需要3T的存储，3T的网络流量贷款。\n\n    ②在执行读或写的过程中，NameNode和DataNode通过HeartBeat进行保存通信，确定DataNode活着。如果发现DataNode死掉了，就将死掉的DataNode上的数据，放到其他节点去。读取时，要读其他节点去。\n\n    ③挂掉一个节点，没关系，还有其他节点可以备份；甚至，挂掉某一个机架，也没关系；其他机架上，也有备份。\n\n## HDFS读操作\n![hdfs-read](images/hdfs-read.jpg)\n\n读操作就简单一些了，如图所示，client要从datanode上，读取FileA。而FileA由block1和block2组成。\n\n\n\n那么，读操作流程为：\n\na. client向namenode发送读请求。\n\nb. namenode查看Metadata信息，返回fileA的block的位置。\n\n    block1:host2,host1,host3\n\n    block2:host7,host8,host4\n\nc. block的位置是有先后顺序的，先读block1，再读block2。而且block1去host2上读取；然后block2，去host7上读取；\n\n\n\n上面例子中，client位于机架外，那么如果client位于机架内某个DataNode上，例如,client是host6。那么读取的时候，遵循的规律是：\n\n优选读取本机架上的数据。\n\n\n## HDFS中常用到的命令\n1、hadoop fs\n```\nhadoop fs -ls /\nhadoop fs -lsr\nhadoop fs -mkdir /user/hadoop\nhadoop fs -put a.txt /user/hadoop/\nhadoop fs -get /user/hadoop/a.txt /\nhadoop fs -cp src dst\nhadoop fs -mv src dst\nhadoop fs -cat /user/hadoop/a.txt\nhadoop fs -rm /user/hadoop/a.txt\nhadoop fs -rmr /user/hadoop/a.txt\nhadoop fs -text /user/hadoop/a.txt\nhadoop fs -copyFromLocal localsrc dst 与hadoop fs -put功能类似。\nhadoop fs -moveFromLocal localsrc dst 将本地文件上传到hdfs，同时删除本地文件。\n```\n2、hadoop fsadmin\n```\nhadoop dfsadmin -report\nhadoop dfsadmin -safemode enter | leave | get | wait\nhadoop dfsadmin -setBalancerBandwidth 1000\n```\n\n3、hadoop fsck\n\n4、start-balancer.sh\n","slug":"hdfs","published":1,"date":"2017-03-26T13:32:42.000Z","updated":"2017-05-08T13:31:34.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj2g8ok3v000bdl72rej0fsy2","content":"<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>HDFS（Hadoop Distributed File System ）Hadoop分布式文件系统。是根据google发表的论文翻版的。论文为GFS（Google File System）Google 文件系统（中文，英文）。</p>\n<p>HDFS有很多特点：</p>\n<ul>\n<li>① 保存多个副本，且提供容错机制，副本丢失或宕机自动恢复。默认存3份。</li>\n<li>② 运行在廉价的机器上。</li>\n<li>③ 适合大数据的处理。多大？多小？HDFS默认会将文件分割成block，64M为1个block。然后将block按键值对存储在HDFS上，并将键值对的映射存到内存中。如果小文件太多，那内存的负担会很重。</li>\n</ul>\n<p><img src=\"images/hdfs1.jpg\" alt=\"hdfs1\"><br>如上图所示，HDFS也是按照Master和Slave的结构。分NameNode、SecondaryNameNode、DataNode这几个角色。</p>\n<ul>\n<li>NameNode：是Master节点，是大领导。管理数据块映射；处理客户端的读写请求；配置副本策略；管理HDFS的名称空间；</li>\n<li>SecondaryNameNode：是一个小弟，分担大哥namenode的工作量；是NameNode的冷备份；合并fsimage和fsedits然后再发给namenode。</li>\n<li>DataNode：Slave节点，奴隶，干活的。负责存储client发来的数据块block；执行数据块的读写操作。</li>\n<li>热备份：b是a的热备份，如果a坏掉。那么b马上运行代替a的工作。</li>\n<li>冷备份：b是a的冷备份，如果a坏掉。那么b不能马上代替a工作。但是b上存储a的一些信息，减少a坏掉之后的损失。</li>\n<li>fsimage:元数据镜像文件（文件系统的目录树。）</li>\n<li>edits：元数据的操作日志（针对文件系统做的修改操作记录）</li>\n</ul>\n<p>Namenode内存中存储的是=fsimage+edits。</p>\n<p>SecondaryNameNode负责定时默认1小时，从namenode上，获取fsimage和edits来进行合并，然后再发送给namenode。减少namenode的工作量。</p>\n<h2 id=\"HDFS写操作\"><a href=\"#HDFS写操作\" class=\"headerlink\" title=\"HDFS写操作\"></a>HDFS写操作</h2><p>有一个文件FileA，100M大小。Client将FileA写入到HDFS上。HDFS按默认配置。HDFS分布在三个机架上Rack1，Rack2，Rack3。<br><img src=\"images/hdfs-write.jpg\" alt=\"hdfs-write\"></p>\n<ul>\n<li>a. Client将FileA按64M分块。分成两块，block1和Block2;</li>\n<li>b. Client向nameNode发送写数据请求，如图蓝色虚线①——&gt;。</li>\n<li><p>c. NameNode节点，记录block信息。并返回可用的DataNode，如粉色虚线②———&gt;。</p>\n<p>  Block1: host2,host1,host3</p>\n<p>  Block2: host7,host8,host4</p>\n<p>  原理：</p>\n<pre><code>NameNode具有RackAware机架感知功能，这个可以配置。\n若client为DataNode节点，那存储block时，规则为：副本1，同client的节点上；副本2，不同机架节点上；副本3，同第二个副本机架的另一个节点上；其他副本随机挑选。\n若client不为DataNode节点，那存储block时，规则为：副本1，随机选择一个节点上；副本2，不同副本1，机架上；副本3，同副本2相同的另一个节点上；其他副本随机挑选。\n</code></pre></li>\n<li><p>d. client向DataNode发送block1；发送过程是以流式写入。</p>\n<p>  流式写入过程，</p>\n<pre><code>1&gt;将64M的block1按64k的package划分;\n\n2&gt;然后将第一个package发送给host2;\n\n3&gt;host2接收完后，将第一个package发送给host1，同时client想host2发送第二个package；\n\n4&gt;host1接收完第一个package后，发送给host3，同时接收host2发来的第二个package。\n\n5&gt;以此类推，如图红线实线所示，直到将block1发送完毕。\n\n6&gt;host2,host1,host3向NameNode，host2向Client发送通知，说“消息发送完了”。如图粉红颜色实线所示。\n\n7&gt;client收到host2发来的消息后，向namenode发送消息，说我写完了。这样就真完成了。如图黄色粗实线\n\n8&gt;发送完block1后，再向host7，host8，host4发送block2，如图蓝色实线所示。\n\n9&gt;发送完block2后，host7,host8,host4向NameNode，host7向Client发送通知，如图浅绿色实线所示。\n\n10&gt;client向NameNode发送消息，说我写完了，如图黄色粗实线。。。这样就完毕了。\n</code></pre></li>\n</ul>\n<p>分析，通过写过程，我们可以了解到：</p>\n<pre><code>①写1T文件，我们需要3T的存储，3T的网络流量贷款。\n\n②在执行读或写的过程中，NameNode和DataNode通过HeartBeat进行保存通信，确定DataNode活着。如果发现DataNode死掉了，就将死掉的DataNode上的数据，放到其他节点去。读取时，要读其他节点去。\n\n③挂掉一个节点，没关系，还有其他节点可以备份；甚至，挂掉某一个机架，也没关系；其他机架上，也有备份。\n</code></pre><h2 id=\"HDFS读操作\"><a href=\"#HDFS读操作\" class=\"headerlink\" title=\"HDFS读操作\"></a>HDFS读操作</h2><p><img src=\"images/hdfs-read.jpg\" alt=\"hdfs-read\"></p>\n<p>读操作就简单一些了，如图所示，client要从datanode上，读取FileA。而FileA由block1和block2组成。</p>\n<p>那么，读操作流程为：</p>\n<p>a. client向namenode发送读请求。</p>\n<p>b. namenode查看Metadata信息，返回fileA的block的位置。</p>\n<pre><code>block1:host2,host1,host3\n\nblock2:host7,host8,host4\n</code></pre><p>c. block的位置是有先后顺序的，先读block1，再读block2。而且block1去host2上读取；然后block2，去host7上读取；</p>\n<p>上面例子中，client位于机架外，那么如果client位于机架内某个DataNode上，例如,client是host6。那么读取的时候，遵循的规律是：</p>\n<p>优选读取本机架上的数据。</p>\n<h2 id=\"HDFS中常用到的命令\"><a href=\"#HDFS中常用到的命令\" class=\"headerlink\" title=\"HDFS中常用到的命令\"></a>HDFS中常用到的命令</h2><p>1、hadoop fs<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">hadoop fs -ls /</div><div class=\"line\">hadoop fs -lsr</div><div class=\"line\">hadoop fs -mkdir /user/hadoop</div><div class=\"line\">hadoop fs -put a.txt /user/hadoop/</div><div class=\"line\">hadoop fs -get /user/hadoop/a.txt /</div><div class=\"line\">hadoop fs -cp src dst</div><div class=\"line\">hadoop fs -mv src dst</div><div class=\"line\">hadoop fs -cat /user/hadoop/a.txt</div><div class=\"line\">hadoop fs -rm /user/hadoop/a.txt</div><div class=\"line\">hadoop fs -rmr /user/hadoop/a.txt</div><div class=\"line\">hadoop fs -text /user/hadoop/a.txt</div><div class=\"line\">hadoop fs -copyFromLocal localsrc dst 与hadoop fs -put功能类似。</div><div class=\"line\">hadoop fs -moveFromLocal localsrc dst 将本地文件上传到hdfs，同时删除本地文件。</div></pre></td></tr></table></figure></p>\n<p>2、hadoop fsadmin<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">hadoop dfsadmin -report</div><div class=\"line\">hadoop dfsadmin -safemode enter | leave | get | wait</div><div class=\"line\">hadoop dfsadmin -setBalancerBandwidth 1000</div></pre></td></tr></table></figure></p>\n<p>3、hadoop fsck</p>\n<p>4、start-balancer.sh</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>HDFS（Hadoop Distributed File System ）Hadoop分布式文件系统。是根据google发表的论文翻版的。论文为GFS（Google File System）Google 文件系统（中文，英文）。</p>\n<p>HDFS有很多特点：</p>\n<ul>\n<li>① 保存多个副本，且提供容错机制，副本丢失或宕机自动恢复。默认存3份。</li>\n<li>② 运行在廉价的机器上。</li>\n<li>③ 适合大数据的处理。多大？多小？HDFS默认会将文件分割成block，64M为1个block。然后将block按键值对存储在HDFS上，并将键值对的映射存到内存中。如果小文件太多，那内存的负担会很重。</li>\n</ul>\n<p><img src=\"images/hdfs1.jpg\" alt=\"hdfs1\"><br>如上图所示，HDFS也是按照Master和Slave的结构。分NameNode、SecondaryNameNode、DataNode这几个角色。</p>\n<ul>\n<li>NameNode：是Master节点，是大领导。管理数据块映射；处理客户端的读写请求；配置副本策略；管理HDFS的名称空间；</li>\n<li>SecondaryNameNode：是一个小弟，分担大哥namenode的工作量；是NameNode的冷备份；合并fsimage和fsedits然后再发给namenode。</li>\n<li>DataNode：Slave节点，奴隶，干活的。负责存储client发来的数据块block；执行数据块的读写操作。</li>\n<li>热备份：b是a的热备份，如果a坏掉。那么b马上运行代替a的工作。</li>\n<li>冷备份：b是a的冷备份，如果a坏掉。那么b不能马上代替a工作。但是b上存储a的一些信息，减少a坏掉之后的损失。</li>\n<li>fsimage:元数据镜像文件（文件系统的目录树。）</li>\n<li>edits：元数据的操作日志（针对文件系统做的修改操作记录）</li>\n</ul>\n<p>Namenode内存中存储的是=fsimage+edits。</p>\n<p>SecondaryNameNode负责定时默认1小时，从namenode上，获取fsimage和edits来进行合并，然后再发送给namenode。减少namenode的工作量。</p>\n<h2 id=\"HDFS写操作\"><a href=\"#HDFS写操作\" class=\"headerlink\" title=\"HDFS写操作\"></a>HDFS写操作</h2><p>有一个文件FileA，100M大小。Client将FileA写入到HDFS上。HDFS按默认配置。HDFS分布在三个机架上Rack1，Rack2，Rack3。<br><img src=\"images/hdfs-write.jpg\" alt=\"hdfs-write\"></p>\n<ul>\n<li>a. Client将FileA按64M分块。分成两块，block1和Block2;</li>\n<li>b. Client向nameNode发送写数据请求，如图蓝色虚线①——&gt;。</li>\n<li><p>c. NameNode节点，记录block信息。并返回可用的DataNode，如粉色虚线②———&gt;。</p>\n<p>  Block1: host2,host1,host3</p>\n<p>  Block2: host7,host8,host4</p>\n<p>  原理：</p>\n<pre><code>NameNode具有RackAware机架感知功能，这个可以配置。\n若client为DataNode节点，那存储block时，规则为：副本1，同client的节点上；副本2，不同机架节点上；副本3，同第二个副本机架的另一个节点上；其他副本随机挑选。\n若client不为DataNode节点，那存储block时，规则为：副本1，随机选择一个节点上；副本2，不同副本1，机架上；副本3，同副本2相同的另一个节点上；其他副本随机挑选。\n</code></pre></li>\n<li><p>d. client向DataNode发送block1；发送过程是以流式写入。</p>\n<p>  流式写入过程，</p>\n<pre><code>1&gt;将64M的block1按64k的package划分;\n\n2&gt;然后将第一个package发送给host2;\n\n3&gt;host2接收完后，将第一个package发送给host1，同时client想host2发送第二个package；\n\n4&gt;host1接收完第一个package后，发送给host3，同时接收host2发来的第二个package。\n\n5&gt;以此类推，如图红线实线所示，直到将block1发送完毕。\n\n6&gt;host2,host1,host3向NameNode，host2向Client发送通知，说“消息发送完了”。如图粉红颜色实线所示。\n\n7&gt;client收到host2发来的消息后，向namenode发送消息，说我写完了。这样就真完成了。如图黄色粗实线\n\n8&gt;发送完block1后，再向host7，host8，host4发送block2，如图蓝色实线所示。\n\n9&gt;发送完block2后，host7,host8,host4向NameNode，host7向Client发送通知，如图浅绿色实线所示。\n\n10&gt;client向NameNode发送消息，说我写完了，如图黄色粗实线。。。这样就完毕了。\n</code></pre></li>\n</ul>\n<p>分析，通过写过程，我们可以了解到：</p>\n<pre><code>①写1T文件，我们需要3T的存储，3T的网络流量贷款。\n\n②在执行读或写的过程中，NameNode和DataNode通过HeartBeat进行保存通信，确定DataNode活着。如果发现DataNode死掉了，就将死掉的DataNode上的数据，放到其他节点去。读取时，要读其他节点去。\n\n③挂掉一个节点，没关系，还有其他节点可以备份；甚至，挂掉某一个机架，也没关系；其他机架上，也有备份。\n</code></pre><h2 id=\"HDFS读操作\"><a href=\"#HDFS读操作\" class=\"headerlink\" title=\"HDFS读操作\"></a>HDFS读操作</h2><p><img src=\"images/hdfs-read.jpg\" alt=\"hdfs-read\"></p>\n<p>读操作就简单一些了，如图所示，client要从datanode上，读取FileA。而FileA由block1和block2组成。</p>\n<p>那么，读操作流程为：</p>\n<p>a. client向namenode发送读请求。</p>\n<p>b. namenode查看Metadata信息，返回fileA的block的位置。</p>\n<pre><code>block1:host2,host1,host3\n\nblock2:host7,host8,host4\n</code></pre><p>c. block的位置是有先后顺序的，先读block1，再读block2。而且block1去host2上读取；然后block2，去host7上读取；</p>\n<p>上面例子中，client位于机架外，那么如果client位于机架内某个DataNode上，例如,client是host6。那么读取的时候，遵循的规律是：</p>\n<p>优选读取本机架上的数据。</p>\n<h2 id=\"HDFS中常用到的命令\"><a href=\"#HDFS中常用到的命令\" class=\"headerlink\" title=\"HDFS中常用到的命令\"></a>HDFS中常用到的命令</h2><p>1、hadoop fs<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">hadoop fs -ls /</div><div class=\"line\">hadoop fs -lsr</div><div class=\"line\">hadoop fs -mkdir /user/hadoop</div><div class=\"line\">hadoop fs -put a.txt /user/hadoop/</div><div class=\"line\">hadoop fs -get /user/hadoop/a.txt /</div><div class=\"line\">hadoop fs -cp src dst</div><div class=\"line\">hadoop fs -mv src dst</div><div class=\"line\">hadoop fs -cat /user/hadoop/a.txt</div><div class=\"line\">hadoop fs -rm /user/hadoop/a.txt</div><div class=\"line\">hadoop fs -rmr /user/hadoop/a.txt</div><div class=\"line\">hadoop fs -text /user/hadoop/a.txt</div><div class=\"line\">hadoop fs -copyFromLocal localsrc dst 与hadoop fs -put功能类似。</div><div class=\"line\">hadoop fs -moveFromLocal localsrc dst 将本地文件上传到hdfs，同时删除本地文件。</div></pre></td></tr></table></figure></p>\n<p>2、hadoop fsadmin<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">hadoop dfsadmin -report</div><div class=\"line\">hadoop dfsadmin -safemode enter | leave | get | wait</div><div class=\"line\">hadoop dfsadmin -setBalancerBandwidth 1000</div></pre></td></tr></table></figure></p>\n<p>3、hadoop fsck</p>\n<p>4、start-balancer.sh</p>\n"},{"title":"HBase","_content":"\n## HBase QuickStart\nHBase是一个开源的分布式存储系统。他可以看作是Google的Bigtable的开源实现。如同Google的Bigtable使用Google File System一样，HBase构建于和Google File System类似的Hadoop HDFS之上。\n\nWith the completed config, issue the command: bin/start-hbase.sh\n\n```\n2017-05-03 11:54:25,802 INFO  [main] http.HttpServer: Jetty bound to port 16010\n2017-05-03 11:54:25,802 INFO  [main] mortbay.log: jetty-6.1.26\n2017-05-03 11:54:25,998 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:16010\n```\nGo to http://localhost:16010 to view the HBase Web UI.\n\n\n## HBase连接池管理\nConnectionFactory 是一个不可实例化的类，专门用于创建HBase的Connection。最简单的创建Connection实例的方式是ConnectionFactory.createConnection(config)，该方法创建了一个连接到集群的Connection实例，该实例被创建的程序管理。通过这个Connection实例，可以使用Connection.getTable()方法取得Table，例如:\n```\n Connection connection = ConnectionFactory.createConnection(config);\n Table table = connection.getTable(TableName.valueOf(\"table1\"));\n try {\n  // Use the table as needed, for a single operation and a single thread\n } finally {\n  table.close();\n  connection.close();\n }\n ```\n **** HConnectionManager在新版本中已经不建议使用。\n\n## HBase客户端的使用\n\n [客户端的使用Sample](samplecodes/hbaseclient/HBaseSample.java)\n\n## Cassandra\nApache Cassandra是高度可扩展的，高性能的分布式NoSQL数据库。 Cassandra旨在处理许多商品服务器上的大量数据，提供高可用性而无需担心单点故障。\n\nCassandra具有能够处理大量数据的分布式架构。 数据放置在具有多个复制因子的不同机器上，以获得高可用性，而无需担心单点故障。它在其节点之间具有对等分布式系统，数据分布在集群中的所有节点上。\n- 在Cassandra中，每个节点是独立的，同时与其他节点互连。 集群中的所有节点都扮演着相同的角色。\n- 集群中的每个节点都可以接受读取和写入请求，而不管数据实际位于集群中的位置。\n- 在一个节点发生故障的情况下，可以从网络中的其他节点提供读/写请求。\n\n## Cassandra和HBase对比\n\nCassandra可以看作是Amazon Dynamo的开源实现。和Dynamo不同之处在于，Cassandra结合了Google Bigtable的ColumnFamily的数据模型。可以简单地认为，Cassandra是一个P2P的，高可靠性并具有丰富的数据模型的分布式文件系统。\n\n- Cassandra部署更简单。Cassandra只有一种角色，而HBase除了Region Server外还需要Zookeeper来同步集群状态\n- 数据一致性是否可配置。Cassandra的数据一致性是可配置的，可以更改为最终一致性，而HBase是强一致性的\n- 负载均衡算法不同。Cassandra通过一致性哈希来决定数据存储的位置，而HBase靠Master节点管理数据的分配，将过热的节点上的Region动态分配给负载较低的节点。因此Cassandra的平均性能会优于HBase，但是HBase有Master节点，热数据的负载更均衡。\n- 单点问题。正是由于HBase存在Master节点，因此会存在单点问题。\n\n<table>\n    <th>\n        <td>HBase</td>\n        <td>Cassandra</td>\n    </th>\n    <tr>\n        <td>语言/License/交互协议</td>\n        <td>Java/Apache/HTTP/REST (also Thrift)\t</td>\n        <td>Java/Apache/Custom, binary (Thrift)</td>\n    </tr>\n    <tr>\n        <td>出发点</td>\n        <td>BigTable</td>\n        <td>BigTable and Dynamo</td>\n    </tr>\n    <tr>\n        <td>架构</td>\n        <td>master/slave\t</td>\n        <td>p2p</td>\n    </tr>\n    <tr>\n        <td>高可用性</td>\n        <td>NameNode是HDFS的单点故障点\t</td>\n        <td>P2P和去中心化设计，不会出现单点故障</td>\n    </tr>\n    <tr>\n        <td>伸缩性\t</td>\n        <td>Region Server扩容，通过将自身发布到Master，Master均匀分布Region\t</td>\n        <td>扩容需在Hash Ring上多个节点间调整数据分布</td>\n    </tr>\n    <tr>\n        <td>一致性\t</td>\n        <td>强一致性\t</td>\n        <td>最终一致性，Quorum NRW策略</td>\n    </tr>\n    <tr>\n        <td>存储目标/数据分布</td>\n        <td>大文件/表划分为多个region存在不同region server上\t</td>\n        <td>小文件/改进的一致性哈希（虚拟节点）</td>\n    </tr>\n    <tr>\n        <td>成员通信及错误检测\t</td>\n        <td>Zookeeper\t</td>\n        <td>基于Gossip/P2P</td>\n    </tr>\n    <tr>\n        <td>读写性能\t</td>\n        <td>数据读写定位可能要通过最多6次的网络RPC，性能较低。\t\t</td>\n        <td>数据读写定位非常快</td>\n    </tr>\n    <tr>\n        <td>数据冲突处理\t</td>\n        <td>乐观并发控制（optimistic concurrency control）\t\t</td>\n        <td>向量时钟</td>\n    </tr>\n    <tr>\n        <td>临时故障处理\t</td>\n        <td>Region Server宕机，重做HLog\t\t</td>\n        <td>数据回传机制：某节点宕机，hash到该节点的新数据自动路由到下一节点做 hinted handoff，源节点恢复后，推送回源节点。</td>\n    </tr>\n    <tr>\n        <td>永久故障恢复\t\t</td>\n        <td>Region Server恢复，master重新给其分配region\t</td>\n        <td>Merkle 哈希树，通过Gossip协议同步Merkle Tree，维护集群节点间的数据一致性</td>\n    </tr>\n    <tr>\n        <td>CAP\t</td>\n        <td>1，强一致性，0数据丢失。2，可用性低。3，扩容方便。\t\t\t</td>\n        <td>1，弱一致性，数据可能丢失。2，可用性高。3，扩容方便。</td>\n    </tr>\n\n</table>\n","source":"_posts/hbase.md","raw":"---\ntitle: HBase\n---\n\n## HBase QuickStart\nHBase是一个开源的分布式存储系统。他可以看作是Google的Bigtable的开源实现。如同Google的Bigtable使用Google File System一样，HBase构建于和Google File System类似的Hadoop HDFS之上。\n\nWith the completed config, issue the command: bin/start-hbase.sh\n\n```\n2017-05-03 11:54:25,802 INFO  [main] http.HttpServer: Jetty bound to port 16010\n2017-05-03 11:54:25,802 INFO  [main] mortbay.log: jetty-6.1.26\n2017-05-03 11:54:25,998 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:16010\n```\nGo to http://localhost:16010 to view the HBase Web UI.\n\n\n## HBase连接池管理\nConnectionFactory 是一个不可实例化的类，专门用于创建HBase的Connection。最简单的创建Connection实例的方式是ConnectionFactory.createConnection(config)，该方法创建了一个连接到集群的Connection实例，该实例被创建的程序管理。通过这个Connection实例，可以使用Connection.getTable()方法取得Table，例如:\n```\n Connection connection = ConnectionFactory.createConnection(config);\n Table table = connection.getTable(TableName.valueOf(\"table1\"));\n try {\n  // Use the table as needed, for a single operation and a single thread\n } finally {\n  table.close();\n  connection.close();\n }\n ```\n **** HConnectionManager在新版本中已经不建议使用。\n\n## HBase客户端的使用\n\n [客户端的使用Sample](samplecodes/hbaseclient/HBaseSample.java)\n\n## Cassandra\nApache Cassandra是高度可扩展的，高性能的分布式NoSQL数据库。 Cassandra旨在处理许多商品服务器上的大量数据，提供高可用性而无需担心单点故障。\n\nCassandra具有能够处理大量数据的分布式架构。 数据放置在具有多个复制因子的不同机器上，以获得高可用性，而无需担心单点故障。它在其节点之间具有对等分布式系统，数据分布在集群中的所有节点上。\n- 在Cassandra中，每个节点是独立的，同时与其他节点互连。 集群中的所有节点都扮演着相同的角色。\n- 集群中的每个节点都可以接受读取和写入请求，而不管数据实际位于集群中的位置。\n- 在一个节点发生故障的情况下，可以从网络中的其他节点提供读/写请求。\n\n## Cassandra和HBase对比\n\nCassandra可以看作是Amazon Dynamo的开源实现。和Dynamo不同之处在于，Cassandra结合了Google Bigtable的ColumnFamily的数据模型。可以简单地认为，Cassandra是一个P2P的，高可靠性并具有丰富的数据模型的分布式文件系统。\n\n- Cassandra部署更简单。Cassandra只有一种角色，而HBase除了Region Server外还需要Zookeeper来同步集群状态\n- 数据一致性是否可配置。Cassandra的数据一致性是可配置的，可以更改为最终一致性，而HBase是强一致性的\n- 负载均衡算法不同。Cassandra通过一致性哈希来决定数据存储的位置，而HBase靠Master节点管理数据的分配，将过热的节点上的Region动态分配给负载较低的节点。因此Cassandra的平均性能会优于HBase，但是HBase有Master节点，热数据的负载更均衡。\n- 单点问题。正是由于HBase存在Master节点，因此会存在单点问题。\n\n<table>\n    <th>\n        <td>HBase</td>\n        <td>Cassandra</td>\n    </th>\n    <tr>\n        <td>语言/License/交互协议</td>\n        <td>Java/Apache/HTTP/REST (also Thrift)\t</td>\n        <td>Java/Apache/Custom, binary (Thrift)</td>\n    </tr>\n    <tr>\n        <td>出发点</td>\n        <td>BigTable</td>\n        <td>BigTable and Dynamo</td>\n    </tr>\n    <tr>\n        <td>架构</td>\n        <td>master/slave\t</td>\n        <td>p2p</td>\n    </tr>\n    <tr>\n        <td>高可用性</td>\n        <td>NameNode是HDFS的单点故障点\t</td>\n        <td>P2P和去中心化设计，不会出现单点故障</td>\n    </tr>\n    <tr>\n        <td>伸缩性\t</td>\n        <td>Region Server扩容，通过将自身发布到Master，Master均匀分布Region\t</td>\n        <td>扩容需在Hash Ring上多个节点间调整数据分布</td>\n    </tr>\n    <tr>\n        <td>一致性\t</td>\n        <td>强一致性\t</td>\n        <td>最终一致性，Quorum NRW策略</td>\n    </tr>\n    <tr>\n        <td>存储目标/数据分布</td>\n        <td>大文件/表划分为多个region存在不同region server上\t</td>\n        <td>小文件/改进的一致性哈希（虚拟节点）</td>\n    </tr>\n    <tr>\n        <td>成员通信及错误检测\t</td>\n        <td>Zookeeper\t</td>\n        <td>基于Gossip/P2P</td>\n    </tr>\n    <tr>\n        <td>读写性能\t</td>\n        <td>数据读写定位可能要通过最多6次的网络RPC，性能较低。\t\t</td>\n        <td>数据读写定位非常快</td>\n    </tr>\n    <tr>\n        <td>数据冲突处理\t</td>\n        <td>乐观并发控制（optimistic concurrency control）\t\t</td>\n        <td>向量时钟</td>\n    </tr>\n    <tr>\n        <td>临时故障处理\t</td>\n        <td>Region Server宕机，重做HLog\t\t</td>\n        <td>数据回传机制：某节点宕机，hash到该节点的新数据自动路由到下一节点做 hinted handoff，源节点恢复后，推送回源节点。</td>\n    </tr>\n    <tr>\n        <td>永久故障恢复\t\t</td>\n        <td>Region Server恢复，master重新给其分配region\t</td>\n        <td>Merkle 哈希树，通过Gossip协议同步Merkle Tree，维护集群节点间的数据一致性</td>\n    </tr>\n    <tr>\n        <td>CAP\t</td>\n        <td>1，强一致性，0数据丢失。2，可用性低。3，扩容方便。\t\t\t</td>\n        <td>1，弱一致性，数据可能丢失。2，可用性高。3，扩容方便。</td>\n    </tr>\n\n</table>\n","slug":"hbase","published":1,"date":"2017-05-03T03:57:18.000Z","updated":"2017-05-08T13:31:26.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj2g8ok3w000ddl72naynia33","content":"<h2 id=\"HBase-QuickStart\"><a href=\"#HBase-QuickStart\" class=\"headerlink\" title=\"HBase QuickStart\"></a>HBase QuickStart</h2><p>HBase是一个开源的分布式存储系统。他可以看作是Google的Bigtable的开源实现。如同Google的Bigtable使用Google File System一样，HBase构建于和Google File System类似的Hadoop HDFS之上。</p>\n<p>With the completed config, issue the command: bin/start-hbase.sh</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">2017-05-03 11:54:25,802 INFO  [main] http.HttpServer: Jetty bound to port 16010</div><div class=\"line\">2017-05-03 11:54:25,802 INFO  [main] mortbay.log: jetty-6.1.26</div><div class=\"line\">2017-05-03 11:54:25,998 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:16010</div></pre></td></tr></table></figure>\n<p>Go to <a href=\"http://localhost:16010\" target=\"_blank\" rel=\"external\">http://localhost:16010</a> to view the HBase Web UI.</p>\n<h2 id=\"HBase连接池管理\"><a href=\"#HBase连接池管理\" class=\"headerlink\" title=\"HBase连接池管理\"></a>HBase连接池管理</h2><p>ConnectionFactory 是一个不可实例化的类，专门用于创建HBase的Connection。最简单的创建Connection实例的方式是ConnectionFactory.createConnection(config)，该方法创建了一个连接到集群的Connection实例，该实例被创建的程序管理。通过这个Connection实例，可以使用Connection.getTable()方法取得Table，例如:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">Connection connection = ConnectionFactory.createConnection(config);</div><div class=\"line\">Table table = connection.getTable(TableName.valueOf(&quot;table1&quot;));</div><div class=\"line\">try &#123;</div><div class=\"line\"> // Use the table as needed, for a single operation and a single thread</div><div class=\"line\">&#125; finally &#123;</div><div class=\"line\"> table.close();</div><div class=\"line\"> connection.close();</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p> <em>**</em> HConnectionManager在新版本中已经不建议使用。</p>\n<h2 id=\"HBase客户端的使用\"><a href=\"#HBase客户端的使用\" class=\"headerlink\" title=\"HBase客户端的使用\"></a>HBase客户端的使用</h2><p> <a href=\"samplecodes/hbaseclient/HBaseSample.java\">客户端的使用Sample</a></p>\n<h2 id=\"Cassandra\"><a href=\"#Cassandra\" class=\"headerlink\" title=\"Cassandra\"></a>Cassandra</h2><p>Apache Cassandra是高度可扩展的，高性能的分布式NoSQL数据库。 Cassandra旨在处理许多商品服务器上的大量数据，提供高可用性而无需担心单点故障。</p>\n<p>Cassandra具有能够处理大量数据的分布式架构。 数据放置在具有多个复制因子的不同机器上，以获得高可用性，而无需担心单点故障。它在其节点之间具有对等分布式系统，数据分布在集群中的所有节点上。</p>\n<ul>\n<li>在Cassandra中，每个节点是独立的，同时与其他节点互连。 集群中的所有节点都扮演着相同的角色。</li>\n<li>集群中的每个节点都可以接受读取和写入请求，而不管数据实际位于集群中的位置。</li>\n<li>在一个节点发生故障的情况下，可以从网络中的其他节点提供读/写请求。</li>\n</ul>\n<h2 id=\"Cassandra和HBase对比\"><a href=\"#Cassandra和HBase对比\" class=\"headerlink\" title=\"Cassandra和HBase对比\"></a>Cassandra和HBase对比</h2><p>Cassandra可以看作是Amazon Dynamo的开源实现。和Dynamo不同之处在于，Cassandra结合了Google Bigtable的ColumnFamily的数据模型。可以简单地认为，Cassandra是一个P2P的，高可靠性并具有丰富的数据模型的分布式文件系统。</p>\n<ul>\n<li>Cassandra部署更简单。Cassandra只有一种角色，而HBase除了Region Server外还需要Zookeeper来同步集群状态</li>\n<li>数据一致性是否可配置。Cassandra的数据一致性是可配置的，可以更改为最终一致性，而HBase是强一致性的</li>\n<li>负载均衡算法不同。Cassandra通过一致性哈希来决定数据存储的位置，而HBase靠Master节点管理数据的分配，将过热的节点上的Region动态分配给负载较低的节点。因此Cassandra的平均性能会优于HBase，但是HBase有Master节点，热数据的负载更均衡。</li>\n<li>单点问题。正是由于HBase存在Master节点，因此会存在单点问题。</li>\n</ul>\n<table><br>    <th><br>        </th><td>HBase</td><br>        <td>Cassandra</td><br>    <br>    <tr><br>        <td>语言/License/交互协议</td><br>        <td>Java/Apache/HTTP/REST (also Thrift)    </td><br>        <td>Java/Apache/Custom, binary (Thrift)</td><br>    </tr><br>    <tr><br>        <td>出发点</td><br>        <td>BigTable</td><br>        <td>BigTable and Dynamo</td><br>    </tr><br>    <tr><br>        <td>架构</td><br>        <td>master/slave    </td><br>        <td>p2p</td><br>    </tr><br>    <tr><br>        <td>高可用性</td><br>        <td>NameNode是HDFS的单点故障点    </td><br>        <td>P2P和去中心化设计，不会出现单点故障</td><br>    </tr><br>    <tr><br>        <td>伸缩性    </td><br>        <td>Region Server扩容，通过将自身发布到Master，Master均匀分布Region    </td><br>        <td>扩容需在Hash Ring上多个节点间调整数据分布</td><br>    </tr><br>    <tr><br>        <td>一致性    </td><br>        <td>强一致性    </td><br>        <td>最终一致性，Quorum NRW策略</td><br>    </tr><br>    <tr><br>        <td>存储目标/数据分布</td><br>        <td>大文件/表划分为多个region存在不同region server上    </td><br>        <td>小文件/改进的一致性哈希（虚拟节点）</td><br>    </tr><br>    <tr><br>        <td>成员通信及错误检测    </td><br>        <td>Zookeeper    </td><br>        <td>基于Gossip/P2P</td><br>    </tr><br>    <tr><br>        <td>读写性能    </td><br>        <td>数据读写定位可能要通过最多6次的网络RPC，性能较低。        </td><br>        <td>数据读写定位非常快</td><br>    </tr><br>    <tr><br>        <td>数据冲突处理    </td><br>        <td>乐观并发控制（optimistic concurrency control）        </td><br>        <td>向量时钟</td><br>    </tr><br>    <tr><br>        <td>临时故障处理    </td><br>        <td>Region Server宕机，重做HLog        </td><br>        <td>数据回传机制：某节点宕机，hash到该节点的新数据自动路由到下一节点做 hinted handoff，源节点恢复后，推送回源节点。</td><br>    </tr><br>    <tr><br>        <td>永久故障恢复        </td><br>        <td>Region Server恢复，master重新给其分配region    </td><br>        <td>Merkle 哈希树，通过Gossip协议同步Merkle Tree，维护集群节点间的数据一致性</td><br>    </tr><br>    <tr><br>        <td>CAP    </td><br>        <td>1，强一致性，0数据丢失。2，可用性低。3，扩容方便。            </td><br>        <td>1，弱一致性，数据可能丢失。2，可用性高。3，扩容方便。</td><br>    </tr><br><br></table>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"HBase-QuickStart\"><a href=\"#HBase-QuickStart\" class=\"headerlink\" title=\"HBase QuickStart\"></a>HBase QuickStart</h2><p>HBase是一个开源的分布式存储系统。他可以看作是Google的Bigtable的开源实现。如同Google的Bigtable使用Google File System一样，HBase构建于和Google File System类似的Hadoop HDFS之上。</p>\n<p>With the completed config, issue the command: bin/start-hbase.sh</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">2017-05-03 11:54:25,802 INFO  [main] http.HttpServer: Jetty bound to port 16010</div><div class=\"line\">2017-05-03 11:54:25,802 INFO  [main] mortbay.log: jetty-6.1.26</div><div class=\"line\">2017-05-03 11:54:25,998 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:16010</div></pre></td></tr></table></figure>\n<p>Go to <a href=\"http://localhost:16010\" target=\"_blank\" rel=\"external\">http://localhost:16010</a> to view the HBase Web UI.</p>\n<h2 id=\"HBase连接池管理\"><a href=\"#HBase连接池管理\" class=\"headerlink\" title=\"HBase连接池管理\"></a>HBase连接池管理</h2><p>ConnectionFactory 是一个不可实例化的类，专门用于创建HBase的Connection。最简单的创建Connection实例的方式是ConnectionFactory.createConnection(config)，该方法创建了一个连接到集群的Connection实例，该实例被创建的程序管理。通过这个Connection实例，可以使用Connection.getTable()方法取得Table，例如:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">Connection connection = ConnectionFactory.createConnection(config);</div><div class=\"line\">Table table = connection.getTable(TableName.valueOf(&quot;table1&quot;));</div><div class=\"line\">try &#123;</div><div class=\"line\"> // Use the table as needed, for a single operation and a single thread</div><div class=\"line\">&#125; finally &#123;</div><div class=\"line\"> table.close();</div><div class=\"line\"> connection.close();</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p> <em>**</em> HConnectionManager在新版本中已经不建议使用。</p>\n<h2 id=\"HBase客户端的使用\"><a href=\"#HBase客户端的使用\" class=\"headerlink\" title=\"HBase客户端的使用\"></a>HBase客户端的使用</h2><p> <a href=\"samplecodes/hbaseclient/HBaseSample.java\">客户端的使用Sample</a></p>\n<h2 id=\"Cassandra\"><a href=\"#Cassandra\" class=\"headerlink\" title=\"Cassandra\"></a>Cassandra</h2><p>Apache Cassandra是高度可扩展的，高性能的分布式NoSQL数据库。 Cassandra旨在处理许多商品服务器上的大量数据，提供高可用性而无需担心单点故障。</p>\n<p>Cassandra具有能够处理大量数据的分布式架构。 数据放置在具有多个复制因子的不同机器上，以获得高可用性，而无需担心单点故障。它在其节点之间具有对等分布式系统，数据分布在集群中的所有节点上。</p>\n<ul>\n<li>在Cassandra中，每个节点是独立的，同时与其他节点互连。 集群中的所有节点都扮演着相同的角色。</li>\n<li>集群中的每个节点都可以接受读取和写入请求，而不管数据实际位于集群中的位置。</li>\n<li>在一个节点发生故障的情况下，可以从网络中的其他节点提供读/写请求。</li>\n</ul>\n<h2 id=\"Cassandra和HBase对比\"><a href=\"#Cassandra和HBase对比\" class=\"headerlink\" title=\"Cassandra和HBase对比\"></a>Cassandra和HBase对比</h2><p>Cassandra可以看作是Amazon Dynamo的开源实现。和Dynamo不同之处在于，Cassandra结合了Google Bigtable的ColumnFamily的数据模型。可以简单地认为，Cassandra是一个P2P的，高可靠性并具有丰富的数据模型的分布式文件系统。</p>\n<ul>\n<li>Cassandra部署更简单。Cassandra只有一种角色，而HBase除了Region Server外还需要Zookeeper来同步集群状态</li>\n<li>数据一致性是否可配置。Cassandra的数据一致性是可配置的，可以更改为最终一致性，而HBase是强一致性的</li>\n<li>负载均衡算法不同。Cassandra通过一致性哈希来决定数据存储的位置，而HBase靠Master节点管理数据的分配，将过热的节点上的Region动态分配给负载较低的节点。因此Cassandra的平均性能会优于HBase，但是HBase有Master节点，热数据的负载更均衡。</li>\n<li>单点问题。正是由于HBase存在Master节点，因此会存在单点问题。</li>\n</ul>\n<table><br>    <th><br>        </th><td>HBase</td><br>        <td>Cassandra</td><br>    <br>    <tr><br>        <td>语言/License/交互协议</td><br>        <td>Java/Apache/HTTP/REST (also Thrift)    </td><br>        <td>Java/Apache/Custom, binary (Thrift)</td><br>    </tr><br>    <tr><br>        <td>出发点</td><br>        <td>BigTable</td><br>        <td>BigTable and Dynamo</td><br>    </tr><br>    <tr><br>        <td>架构</td><br>        <td>master/slave    </td><br>        <td>p2p</td><br>    </tr><br>    <tr><br>        <td>高可用性</td><br>        <td>NameNode是HDFS的单点故障点    </td><br>        <td>P2P和去中心化设计，不会出现单点故障</td><br>    </tr><br>    <tr><br>        <td>伸缩性    </td><br>        <td>Region Server扩容，通过将自身发布到Master，Master均匀分布Region    </td><br>        <td>扩容需在Hash Ring上多个节点间调整数据分布</td><br>    </tr><br>    <tr><br>        <td>一致性    </td><br>        <td>强一致性    </td><br>        <td>最终一致性，Quorum NRW策略</td><br>    </tr><br>    <tr><br>        <td>存储目标/数据分布</td><br>        <td>大文件/表划分为多个region存在不同region server上    </td><br>        <td>小文件/改进的一致性哈希（虚拟节点）</td><br>    </tr><br>    <tr><br>        <td>成员通信及错误检测    </td><br>        <td>Zookeeper    </td><br>        <td>基于Gossip/P2P</td><br>    </tr><br>    <tr><br>        <td>读写性能    </td><br>        <td>数据读写定位可能要通过最多6次的网络RPC，性能较低。        </td><br>        <td>数据读写定位非常快</td><br>    </tr><br>    <tr><br>        <td>数据冲突处理    </td><br>        <td>乐观并发控制（optimistic concurrency control）        </td><br>        <td>向量时钟</td><br>    </tr><br>    <tr><br>        <td>临时故障处理    </td><br>        <td>Region Server宕机，重做HLog        </td><br>        <td>数据回传机制：某节点宕机，hash到该节点的新数据自动路由到下一节点做 hinted handoff，源节点恢复后，推送回源节点。</td><br>    </tr><br>    <tr><br>        <td>永久故障恢复        </td><br>        <td>Region Server恢复，master重新给其分配region    </td><br>        <td>Merkle 哈希树，通过Gossip协议同步Merkle Tree，维护集群节点间的数据一致性</td><br>    </tr><br>    <tr><br>        <td>CAP    </td><br>        <td>1，强一致性，0数据丢失。2，可用性低。3，扩容方便。            </td><br>        <td>1，弱一致性，数据可能丢失。2，可用性高。3，扩容方便。</td><br>    </tr><br><br></table>\n"},{"title":"Mongo","_content":"### 1. mongo docker image\nStart the Database\n```\ndocker run --name mymongo -d mongo:<label> --auth\n```\n\nAdd the Initial Admin User\n```\n$ docker exec -it mymongo mongo admin\nconnecting to: admin\n> db.createUser({ user: 'jsmith', pwd: 'some-initial-password', roles: [ { role: \"userAdminAnyDatabase\", db: \"admin\" } ] });\nSuccessfully added user: {\n    \"user\" : \"jsmith\",\n    \"roles\" : [\n        {\n            \"role\" : \"userAdminAnyDatabase\",\n            \"db\" : \"admin\"\n        }\n    ]\n}\n```\n### 2. mongo backup and restore\n","source":"_posts/mongo.md","raw":"---\ntitle: Mongo\n---\n### 1. mongo docker image\nStart the Database\n```\ndocker run --name mymongo -d mongo:<label> --auth\n```\n\nAdd the Initial Admin User\n```\n$ docker exec -it mymongo mongo admin\nconnecting to: admin\n> db.createUser({ user: 'jsmith', pwd: 'some-initial-password', roles: [ { role: \"userAdminAnyDatabase\", db: \"admin\" } ] });\nSuccessfully added user: {\n    \"user\" : \"jsmith\",\n    \"roles\" : [\n        {\n            \"role\" : \"userAdminAnyDatabase\",\n            \"db\" : \"admin\"\n        }\n    ]\n}\n```\n### 2. mongo backup and restore\n","slug":"mongo","published":1,"date":"2017-03-24T05:26:48.000Z","updated":"2017-05-08T13:32:02.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj2g8ok3x000edl72sqdx3rn0","content":"<h3 id=\"1-mongo-docker-image\"><a href=\"#1-mongo-docker-image\" class=\"headerlink\" title=\"1. mongo docker image\"></a>1. mongo docker image</h3><p>Start the Database<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker run --name mymongo -d mongo:&lt;label&gt; --auth</div></pre></td></tr></table></figure></p>\n<p>Add the Initial Admin User<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ docker exec -it mymongo mongo admin</div><div class=\"line\">connecting to: admin</div><div class=\"line\">&gt; db.createUser(&#123; user: &apos;jsmith&apos;, pwd: &apos;some-initial-password&apos;, roles: [ &#123; role: &quot;userAdminAnyDatabase&quot;, db: &quot;admin&quot; &#125; ] &#125;);</div><div class=\"line\">Successfully added user: &#123;</div><div class=\"line\">    &quot;user&quot; : &quot;jsmith&quot;,</div><div class=\"line\">    &quot;roles&quot; : [</div><div class=\"line\">        &#123;</div><div class=\"line\">            &quot;role&quot; : &quot;userAdminAnyDatabase&quot;,</div><div class=\"line\">            &quot;db&quot; : &quot;admin&quot;</div><div class=\"line\">        &#125;</div><div class=\"line\">    ]</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h3 id=\"2-mongo-backup-and-restore\"><a href=\"#2-mongo-backup-and-restore\" class=\"headerlink\" title=\"2. mongo backup and restore\"></a>2. mongo backup and restore</h3>","site":{"data":{}},"excerpt":"","more":"<h3 id=\"1-mongo-docker-image\"><a href=\"#1-mongo-docker-image\" class=\"headerlink\" title=\"1. mongo docker image\"></a>1. mongo docker image</h3><p>Start the Database<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker run --name mymongo -d mongo:&lt;label&gt; --auth</div></pre></td></tr></table></figure></p>\n<p>Add the Initial Admin User<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ docker exec -it mymongo mongo admin</div><div class=\"line\">connecting to: admin</div><div class=\"line\">&gt; db.createUser(&#123; user: &apos;jsmith&apos;, pwd: &apos;some-initial-password&apos;, roles: [ &#123; role: &quot;userAdminAnyDatabase&quot;, db: &quot;admin&quot; &#125; ] &#125;);</div><div class=\"line\">Successfully added user: &#123;</div><div class=\"line\">    &quot;user&quot; : &quot;jsmith&quot;,</div><div class=\"line\">    &quot;roles&quot; : [</div><div class=\"line\">        &#123;</div><div class=\"line\">            &quot;role&quot; : &quot;userAdminAnyDatabase&quot;,</div><div class=\"line\">            &quot;db&quot; : &quot;admin&quot;</div><div class=\"line\">        &#125;</div><div class=\"line\">    ]</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h3 id=\"2-mongo-backup-and-restore\"><a href=\"#2-mongo-backup-and-restore\" class=\"headerlink\" title=\"2. mongo backup and restore\"></a>2. mongo backup and restore</h3>"},{"title":"Kubernetes","_content":"\n## MiniKube\n环境: MacOS, virtualbox, minikube v0.18.0, kubectl v1.6.0\n\nKubernetes将底层的计算资源连接在一起对外体现为一个计算集群，并将资源高度抽象化。部署应用时Kubernetes会以更高效的方式自动的将应用分发到集群内的机器上面，并调度运行。\n\n## 搭建Kubernetes集群\nKubernetes集群包含两种类型的资源：\n- Master节点：协调控制整个集群。Master负责管理整个集群，协调集群内的所有行为。比如调度应用，监控应用的状态等。\n- Nodes节点：运行应用的工作节点。Node节点负责运行应用，一般是一台物理机或者虚机。每个Node节点上面都有一个Kubelet，它是一个代理程序，用来管理该节点以及和Master节点通信。除此以外，Node节点上还会有一些管理容器的工具，比如Docker或者rkt等。生产环境中一个Kubernetes集群至少应该包含三个Nodes节点。\n\n当部署应用的时候，我们通知Master节点启动应用容器。然后Master会调度这些应用将它们运行在Node节点上面。Node节点和Master节点通过Master节点暴露的Kubernetes API通信。当然我们也可以直接通过这些API和集群交互。\n![kubernetes Cluster](http://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_01_cluster.svg)\n\nKubernetes提供了一个轻量级的Minikube应用，利用它我们可以很容器的创建一个只包含一个Node节点的Kubernetes Cluster用于日常的开发测试。\n\n### 安装\nMinikube的安装可以参考: Minikube的Github：https://github.com/kubernetes/minikube\n\n要正常使用，还必须安装kubectl，并且放在PATH里面。kubectl是一个通过Kubernetes API和Kubernetes集群交互的命令行工具。\n\n### ONLY FOR CHINESE\nKubernetes在部署容器应用的时候会先拉一个pause镜像，这个是一个基础容器，主要是负责网络部分的功能的，具体这里不展开讨论。最关键的是Kubernetes里面镜像默认都是从Google的镜像仓库拉的（就跟docker默认从docker hub拉的一样），但是因为GFW的原因，中国用户是访问不了Google的镜像仓库gcr.io的（如果你可以ping通，那恭喜你）。庆幸的是这个镜像被传到了docker hub上面，虽然中国用户访问后者也非常艰难，但通过一些加速器之类的还是可以pull下来的。如果没有VPN等科学上网的工具的话，请先做如下操作：\n\nSee: https://github.com/kubernetes/kubernetes/issues/6888\n\n```\nminikube ssh    # 登录到我们的Kubernetes VM里面去\ndocker pull registry.hnaresearch.com/public/pause-amd64:3.0  \ndocker tag registry.hnaresearch.com/public/pause-amd64:3.0 gcr.io/google_containers/pause-amd64:3.0  \n```\n这样Kubernetes VM就不会从gcr.io拉镜像了，而是会直接使用本地的镜像。\n\n## 部署应用\n\n在Kubernetes Cluster上面部署应用，我们需要先创建一个Kubernetes Deployment。这个Deployment负责创建和更新我们的应用实例。当这个Deployment创建之后，Kubernetes master就会将这个Deployment创建出来的应用实例部署到集群内某个Node节点上。而且自应用实例创建后，Deployment controller还会持续监控应用，直到应用被删除或者部署应用的Node节点不存在。\n>A Deployment is responsible for creating and updating instances of your application.\n\n![](http://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_02_first_app.svg)\n\n使用kubectl来创建Deployment，创建的时候需要制定容器镜像以及我们要启动的个数（replicas），当然这些信息后面可以再更新。这里我用Go写了一个简单的Webserver，返回“Hello World”，监听端口是8090.我们就来启动这个应用.\n```\nkubectl run helloworld --image=registry.hnaresearch.com/public/hello-world:v1.0 --port=8090\n```\n执行后master寻找一个合适的node来部署我们的应用实例（我们只有一个node）。我们可以使用kubectl get deployment来查看我们创建的Deployment：\n```\nkubectl get deployment\n```\n默认应用部署好之后是只在Kubernetes Cluster内部可见的，有多种方法可以让我们的应用暴露到外部，这里先介绍一种简单的：我们可以通过kubectl proxy命令在我们的终端和Kubernetes Cluster直接创建一个代理。然后，打开一个新的终端，通过Pod名(Pod后面会有讲到，可以通过kubectl get pod查看Pod名字)就可以访问了：\n```\nxis-macbook-pro:~ xiningwang$ kubectl get pod\nNAME                             READY     STATUS             RESTARTS   AGE\nhello-minikube-938614450-xjl4s   0/1       ImagePullBackOff   0          15h\nhelloworld-2790924137-bvfhn      1/1       Running            0          2m\n\nxis-macbook-pro:~ xiningwang$ curl http://localhost:8001/api/v1/proxy/namespaces/default/pods/helloworld-2790924137-bvfhn/\nHello world !\nhostname:helloworld-2790924137-bvfhn\n```\n\n## Pod\nPod是Kubernetes中一个非常重要的概念，也是区别于其他编排系统的一个设计. Deployment执行时并不是直接创建了容器实例，而是先在Node上面创建了Pod，然后再在Pod里面创建容器。那Pod到底是什么？Pod是Kubernetes里面抽象出来的一个概念，它是能够被创建、调度和管理的最小单元；每个Pod都有一个独立的IP；一个Pod由若干个容器构成。一个Pod之内的容器共享Pod的所有资源，这些资源主要包括：共享存储（以Volumes的形式）、共享网络、共享端口等。Kubernetes虽然也是一个容器编排系统，但不同于其他系统，它的最小操作单元不是单个容器，而是Pod。这个特性给Kubernetes带来了很多优势，比如最显而易见的是同一个Pod内的容器可以非常方便的互相访问（通过localhost就可以访问）和共享数据。\n\n> A Pod is a group of one or more application containers (such as Docker or rkt) and includes shared storage (volumes), IP address and information about how to run them.\n\n![pod](http://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_03_pods.svg)\n\n>A Node is a group of one ore more pods and includes the kubelet and container engine.  \n>\n>Containers should only be scheduled together in a single Pod if they are tightly coupled and need to share resources such as disk.\n\n![node](http://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_03_nodes.svg)\n\n## Service\n通过proxy实现集群外部可以访问的方式是不太适用于实际生产环境的。[Service](id:service)是Kubernetes里面抽象出来的一层，它定义了由多个Pods组成的逻辑组（logical set），可以对组内的Pod做一些事情：\n- 对外暴露流量\n- 做负载均衡（load balancing）\n- 服务发现（service-discovery）\n\n> A Kubernetes Service is an abstraction layer which defines a logical set of Pods and enables external traffic exposure, load balancing and service discovery for those Pods.\n\n而且每个Service都有一个集群内唯一的私有IP和对外的端口，用于接收流量。如果我们想将一个Service暴露到集群外，有两种方法：\n- LoadBalancer - 提供一个公网的IP\n- NodePort - 使用NAT将Service的端口暴露出去。Minikube只支持这种方式。\n\n![service](http://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_04_services.svg)\n\n\n使用kubectl get service可以查看目前已有的service，Minikube默认创建了一个kubernetes Service。我们使用expose命令再创建一个Service：\n```\nxis-macbook-pro:~ xiningwang$ kubectl get service\nNAME             CLUSTER-IP   EXTERNAL-IP   PORT(S)          AGE\nhello-minikube   10.0.0.188   <nodes>       8080:32710/TCP   16h\nkubernetes       10.0.0.1     <none>        443/TCP          16h\nxis-macbook-pro:~ xiningwang$ kubectl expose deployment/helloworld --type=\"NodePort\" --port 8090\nservice \"helloworld\" exposed\nxis-macbook-pro:~ xiningwang$ kubectl get service\nNAME             CLUSTER-IP   EXTERNAL-IP   PORT(S)          AGE\nhello-minikube   10.0.0.188   <nodes>       8080:32710/TCP   16h\nhelloworld       10.0.0.249   <nodes>       8090:31240/TCP   2m\nkubernetes       10.0.0.1     <none>        443/TCP          16h\nxis-macbook-pro:~ xiningwang$ kubectl delete service hello-minikube\nservice \"hello-minikube\" deleted\nxis-macbook-pro:~ xiningwang$ kubectl get service\nNAME         CLUSTER-IP   EXTERNAL-IP   PORT(S)          AGE\nhelloworld   10.0.0.249   <nodes>       8090:31240/TCP   2m\nkubernetes   10.0.0.1     <none>        443/TCP          16h\nxis-macbook-pro:~ xiningwang$ kubectl describe service/helloworld\nName:  \t\t\thelloworld\nNamespace:     \t\tdefault\nLabels:\t\t\trun=helloworld\nAnnotations:   \t\t<none>\nSelector:      \t\trun=helloworld\nType:  \t\t\tNodePort\nIP:    \t\t\t10.0.0.249\nPort:  \t\t\t<unset>\t8090/TCP\nNodePort:      \t\t<unset>\t31240/TCP\nEndpoints:     \t\t172.17.0.3:8090\nSession Affinity:      \tNone\nEvents:\t\t\t<none>\nxis-macbook-pro:~ xiningwang$ minikube docker-env\nexport DOCKER_TLS_VERIFY=\"1\"\nexport DOCKER_HOST=\"tcp://192.168.99.100:2376\"\nexport DOCKER_CERT_PATH=\"/Users/xiningwang/.minikube/certs\"\nexport DOCKER_API_VERSION=\"1.23\"\n# Run this command to configure your shell:\n# eval $(minikube docker-env)\nxis-macbook-pro:~ xiningwang$ curl http://192.168.99.100:31240\nHello world !\nhostname:helloworld-2790924137-bvfhn\n```\n\n## Label\nService就是靠Label选择器（Label Selectors）来匹配组内的Pod的，而且很多命令都可以操作Label。Label是绑定在对象上（比如Pod）的键值对，主要用来把一些相关的对象组织在一起，并且对于用户来说label是有含义的，比如：\n- Production environment (production, test, dev)\n- Application version (beta, v1.3)\n- Type of service/server (frontend, backend, database)\n\n>    Labels are key/value pairs that are attached to objects\n\n![Label](http://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_04_labels.svg)\n\n### Pod创建时默认创建的Label\n```\nxis-macbook-pro:~ xiningwang$ kubectl describe pod helloworld-2790924137-bvfhn\nName:  \t\thelloworld-2790924137-bvfhn\nNamespace:     \tdefault\nNode:  \t\tminikube/192.168.99.100\nStart Time:    \tFri, 05 May 2017 14:03:56 +0800\nLabels:\t\tpod-template-hash=2790924137\n       \t\trun=helloworld\n```\n\n### 新增一个Label\n\n```\nxis-macbook-pro:~ xiningwang$ kubectl label pod helloworld-2790924137-bvfhn app=v1\npod \"helloworld-2790924137-bvfhn\" labeled\nxis-macbook-pro:~ xiningwang$ kubectl describe pod helloworld-2790924137-bvfhn\nName:  \t\thelloworld-2790924137-bvfhn\nNamespace:     \tdefault\nNode:  \t\tminikube/192.168.99.100\nStart Time:    \tFri, 05 May 2017 14:03:56 +0800\nLabels:\t\tapp=v1\n       \t\tpod-template-hash=2790924137\n       \t\trun=helloworld\n```\n\n### 使用Label的例子\n\n```\nxis-macbook-pro:~ xiningwang$ kubectl get service\nNAME         CLUSTER-IP   EXTERNAL-IP   PORT(S)          AGE\nhelloworld   10.0.0.249   <nodes>       8090:31240/TCP   46m\nkubernetes   10.0.0.1     <none>        443/TCP          17h\nxis-macbook-pro:~ xiningwang$ kubectl get service  -l run=helloworld\nNAME         CLUSTER-IP   EXTERNAL-IP   PORT(S)          AGE\nhelloworld   10.0.0.249   <nodes>       8090:31240/TCP   46m\nxis-macbook-pro:~ xiningwang$ kubectl get pod -l app=v1\nNAME                          READY     STATUS    RESTARTS   AGE\nhelloworld-2790924137-bvfhn   1/1       Running   0          1h\nxis-macbook-pro:~ xiningwang$ kubectl get pod\nNAME                             READY     STATUS             RESTARTS   AGE\nhello-minikube-938614450-b7xwm   0/1       ImagePullBackOff   0          38m\nhelloworld-2790924137-bvfhn      1/1       Running            0          1h\n```\n## Scale\n随着流量的增加，我们可能需要增加我们应用的规模来满足用户的需求。Kubernetes的Scale功能就可以实现这个需求。\n>    Scaling is accomplished by changing the number of replicas in a Deployment.\n\n扩大应用的规模时，Kubernetes将会在Nodes上面使用可用的资源来创建新的Pod，并运行新增加的应用，缩小规模时做相反的操作。Kubernetes也支持自动规模化Pod。当然我们也可以将应用的数量变为0，这样就会终止所有部署该应用的Pods。应用数量增加后，Service内的负载均衡就会变得非常有用了.\n\n![scale](https://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_05_scaling1.svg)\n\n\n![scale](https://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_05_scaling2.svg)\n\n```\nxis-macbook-pro:~ xiningwang$ kubectl get deployment\nNAME         DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE\nhelloworld   1         1         1            1           2h\n```\n可以看到，现在我们只有一个Pod，\n- DESIRED字段表示我们配置的replicas的个数，即实例的个数。\n- CURRENT字段表示目前处于running状态的replicas的个数。\n- UP-TO-DATE字段表示表示和预先配置的期望状态相符的replicas的个数。\n- AVAILABLE字段表示目前实际对用户可用的replicas的个数。\n\n下面我们使用kubectl scale命令将启动4个复制品，语法规则是kubectl scale deployment-type name replicas-number：\n```\nxis-macbook-pro:~ xiningwang$ kubectl scale deployment/helloworld --replicas=4\ndeployment \"helloworld\" scaled\nxis-macbook-pro:~ xiningwang$ kubectl get deployment\nNAME         DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE\nhelloworld   4         4         4            4           2h\n\nxis-macbook-pro:~ xiningwang$ kubectl get pod -o wide\nNAME                          READY     STATUS    RESTARTS   AGE       IP           NODE\nhelloworld-2790924137-2kg70   1/1       Running   0          3m        172.17.0.4   minikube\nhelloworld-2790924137-bvfhn   1/1       Running   0          2h        172.17.0.3   minikube\nhelloworld-2790924137-jg15m   1/1       Running   0          3m        172.17.0.5   minikube\nhelloworld-2790924137-tgqr9   1/1       Running   0          3m        172.17.0.2   minikube\n```\n验证一下这个Service是有负载均衡的：\n```\nxis-macbook-pro:~ xiningwang$ kubectl get deployment\nNAME         DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE\nhelloworld   4         4         4            4           2h\nxis-macbook-pro:~ xiningwang$ curl 192.168.99.100:31240\nHello world !\nhostname:helloworld-2790924137-bvfhn\nxis-macbook-pro:~ xiningwang$ curl 192.168.99.100:31240\nHello world !\nhostname:helloworld-2790924137-tgqr9\nxis-macbook-pro:~ xiningwang$ curl 192.168.99.100:31240\nHello world !\nhostname:helloworld-2790924137-2kg70\nxis-macbook-pro:~ xiningwang$ curl 192.168.99.100:31240\nHello world !\nhostname:helloworld-2790924137-bvfhn\nxis-macbook-pro:~ xiningwang$ curl 192.168.99.100:31240\nHello world !\nhostname:helloworld-2790924137-tgqr9\n```\n## Rolling Update\n滚动更新（Rolling update）特性的好处就是我们不用停止服务就可以实现应用更新。默认更新的时候是一个Pod一个Pod更新的，所以整个过程服务不会中断。当然你也可以设置一次更新的Pod的百分比。而且更新过程中，Service只会将流量转发到可用的节点上面。更加重要的是，我们可以随时回退到旧版本。\n>Rolling updates allow Deployments' update to take place with zero downtime by incrementally updating Pods instances with new ones.\nIf a Deployment is exposed publicly, the Service will load-balance the traffic only to available Pods during the update.\n\n![rollingupdate](https://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_06_rollingupdates1.svg)\n![rollingupdate](https://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_06_rollingupdates2.svg)\n![rollingupdate](https://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_06_rollingupdates3.svg)\n![rollingupdate](https://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_06_rollingupdates4.svg)\n\n在原来程序的基础上，多输出一个v2作为新版本，使用set image命令指定新版本镜像.\n```\nxis-macbook-pro:~ xiningwang$ kubectl set image deployments/helloworld helloworld=registry.hnaresearch.com/public/hello-world:v2.0\ndeployment \"helloworld\" image updated\nxis-macbook-pro:~ xiningwang$ kubectl get pods\nNAME                          READY     STATUS              RESTARTS   AGE\nhelloworld-2790924137-2kg70   1/1       Running             0          54m\nhelloworld-2790924137-bvfhn   1/1       Running             0          3h\nhelloworld-2790924137-tgqr9   1/1       Running             0          54m\nhelloworld-2889228138-65lmj   0/1       ContainerCreating   0          9m\nhelloworld-2889228138-q68vx   0/1       ContainerCreating   0          9m\nxis-macbook-pro:~ xiningwang$ kubectl get pods\nNAME                          READY     STATUS              RESTARTS   AGE\nhelloworld-2790924137-2kg70   1/1       Terminating         0          54m\nhelloworld-2790924137-bvfhn   1/1       Running             0          3h\nhelloworld-2790924137-tgqr9   0/1       Terminating         0          54m\nhelloworld-2889228138-65lmj   0/1       ContainerCreating   0          9m\nhelloworld-2889228138-bj38m   0/1       Pending             0          9m\nhelloworld-2889228138-dv3ch   1/1       Running             0          9m\nhelloworld-2889228138-q68vx   1/1       Running             0          9m\nxis-macbook-pro:~ xiningwang$ kubectl get pods\nNAME                          READY     STATUS    RESTARTS   AGE\nhelloworld-2889228138-65lmj   1/1       Running   0          10m\nhelloworld-2889228138-bj38m   1/1       Running   0          10m\nhelloworld-2889228138-dv3ch   1/1       Running   0          10m\nhelloworld-2889228138-q68vx   1/1       Running   0          10m\n```\n\n使用kubectl rollout undo命令回滚到之前的版本：\n```\nxis-macbook-pro:~ xiningwang$ kubectl rollout undo deployment/helloworld\ndeployment \"helloworld\" rolled back\n```\n","source":"_posts/kubernetes.md","raw":"---\ntitle: Kubernetes\n---\n\n## MiniKube\n环境: MacOS, virtualbox, minikube v0.18.0, kubectl v1.6.0\n\nKubernetes将底层的计算资源连接在一起对外体现为一个计算集群，并将资源高度抽象化。部署应用时Kubernetes会以更高效的方式自动的将应用分发到集群内的机器上面，并调度运行。\n\n## 搭建Kubernetes集群\nKubernetes集群包含两种类型的资源：\n- Master节点：协调控制整个集群。Master负责管理整个集群，协调集群内的所有行为。比如调度应用，监控应用的状态等。\n- Nodes节点：运行应用的工作节点。Node节点负责运行应用，一般是一台物理机或者虚机。每个Node节点上面都有一个Kubelet，它是一个代理程序，用来管理该节点以及和Master节点通信。除此以外，Node节点上还会有一些管理容器的工具，比如Docker或者rkt等。生产环境中一个Kubernetes集群至少应该包含三个Nodes节点。\n\n当部署应用的时候，我们通知Master节点启动应用容器。然后Master会调度这些应用将它们运行在Node节点上面。Node节点和Master节点通过Master节点暴露的Kubernetes API通信。当然我们也可以直接通过这些API和集群交互。\n![kubernetes Cluster](http://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_01_cluster.svg)\n\nKubernetes提供了一个轻量级的Minikube应用，利用它我们可以很容器的创建一个只包含一个Node节点的Kubernetes Cluster用于日常的开发测试。\n\n### 安装\nMinikube的安装可以参考: Minikube的Github：https://github.com/kubernetes/minikube\n\n要正常使用，还必须安装kubectl，并且放在PATH里面。kubectl是一个通过Kubernetes API和Kubernetes集群交互的命令行工具。\n\n### ONLY FOR CHINESE\nKubernetes在部署容器应用的时候会先拉一个pause镜像，这个是一个基础容器，主要是负责网络部分的功能的，具体这里不展开讨论。最关键的是Kubernetes里面镜像默认都是从Google的镜像仓库拉的（就跟docker默认从docker hub拉的一样），但是因为GFW的原因，中国用户是访问不了Google的镜像仓库gcr.io的（如果你可以ping通，那恭喜你）。庆幸的是这个镜像被传到了docker hub上面，虽然中国用户访问后者也非常艰难，但通过一些加速器之类的还是可以pull下来的。如果没有VPN等科学上网的工具的话，请先做如下操作：\n\nSee: https://github.com/kubernetes/kubernetes/issues/6888\n\n```\nminikube ssh    # 登录到我们的Kubernetes VM里面去\ndocker pull registry.hnaresearch.com/public/pause-amd64:3.0  \ndocker tag registry.hnaresearch.com/public/pause-amd64:3.0 gcr.io/google_containers/pause-amd64:3.0  \n```\n这样Kubernetes VM就不会从gcr.io拉镜像了，而是会直接使用本地的镜像。\n\n## 部署应用\n\n在Kubernetes Cluster上面部署应用，我们需要先创建一个Kubernetes Deployment。这个Deployment负责创建和更新我们的应用实例。当这个Deployment创建之后，Kubernetes master就会将这个Deployment创建出来的应用实例部署到集群内某个Node节点上。而且自应用实例创建后，Deployment controller还会持续监控应用，直到应用被删除或者部署应用的Node节点不存在。\n>A Deployment is responsible for creating and updating instances of your application.\n\n![](http://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_02_first_app.svg)\n\n使用kubectl来创建Deployment，创建的时候需要制定容器镜像以及我们要启动的个数（replicas），当然这些信息后面可以再更新。这里我用Go写了一个简单的Webserver，返回“Hello World”，监听端口是8090.我们就来启动这个应用.\n```\nkubectl run helloworld --image=registry.hnaresearch.com/public/hello-world:v1.0 --port=8090\n```\n执行后master寻找一个合适的node来部署我们的应用实例（我们只有一个node）。我们可以使用kubectl get deployment来查看我们创建的Deployment：\n```\nkubectl get deployment\n```\n默认应用部署好之后是只在Kubernetes Cluster内部可见的，有多种方法可以让我们的应用暴露到外部，这里先介绍一种简单的：我们可以通过kubectl proxy命令在我们的终端和Kubernetes Cluster直接创建一个代理。然后，打开一个新的终端，通过Pod名(Pod后面会有讲到，可以通过kubectl get pod查看Pod名字)就可以访问了：\n```\nxis-macbook-pro:~ xiningwang$ kubectl get pod\nNAME                             READY     STATUS             RESTARTS   AGE\nhello-minikube-938614450-xjl4s   0/1       ImagePullBackOff   0          15h\nhelloworld-2790924137-bvfhn      1/1       Running            0          2m\n\nxis-macbook-pro:~ xiningwang$ curl http://localhost:8001/api/v1/proxy/namespaces/default/pods/helloworld-2790924137-bvfhn/\nHello world !\nhostname:helloworld-2790924137-bvfhn\n```\n\n## Pod\nPod是Kubernetes中一个非常重要的概念，也是区别于其他编排系统的一个设计. Deployment执行时并不是直接创建了容器实例，而是先在Node上面创建了Pod，然后再在Pod里面创建容器。那Pod到底是什么？Pod是Kubernetes里面抽象出来的一个概念，它是能够被创建、调度和管理的最小单元；每个Pod都有一个独立的IP；一个Pod由若干个容器构成。一个Pod之内的容器共享Pod的所有资源，这些资源主要包括：共享存储（以Volumes的形式）、共享网络、共享端口等。Kubernetes虽然也是一个容器编排系统，但不同于其他系统，它的最小操作单元不是单个容器，而是Pod。这个特性给Kubernetes带来了很多优势，比如最显而易见的是同一个Pod内的容器可以非常方便的互相访问（通过localhost就可以访问）和共享数据。\n\n> A Pod is a group of one or more application containers (such as Docker or rkt) and includes shared storage (volumes), IP address and information about how to run them.\n\n![pod](http://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_03_pods.svg)\n\n>A Node is a group of one ore more pods and includes the kubelet and container engine.  \n>\n>Containers should only be scheduled together in a single Pod if they are tightly coupled and need to share resources such as disk.\n\n![node](http://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_03_nodes.svg)\n\n## Service\n通过proxy实现集群外部可以访问的方式是不太适用于实际生产环境的。[Service](id:service)是Kubernetes里面抽象出来的一层，它定义了由多个Pods组成的逻辑组（logical set），可以对组内的Pod做一些事情：\n- 对外暴露流量\n- 做负载均衡（load balancing）\n- 服务发现（service-discovery）\n\n> A Kubernetes Service is an abstraction layer which defines a logical set of Pods and enables external traffic exposure, load balancing and service discovery for those Pods.\n\n而且每个Service都有一个集群内唯一的私有IP和对外的端口，用于接收流量。如果我们想将一个Service暴露到集群外，有两种方法：\n- LoadBalancer - 提供一个公网的IP\n- NodePort - 使用NAT将Service的端口暴露出去。Minikube只支持这种方式。\n\n![service](http://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_04_services.svg)\n\n\n使用kubectl get service可以查看目前已有的service，Minikube默认创建了一个kubernetes Service。我们使用expose命令再创建一个Service：\n```\nxis-macbook-pro:~ xiningwang$ kubectl get service\nNAME             CLUSTER-IP   EXTERNAL-IP   PORT(S)          AGE\nhello-minikube   10.0.0.188   <nodes>       8080:32710/TCP   16h\nkubernetes       10.0.0.1     <none>        443/TCP          16h\nxis-macbook-pro:~ xiningwang$ kubectl expose deployment/helloworld --type=\"NodePort\" --port 8090\nservice \"helloworld\" exposed\nxis-macbook-pro:~ xiningwang$ kubectl get service\nNAME             CLUSTER-IP   EXTERNAL-IP   PORT(S)          AGE\nhello-minikube   10.0.0.188   <nodes>       8080:32710/TCP   16h\nhelloworld       10.0.0.249   <nodes>       8090:31240/TCP   2m\nkubernetes       10.0.0.1     <none>        443/TCP          16h\nxis-macbook-pro:~ xiningwang$ kubectl delete service hello-minikube\nservice \"hello-minikube\" deleted\nxis-macbook-pro:~ xiningwang$ kubectl get service\nNAME         CLUSTER-IP   EXTERNAL-IP   PORT(S)          AGE\nhelloworld   10.0.0.249   <nodes>       8090:31240/TCP   2m\nkubernetes   10.0.0.1     <none>        443/TCP          16h\nxis-macbook-pro:~ xiningwang$ kubectl describe service/helloworld\nName:  \t\t\thelloworld\nNamespace:     \t\tdefault\nLabels:\t\t\trun=helloworld\nAnnotations:   \t\t<none>\nSelector:      \t\trun=helloworld\nType:  \t\t\tNodePort\nIP:    \t\t\t10.0.0.249\nPort:  \t\t\t<unset>\t8090/TCP\nNodePort:      \t\t<unset>\t31240/TCP\nEndpoints:     \t\t172.17.0.3:8090\nSession Affinity:      \tNone\nEvents:\t\t\t<none>\nxis-macbook-pro:~ xiningwang$ minikube docker-env\nexport DOCKER_TLS_VERIFY=\"1\"\nexport DOCKER_HOST=\"tcp://192.168.99.100:2376\"\nexport DOCKER_CERT_PATH=\"/Users/xiningwang/.minikube/certs\"\nexport DOCKER_API_VERSION=\"1.23\"\n# Run this command to configure your shell:\n# eval $(minikube docker-env)\nxis-macbook-pro:~ xiningwang$ curl http://192.168.99.100:31240\nHello world !\nhostname:helloworld-2790924137-bvfhn\n```\n\n## Label\nService就是靠Label选择器（Label Selectors）来匹配组内的Pod的，而且很多命令都可以操作Label。Label是绑定在对象上（比如Pod）的键值对，主要用来把一些相关的对象组织在一起，并且对于用户来说label是有含义的，比如：\n- Production environment (production, test, dev)\n- Application version (beta, v1.3)\n- Type of service/server (frontend, backend, database)\n\n>    Labels are key/value pairs that are attached to objects\n\n![Label](http://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_04_labels.svg)\n\n### Pod创建时默认创建的Label\n```\nxis-macbook-pro:~ xiningwang$ kubectl describe pod helloworld-2790924137-bvfhn\nName:  \t\thelloworld-2790924137-bvfhn\nNamespace:     \tdefault\nNode:  \t\tminikube/192.168.99.100\nStart Time:    \tFri, 05 May 2017 14:03:56 +0800\nLabels:\t\tpod-template-hash=2790924137\n       \t\trun=helloworld\n```\n\n### 新增一个Label\n\n```\nxis-macbook-pro:~ xiningwang$ kubectl label pod helloworld-2790924137-bvfhn app=v1\npod \"helloworld-2790924137-bvfhn\" labeled\nxis-macbook-pro:~ xiningwang$ kubectl describe pod helloworld-2790924137-bvfhn\nName:  \t\thelloworld-2790924137-bvfhn\nNamespace:     \tdefault\nNode:  \t\tminikube/192.168.99.100\nStart Time:    \tFri, 05 May 2017 14:03:56 +0800\nLabels:\t\tapp=v1\n       \t\tpod-template-hash=2790924137\n       \t\trun=helloworld\n```\n\n### 使用Label的例子\n\n```\nxis-macbook-pro:~ xiningwang$ kubectl get service\nNAME         CLUSTER-IP   EXTERNAL-IP   PORT(S)          AGE\nhelloworld   10.0.0.249   <nodes>       8090:31240/TCP   46m\nkubernetes   10.0.0.1     <none>        443/TCP          17h\nxis-macbook-pro:~ xiningwang$ kubectl get service  -l run=helloworld\nNAME         CLUSTER-IP   EXTERNAL-IP   PORT(S)          AGE\nhelloworld   10.0.0.249   <nodes>       8090:31240/TCP   46m\nxis-macbook-pro:~ xiningwang$ kubectl get pod -l app=v1\nNAME                          READY     STATUS    RESTARTS   AGE\nhelloworld-2790924137-bvfhn   1/1       Running   0          1h\nxis-macbook-pro:~ xiningwang$ kubectl get pod\nNAME                             READY     STATUS             RESTARTS   AGE\nhello-minikube-938614450-b7xwm   0/1       ImagePullBackOff   0          38m\nhelloworld-2790924137-bvfhn      1/1       Running            0          1h\n```\n## Scale\n随着流量的增加，我们可能需要增加我们应用的规模来满足用户的需求。Kubernetes的Scale功能就可以实现这个需求。\n>    Scaling is accomplished by changing the number of replicas in a Deployment.\n\n扩大应用的规模时，Kubernetes将会在Nodes上面使用可用的资源来创建新的Pod，并运行新增加的应用，缩小规模时做相反的操作。Kubernetes也支持自动规模化Pod。当然我们也可以将应用的数量变为0，这样就会终止所有部署该应用的Pods。应用数量增加后，Service内的负载均衡就会变得非常有用了.\n\n![scale](https://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_05_scaling1.svg)\n\n\n![scale](https://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_05_scaling2.svg)\n\n```\nxis-macbook-pro:~ xiningwang$ kubectl get deployment\nNAME         DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE\nhelloworld   1         1         1            1           2h\n```\n可以看到，现在我们只有一个Pod，\n- DESIRED字段表示我们配置的replicas的个数，即实例的个数。\n- CURRENT字段表示目前处于running状态的replicas的个数。\n- UP-TO-DATE字段表示表示和预先配置的期望状态相符的replicas的个数。\n- AVAILABLE字段表示目前实际对用户可用的replicas的个数。\n\n下面我们使用kubectl scale命令将启动4个复制品，语法规则是kubectl scale deployment-type name replicas-number：\n```\nxis-macbook-pro:~ xiningwang$ kubectl scale deployment/helloworld --replicas=4\ndeployment \"helloworld\" scaled\nxis-macbook-pro:~ xiningwang$ kubectl get deployment\nNAME         DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE\nhelloworld   4         4         4            4           2h\n\nxis-macbook-pro:~ xiningwang$ kubectl get pod -o wide\nNAME                          READY     STATUS    RESTARTS   AGE       IP           NODE\nhelloworld-2790924137-2kg70   1/1       Running   0          3m        172.17.0.4   minikube\nhelloworld-2790924137-bvfhn   1/1       Running   0          2h        172.17.0.3   minikube\nhelloworld-2790924137-jg15m   1/1       Running   0          3m        172.17.0.5   minikube\nhelloworld-2790924137-tgqr9   1/1       Running   0          3m        172.17.0.2   minikube\n```\n验证一下这个Service是有负载均衡的：\n```\nxis-macbook-pro:~ xiningwang$ kubectl get deployment\nNAME         DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE\nhelloworld   4         4         4            4           2h\nxis-macbook-pro:~ xiningwang$ curl 192.168.99.100:31240\nHello world !\nhostname:helloworld-2790924137-bvfhn\nxis-macbook-pro:~ xiningwang$ curl 192.168.99.100:31240\nHello world !\nhostname:helloworld-2790924137-tgqr9\nxis-macbook-pro:~ xiningwang$ curl 192.168.99.100:31240\nHello world !\nhostname:helloworld-2790924137-2kg70\nxis-macbook-pro:~ xiningwang$ curl 192.168.99.100:31240\nHello world !\nhostname:helloworld-2790924137-bvfhn\nxis-macbook-pro:~ xiningwang$ curl 192.168.99.100:31240\nHello world !\nhostname:helloworld-2790924137-tgqr9\n```\n## Rolling Update\n滚动更新（Rolling update）特性的好处就是我们不用停止服务就可以实现应用更新。默认更新的时候是一个Pod一个Pod更新的，所以整个过程服务不会中断。当然你也可以设置一次更新的Pod的百分比。而且更新过程中，Service只会将流量转发到可用的节点上面。更加重要的是，我们可以随时回退到旧版本。\n>Rolling updates allow Deployments' update to take place with zero downtime by incrementally updating Pods instances with new ones.\nIf a Deployment is exposed publicly, the Service will load-balance the traffic only to available Pods during the update.\n\n![rollingupdate](https://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_06_rollingupdates1.svg)\n![rollingupdate](https://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_06_rollingupdates2.svg)\n![rollingupdate](https://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_06_rollingupdates3.svg)\n![rollingupdate](https://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_06_rollingupdates4.svg)\n\n在原来程序的基础上，多输出一个v2作为新版本，使用set image命令指定新版本镜像.\n```\nxis-macbook-pro:~ xiningwang$ kubectl set image deployments/helloworld helloworld=registry.hnaresearch.com/public/hello-world:v2.0\ndeployment \"helloworld\" image updated\nxis-macbook-pro:~ xiningwang$ kubectl get pods\nNAME                          READY     STATUS              RESTARTS   AGE\nhelloworld-2790924137-2kg70   1/1       Running             0          54m\nhelloworld-2790924137-bvfhn   1/1       Running             0          3h\nhelloworld-2790924137-tgqr9   1/1       Running             0          54m\nhelloworld-2889228138-65lmj   0/1       ContainerCreating   0          9m\nhelloworld-2889228138-q68vx   0/1       ContainerCreating   0          9m\nxis-macbook-pro:~ xiningwang$ kubectl get pods\nNAME                          READY     STATUS              RESTARTS   AGE\nhelloworld-2790924137-2kg70   1/1       Terminating         0          54m\nhelloworld-2790924137-bvfhn   1/1       Running             0          3h\nhelloworld-2790924137-tgqr9   0/1       Terminating         0          54m\nhelloworld-2889228138-65lmj   0/1       ContainerCreating   0          9m\nhelloworld-2889228138-bj38m   0/1       Pending             0          9m\nhelloworld-2889228138-dv3ch   1/1       Running             0          9m\nhelloworld-2889228138-q68vx   1/1       Running             0          9m\nxis-macbook-pro:~ xiningwang$ kubectl get pods\nNAME                          READY     STATUS    RESTARTS   AGE\nhelloworld-2889228138-65lmj   1/1       Running   0          10m\nhelloworld-2889228138-bj38m   1/1       Running   0          10m\nhelloworld-2889228138-dv3ch   1/1       Running   0          10m\nhelloworld-2889228138-q68vx   1/1       Running   0          10m\n```\n\n使用kubectl rollout undo命令回滚到之前的版本：\n```\nxis-macbook-pro:~ xiningwang$ kubectl rollout undo deployment/helloworld\ndeployment \"helloworld\" rolled back\n```\n","slug":"kubernetes","published":1,"date":"2017-05-05T03:00:22.000Z","updated":"2017-05-08T13:29:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj2g8ok3y000gdl721rordzwk","content":"<h2 id=\"MiniKube\"><a href=\"#MiniKube\" class=\"headerlink\" title=\"MiniKube\"></a>MiniKube</h2><p>环境: MacOS, virtualbox, minikube v0.18.0, kubectl v1.6.0</p>\n<p>Kubernetes将底层的计算资源连接在一起对外体现为一个计算集群，并将资源高度抽象化。部署应用时Kubernetes会以更高效的方式自动的将应用分发到集群内的机器上面，并调度运行。</p>\n<h2 id=\"搭建Kubernetes集群\"><a href=\"#搭建Kubernetes集群\" class=\"headerlink\" title=\"搭建Kubernetes集群\"></a>搭建Kubernetes集群</h2><p>Kubernetes集群包含两种类型的资源：</p>\n<ul>\n<li>Master节点：协调控制整个集群。Master负责管理整个集群，协调集群内的所有行为。比如调度应用，监控应用的状态等。</li>\n<li>Nodes节点：运行应用的工作节点。Node节点负责运行应用，一般是一台物理机或者虚机。每个Node节点上面都有一个Kubelet，它是一个代理程序，用来管理该节点以及和Master节点通信。除此以外，Node节点上还会有一些管理容器的工具，比如Docker或者rkt等。生产环境中一个Kubernetes集群至少应该包含三个Nodes节点。</li>\n</ul>\n<p>当部署应用的时候，我们通知Master节点启动应用容器。然后Master会调度这些应用将它们运行在Node节点上面。Node节点和Master节点通过Master节点暴露的Kubernetes API通信。当然我们也可以直接通过这些API和集群交互。<br><img src=\"http://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_01_cluster.svg\" alt=\"kubernetes Cluster\"></p>\n<p>Kubernetes提供了一个轻量级的Minikube应用，利用它我们可以很容器的创建一个只包含一个Node节点的Kubernetes Cluster用于日常的开发测试。</p>\n<h3 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h3><p>Minikube的安装可以参考: Minikube的Github：<a href=\"https://github.com/kubernetes/minikube\" target=\"_blank\" rel=\"external\">https://github.com/kubernetes/minikube</a></p>\n<p>要正常使用，还必须安装kubectl，并且放在PATH里面。kubectl是一个通过Kubernetes API和Kubernetes集群交互的命令行工具。</p>\n<h3 id=\"ONLY-FOR-CHINESE\"><a href=\"#ONLY-FOR-CHINESE\" class=\"headerlink\" title=\"ONLY FOR CHINESE\"></a>ONLY FOR CHINESE</h3><p>Kubernetes在部署容器应用的时候会先拉一个pause镜像，这个是一个基础容器，主要是负责网络部分的功能的，具体这里不展开讨论。最关键的是Kubernetes里面镜像默认都是从Google的镜像仓库拉的（就跟docker默认从docker hub拉的一样），但是因为GFW的原因，中国用户是访问不了Google的镜像仓库gcr.io的（如果你可以ping通，那恭喜你）。庆幸的是这个镜像被传到了docker hub上面，虽然中国用户访问后者也非常艰难，但通过一些加速器之类的还是可以pull下来的。如果没有VPN等科学上网的工具的话，请先做如下操作：</p>\n<p>See: <a href=\"https://github.com/kubernetes/kubernetes/issues/6888\" target=\"_blank\" rel=\"external\">https://github.com/kubernetes/kubernetes/issues/6888</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">minikube ssh    # 登录到我们的Kubernetes VM里面去</div><div class=\"line\">docker pull registry.hnaresearch.com/public/pause-amd64:3.0  </div><div class=\"line\">docker tag registry.hnaresearch.com/public/pause-amd64:3.0 gcr.io/google_containers/pause-amd64:3.0</div></pre></td></tr></table></figure>\n<p>这样Kubernetes VM就不会从gcr.io拉镜像了，而是会直接使用本地的镜像。</p>\n<h2 id=\"部署应用\"><a href=\"#部署应用\" class=\"headerlink\" title=\"部署应用\"></a>部署应用</h2><p>在Kubernetes Cluster上面部署应用，我们需要先创建一个Kubernetes Deployment。这个Deployment负责创建和更新我们的应用实例。当这个Deployment创建之后，Kubernetes master就会将这个Deployment创建出来的应用实例部署到集群内某个Node节点上。而且自应用实例创建后，Deployment controller还会持续监控应用，直到应用被删除或者部署应用的Node节点不存在。</p>\n<blockquote>\n<p>A Deployment is responsible for creating and updating instances of your application.</p>\n</blockquote>\n<p><img src=\"http://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_02_first_app.svg\" alt=\"\"></p>\n<p>使用kubectl来创建Deployment，创建的时候需要制定容器镜像以及我们要启动的个数（replicas），当然这些信息后面可以再更新。这里我用Go写了一个简单的Webserver，返回“Hello World”，监听端口是8090.我们就来启动这个应用.<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">kubectl run helloworld --image=registry.hnaresearch.com/public/hello-world:v1.0 --port=8090</div></pre></td></tr></table></figure></p>\n<p>执行后master寻找一个合适的node来部署我们的应用实例（我们只有一个node）。我们可以使用kubectl get deployment来查看我们创建的Deployment：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">kubectl get deployment</div></pre></td></tr></table></figure></p>\n<p>默认应用部署好之后是只在Kubernetes Cluster内部可见的，有多种方法可以让我们的应用暴露到外部，这里先介绍一种简单的：我们可以通过kubectl proxy命令在我们的终端和Kubernetes Cluster直接创建一个代理。然后，打开一个新的终端，通过Pod名(Pod后面会有讲到，可以通过kubectl get pod查看Pod名字)就可以访问了：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl get pod</div><div class=\"line\">NAME                             READY     STATUS             RESTARTS   AGE</div><div class=\"line\">hello-minikube-938614450-xjl4s   0/1       ImagePullBackOff   0          15h</div><div class=\"line\">helloworld-2790924137-bvfhn      1/1       Running            0          2m</div><div class=\"line\"></div><div class=\"line\">xis-macbook-pro:~ xiningwang$ curl http://localhost:8001/api/v1/proxy/namespaces/default/pods/helloworld-2790924137-bvfhn/</div><div class=\"line\">Hello world !</div><div class=\"line\">hostname:helloworld-2790924137-bvfhn</div></pre></td></tr></table></figure></p>\n<h2 id=\"Pod\"><a href=\"#Pod\" class=\"headerlink\" title=\"Pod\"></a>Pod</h2><p>Pod是Kubernetes中一个非常重要的概念，也是区别于其他编排系统的一个设计. Deployment执行时并不是直接创建了容器实例，而是先在Node上面创建了Pod，然后再在Pod里面创建容器。那Pod到底是什么？Pod是Kubernetes里面抽象出来的一个概念，它是能够被创建、调度和管理的最小单元；每个Pod都有一个独立的IP；一个Pod由若干个容器构成。一个Pod之内的容器共享Pod的所有资源，这些资源主要包括：共享存储（以Volumes的形式）、共享网络、共享端口等。Kubernetes虽然也是一个容器编排系统，但不同于其他系统，它的最小操作单元不是单个容器，而是Pod。这个特性给Kubernetes带来了很多优势，比如最显而易见的是同一个Pod内的容器可以非常方便的互相访问（通过localhost就可以访问）和共享数据。</p>\n<blockquote>\n<p>A Pod is a group of one or more application containers (such as Docker or rkt) and includes shared storage (volumes), IP address and information about how to run them.</p>\n</blockquote>\n<p><img src=\"http://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_03_pods.svg\" alt=\"pod\"></p>\n<blockquote>\n<p>A Node is a group of one ore more pods and includes the kubelet and container engine.  </p>\n<p>Containers should only be scheduled together in a single Pod if they are tightly coupled and need to share resources such as disk.</p>\n</blockquote>\n<p><img src=\"http://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_03_nodes.svg\" alt=\"node\"></p>\n<h2 id=\"Service\"><a href=\"#Service\" class=\"headerlink\" title=\"Service\"></a>Service</h2><p>通过proxy实现集群外部可以访问的方式是不太适用于实际生产环境的。<a href=\"id:service\" target=\"_blank\" rel=\"external\">Service</a>是Kubernetes里面抽象出来的一层，它定义了由多个Pods组成的逻辑组（logical set），可以对组内的Pod做一些事情：</p>\n<ul>\n<li>对外暴露流量</li>\n<li>做负载均衡（load balancing）</li>\n<li>服务发现（service-discovery）</li>\n</ul>\n<blockquote>\n<p>A Kubernetes Service is an abstraction layer which defines a logical set of Pods and enables external traffic exposure, load balancing and service discovery for those Pods.</p>\n</blockquote>\n<p>而且每个Service都有一个集群内唯一的私有IP和对外的端口，用于接收流量。如果我们想将一个Service暴露到集群外，有两种方法：</p>\n<ul>\n<li>LoadBalancer - 提供一个公网的IP</li>\n<li>NodePort - 使用NAT将Service的端口暴露出去。Minikube只支持这种方式。</li>\n</ul>\n<p><img src=\"http://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_04_services.svg\" alt=\"service\"></p>\n<p>使用kubectl get service可以查看目前已有的service，Minikube默认创建了一个kubernetes Service。我们使用expose命令再创建一个Service：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div></pre></td><td class=\"code\"><pre><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl get service</div><div class=\"line\">NAME             CLUSTER-IP   EXTERNAL-IP   PORT(S)          AGE</div><div class=\"line\">hello-minikube   10.0.0.188   &lt;nodes&gt;       8080:32710/TCP   16h</div><div class=\"line\">kubernetes       10.0.0.1     &lt;none&gt;        443/TCP          16h</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl expose deployment/helloworld --type=&quot;NodePort&quot; --port 8090</div><div class=\"line\">service &quot;helloworld&quot; exposed</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl get service</div><div class=\"line\">NAME             CLUSTER-IP   EXTERNAL-IP   PORT(S)          AGE</div><div class=\"line\">hello-minikube   10.0.0.188   &lt;nodes&gt;       8080:32710/TCP   16h</div><div class=\"line\">helloworld       10.0.0.249   &lt;nodes&gt;       8090:31240/TCP   2m</div><div class=\"line\">kubernetes       10.0.0.1     &lt;none&gt;        443/TCP          16h</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl delete service hello-minikube</div><div class=\"line\">service &quot;hello-minikube&quot; deleted</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl get service</div><div class=\"line\">NAME         CLUSTER-IP   EXTERNAL-IP   PORT(S)          AGE</div><div class=\"line\">helloworld   10.0.0.249   &lt;nodes&gt;       8090:31240/TCP   2m</div><div class=\"line\">kubernetes   10.0.0.1     &lt;none&gt;        443/TCP          16h</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl describe service/helloworld</div><div class=\"line\">Name:  \t\t\thelloworld</div><div class=\"line\">Namespace:     \t\tdefault</div><div class=\"line\">Labels:\t\t\trun=helloworld</div><div class=\"line\">Annotations:   \t\t&lt;none&gt;</div><div class=\"line\">Selector:      \t\trun=helloworld</div><div class=\"line\">Type:  \t\t\tNodePort</div><div class=\"line\">IP:    \t\t\t10.0.0.249</div><div class=\"line\">Port:  \t\t\t&lt;unset&gt;\t8090/TCP</div><div class=\"line\">NodePort:      \t\t&lt;unset&gt;\t31240/TCP</div><div class=\"line\">Endpoints:     \t\t172.17.0.3:8090</div><div class=\"line\">Session Affinity:      \tNone</div><div class=\"line\">Events:\t\t\t&lt;none&gt;</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ minikube docker-env</div><div class=\"line\">export DOCKER_TLS_VERIFY=&quot;1&quot;</div><div class=\"line\">export DOCKER_HOST=&quot;tcp://192.168.99.100:2376&quot;</div><div class=\"line\">export DOCKER_CERT_PATH=&quot;/Users/xiningwang/.minikube/certs&quot;</div><div class=\"line\">export DOCKER_API_VERSION=&quot;1.23&quot;</div><div class=\"line\"># Run this command to configure your shell:</div><div class=\"line\"># eval $(minikube docker-env)</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ curl http://192.168.99.100:31240</div><div class=\"line\">Hello world !</div><div class=\"line\">hostname:helloworld-2790924137-bvfhn</div></pre></td></tr></table></figure></p>\n<h2 id=\"Label\"><a href=\"#Label\" class=\"headerlink\" title=\"Label\"></a>Label</h2><p>Service就是靠Label选择器（Label Selectors）来匹配组内的Pod的，而且很多命令都可以操作Label。Label是绑定在对象上（比如Pod）的键值对，主要用来把一些相关的对象组织在一起，并且对于用户来说label是有含义的，比如：</p>\n<ul>\n<li>Production environment (production, test, dev)</li>\n<li>Application version (beta, v1.3)</li>\n<li>Type of service/server (frontend, backend, database)</li>\n</ul>\n<blockquote>\n<p>   Labels are key/value pairs that are attached to objects</p>\n</blockquote>\n<p><img src=\"http://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_04_labels.svg\" alt=\"Label\"></p>\n<h3 id=\"Pod创建时默认创建的Label\"><a href=\"#Pod创建时默认创建的Label\" class=\"headerlink\" title=\"Pod创建时默认创建的Label\"></a>Pod创建时默认创建的Label</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl describe pod helloworld-2790924137-bvfhn</div><div class=\"line\">Name:  \t\thelloworld-2790924137-bvfhn</div><div class=\"line\">Namespace:     \tdefault</div><div class=\"line\">Node:  \t\tminikube/192.168.99.100</div><div class=\"line\">Start Time:    \tFri, 05 May 2017 14:03:56 +0800</div><div class=\"line\">Labels:\t\tpod-template-hash=2790924137</div><div class=\"line\">       \t\trun=helloworld</div></pre></td></tr></table></figure>\n<h3 id=\"新增一个Label\"><a href=\"#新增一个Label\" class=\"headerlink\" title=\"新增一个Label\"></a>新增一个Label</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl label pod helloworld-2790924137-bvfhn app=v1</div><div class=\"line\">pod &quot;helloworld-2790924137-bvfhn&quot; labeled</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl describe pod helloworld-2790924137-bvfhn</div><div class=\"line\">Name:  \t\thelloworld-2790924137-bvfhn</div><div class=\"line\">Namespace:     \tdefault</div><div class=\"line\">Node:  \t\tminikube/192.168.99.100</div><div class=\"line\">Start Time:    \tFri, 05 May 2017 14:03:56 +0800</div><div class=\"line\">Labels:\t\tapp=v1</div><div class=\"line\">       \t\tpod-template-hash=2790924137</div><div class=\"line\">       \t\trun=helloworld</div></pre></td></tr></table></figure>\n<h3 id=\"使用Label的例子\"><a href=\"#使用Label的例子\" class=\"headerlink\" title=\"使用Label的例子\"></a>使用Label的例子</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl get service</div><div class=\"line\">NAME         CLUSTER-IP   EXTERNAL-IP   PORT(S)          AGE</div><div class=\"line\">helloworld   10.0.0.249   &lt;nodes&gt;       8090:31240/TCP   46m</div><div class=\"line\">kubernetes   10.0.0.1     &lt;none&gt;        443/TCP          17h</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl get service  -l run=helloworld</div><div class=\"line\">NAME         CLUSTER-IP   EXTERNAL-IP   PORT(S)          AGE</div><div class=\"line\">helloworld   10.0.0.249   &lt;nodes&gt;       8090:31240/TCP   46m</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl get pod -l app=v1</div><div class=\"line\">NAME                          READY     STATUS    RESTARTS   AGE</div><div class=\"line\">helloworld-2790924137-bvfhn   1/1       Running   0          1h</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl get pod</div><div class=\"line\">NAME                             READY     STATUS             RESTARTS   AGE</div><div class=\"line\">hello-minikube-938614450-b7xwm   0/1       ImagePullBackOff   0          38m</div><div class=\"line\">helloworld-2790924137-bvfhn      1/1       Running            0          1h</div></pre></td></tr></table></figure>\n<h2 id=\"Scale\"><a href=\"#Scale\" class=\"headerlink\" title=\"Scale\"></a>Scale</h2><p>随着流量的增加，我们可能需要增加我们应用的规模来满足用户的需求。Kubernetes的Scale功能就可以实现这个需求。</p>\n<blockquote>\n<p>   Scaling is accomplished by changing the number of replicas in a Deployment.</p>\n</blockquote>\n<p>扩大应用的规模时，Kubernetes将会在Nodes上面使用可用的资源来创建新的Pod，并运行新增加的应用，缩小规模时做相反的操作。Kubernetes也支持自动规模化Pod。当然我们也可以将应用的数量变为0，这样就会终止所有部署该应用的Pods。应用数量增加后，Service内的负载均衡就会变得非常有用了.</p>\n<p><img src=\"https://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_05_scaling1.svg\" alt=\"scale\"></p>\n<p><img src=\"https://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_05_scaling2.svg\" alt=\"scale\"></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl get deployment</div><div class=\"line\">NAME         DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</div><div class=\"line\">helloworld   1         1         1            1           2h</div></pre></td></tr></table></figure>\n<p>可以看到，现在我们只有一个Pod，</p>\n<ul>\n<li>DESIRED字段表示我们配置的replicas的个数，即实例的个数。</li>\n<li>CURRENT字段表示目前处于running状态的replicas的个数。</li>\n<li>UP-TO-DATE字段表示表示和预先配置的期望状态相符的replicas的个数。</li>\n<li>AVAILABLE字段表示目前实际对用户可用的replicas的个数。</li>\n</ul>\n<p>下面我们使用kubectl scale命令将启动4个复制品，语法规则是kubectl scale deployment-type name replicas-number：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl scale deployment/helloworld --replicas=4</div><div class=\"line\">deployment &quot;helloworld&quot; scaled</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl get deployment</div><div class=\"line\">NAME         DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</div><div class=\"line\">helloworld   4         4         4            4           2h</div><div class=\"line\"></div><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl get pod -o wide</div><div class=\"line\">NAME                          READY     STATUS    RESTARTS   AGE       IP           NODE</div><div class=\"line\">helloworld-2790924137-2kg70   1/1       Running   0          3m        172.17.0.4   minikube</div><div class=\"line\">helloworld-2790924137-bvfhn   1/1       Running   0          2h        172.17.0.3   minikube</div><div class=\"line\">helloworld-2790924137-jg15m   1/1       Running   0          3m        172.17.0.5   minikube</div><div class=\"line\">helloworld-2790924137-tgqr9   1/1       Running   0          3m        172.17.0.2   minikube</div></pre></td></tr></table></figure></p>\n<p>验证一下这个Service是有负载均衡的：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div></pre></td><td class=\"code\"><pre><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl get deployment</div><div class=\"line\">NAME         DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</div><div class=\"line\">helloworld   4         4         4            4           2h</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ curl 192.168.99.100:31240</div><div class=\"line\">Hello world !</div><div class=\"line\">hostname:helloworld-2790924137-bvfhn</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ curl 192.168.99.100:31240</div><div class=\"line\">Hello world !</div><div class=\"line\">hostname:helloworld-2790924137-tgqr9</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ curl 192.168.99.100:31240</div><div class=\"line\">Hello world !</div><div class=\"line\">hostname:helloworld-2790924137-2kg70</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ curl 192.168.99.100:31240</div><div class=\"line\">Hello world !</div><div class=\"line\">hostname:helloworld-2790924137-bvfhn</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ curl 192.168.99.100:31240</div><div class=\"line\">Hello world !</div><div class=\"line\">hostname:helloworld-2790924137-tgqr9</div></pre></td></tr></table></figure></p>\n<h2 id=\"Rolling-Update\"><a href=\"#Rolling-Update\" class=\"headerlink\" title=\"Rolling Update\"></a>Rolling Update</h2><p>滚动更新（Rolling update）特性的好处就是我们不用停止服务就可以实现应用更新。默认更新的时候是一个Pod一个Pod更新的，所以整个过程服务不会中断。当然你也可以设置一次更新的Pod的百分比。而且更新过程中，Service只会将流量转发到可用的节点上面。更加重要的是，我们可以随时回退到旧版本。</p>\n<blockquote>\n<p>Rolling updates allow Deployments’ update to take place with zero downtime by incrementally updating Pods instances with new ones.<br>If a Deployment is exposed publicly, the Service will load-balance the traffic only to available Pods during the update.</p>\n</blockquote>\n<p><img src=\"https://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_06_rollingupdates1.svg\" alt=\"rollingupdate\"><br><img src=\"https://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_06_rollingupdates2.svg\" alt=\"rollingupdate\"><br><img src=\"https://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_06_rollingupdates3.svg\" alt=\"rollingupdate\"><br><img src=\"https://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_06_rollingupdates4.svg\" alt=\"rollingupdate\"></p>\n<p>在原来程序的基础上，多输出一个v2作为新版本，使用set image命令指定新版本镜像.<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div></pre></td><td class=\"code\"><pre><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl set image deployments/helloworld helloworld=registry.hnaresearch.com/public/hello-world:v2.0</div><div class=\"line\">deployment &quot;helloworld&quot; image updated</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl get pods</div><div class=\"line\">NAME                          READY     STATUS              RESTARTS   AGE</div><div class=\"line\">helloworld-2790924137-2kg70   1/1       Running             0          54m</div><div class=\"line\">helloworld-2790924137-bvfhn   1/1       Running             0          3h</div><div class=\"line\">helloworld-2790924137-tgqr9   1/1       Running             0          54m</div><div class=\"line\">helloworld-2889228138-65lmj   0/1       ContainerCreating   0          9m</div><div class=\"line\">helloworld-2889228138-q68vx   0/1       ContainerCreating   0          9m</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl get pods</div><div class=\"line\">NAME                          READY     STATUS              RESTARTS   AGE</div><div class=\"line\">helloworld-2790924137-2kg70   1/1       Terminating         0          54m</div><div class=\"line\">helloworld-2790924137-bvfhn   1/1       Running             0          3h</div><div class=\"line\">helloworld-2790924137-tgqr9   0/1       Terminating         0          54m</div><div class=\"line\">helloworld-2889228138-65lmj   0/1       ContainerCreating   0          9m</div><div class=\"line\">helloworld-2889228138-bj38m   0/1       Pending             0          9m</div><div class=\"line\">helloworld-2889228138-dv3ch   1/1       Running             0          9m</div><div class=\"line\">helloworld-2889228138-q68vx   1/1       Running             0          9m</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl get pods</div><div class=\"line\">NAME                          READY     STATUS    RESTARTS   AGE</div><div class=\"line\">helloworld-2889228138-65lmj   1/1       Running   0          10m</div><div class=\"line\">helloworld-2889228138-bj38m   1/1       Running   0          10m</div><div class=\"line\">helloworld-2889228138-dv3ch   1/1       Running   0          10m</div><div class=\"line\">helloworld-2889228138-q68vx   1/1       Running   0          10m</div></pre></td></tr></table></figure></p>\n<p>使用kubectl rollout undo命令回滚到之前的版本：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl rollout undo deployment/helloworld</div><div class=\"line\">deployment &quot;helloworld&quot; rolled back</div></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"MiniKube\"><a href=\"#MiniKube\" class=\"headerlink\" title=\"MiniKube\"></a>MiniKube</h2><p>环境: MacOS, virtualbox, minikube v0.18.0, kubectl v1.6.0</p>\n<p>Kubernetes将底层的计算资源连接在一起对外体现为一个计算集群，并将资源高度抽象化。部署应用时Kubernetes会以更高效的方式自动的将应用分发到集群内的机器上面，并调度运行。</p>\n<h2 id=\"搭建Kubernetes集群\"><a href=\"#搭建Kubernetes集群\" class=\"headerlink\" title=\"搭建Kubernetes集群\"></a>搭建Kubernetes集群</h2><p>Kubernetes集群包含两种类型的资源：</p>\n<ul>\n<li>Master节点：协调控制整个集群。Master负责管理整个集群，协调集群内的所有行为。比如调度应用，监控应用的状态等。</li>\n<li>Nodes节点：运行应用的工作节点。Node节点负责运行应用，一般是一台物理机或者虚机。每个Node节点上面都有一个Kubelet，它是一个代理程序，用来管理该节点以及和Master节点通信。除此以外，Node节点上还会有一些管理容器的工具，比如Docker或者rkt等。生产环境中一个Kubernetes集群至少应该包含三个Nodes节点。</li>\n</ul>\n<p>当部署应用的时候，我们通知Master节点启动应用容器。然后Master会调度这些应用将它们运行在Node节点上面。Node节点和Master节点通过Master节点暴露的Kubernetes API通信。当然我们也可以直接通过这些API和集群交互。<br><img src=\"http://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_01_cluster.svg\" alt=\"kubernetes Cluster\"></p>\n<p>Kubernetes提供了一个轻量级的Minikube应用，利用它我们可以很容器的创建一个只包含一个Node节点的Kubernetes Cluster用于日常的开发测试。</p>\n<h3 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h3><p>Minikube的安装可以参考: Minikube的Github：<a href=\"https://github.com/kubernetes/minikube\" target=\"_blank\" rel=\"external\">https://github.com/kubernetes/minikube</a></p>\n<p>要正常使用，还必须安装kubectl，并且放在PATH里面。kubectl是一个通过Kubernetes API和Kubernetes集群交互的命令行工具。</p>\n<h3 id=\"ONLY-FOR-CHINESE\"><a href=\"#ONLY-FOR-CHINESE\" class=\"headerlink\" title=\"ONLY FOR CHINESE\"></a>ONLY FOR CHINESE</h3><p>Kubernetes在部署容器应用的时候会先拉一个pause镜像，这个是一个基础容器，主要是负责网络部分的功能的，具体这里不展开讨论。最关键的是Kubernetes里面镜像默认都是从Google的镜像仓库拉的（就跟docker默认从docker hub拉的一样），但是因为GFW的原因，中国用户是访问不了Google的镜像仓库gcr.io的（如果你可以ping通，那恭喜你）。庆幸的是这个镜像被传到了docker hub上面，虽然中国用户访问后者也非常艰难，但通过一些加速器之类的还是可以pull下来的。如果没有VPN等科学上网的工具的话，请先做如下操作：</p>\n<p>See: <a href=\"https://github.com/kubernetes/kubernetes/issues/6888\" target=\"_blank\" rel=\"external\">https://github.com/kubernetes/kubernetes/issues/6888</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">minikube ssh    # 登录到我们的Kubernetes VM里面去</div><div class=\"line\">docker pull registry.hnaresearch.com/public/pause-amd64:3.0  </div><div class=\"line\">docker tag registry.hnaresearch.com/public/pause-amd64:3.0 gcr.io/google_containers/pause-amd64:3.0</div></pre></td></tr></table></figure>\n<p>这样Kubernetes VM就不会从gcr.io拉镜像了，而是会直接使用本地的镜像。</p>\n<h2 id=\"部署应用\"><a href=\"#部署应用\" class=\"headerlink\" title=\"部署应用\"></a>部署应用</h2><p>在Kubernetes Cluster上面部署应用，我们需要先创建一个Kubernetes Deployment。这个Deployment负责创建和更新我们的应用实例。当这个Deployment创建之后，Kubernetes master就会将这个Deployment创建出来的应用实例部署到集群内某个Node节点上。而且自应用实例创建后，Deployment controller还会持续监控应用，直到应用被删除或者部署应用的Node节点不存在。</p>\n<blockquote>\n<p>A Deployment is responsible for creating and updating instances of your application.</p>\n</blockquote>\n<p><img src=\"http://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_02_first_app.svg\" alt=\"\"></p>\n<p>使用kubectl来创建Deployment，创建的时候需要制定容器镜像以及我们要启动的个数（replicas），当然这些信息后面可以再更新。这里我用Go写了一个简单的Webserver，返回“Hello World”，监听端口是8090.我们就来启动这个应用.<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">kubectl run helloworld --image=registry.hnaresearch.com/public/hello-world:v1.0 --port=8090</div></pre></td></tr></table></figure></p>\n<p>执行后master寻找一个合适的node来部署我们的应用实例（我们只有一个node）。我们可以使用kubectl get deployment来查看我们创建的Deployment：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">kubectl get deployment</div></pre></td></tr></table></figure></p>\n<p>默认应用部署好之后是只在Kubernetes Cluster内部可见的，有多种方法可以让我们的应用暴露到外部，这里先介绍一种简单的：我们可以通过kubectl proxy命令在我们的终端和Kubernetes Cluster直接创建一个代理。然后，打开一个新的终端，通过Pod名(Pod后面会有讲到，可以通过kubectl get pod查看Pod名字)就可以访问了：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl get pod</div><div class=\"line\">NAME                             READY     STATUS             RESTARTS   AGE</div><div class=\"line\">hello-minikube-938614450-xjl4s   0/1       ImagePullBackOff   0          15h</div><div class=\"line\">helloworld-2790924137-bvfhn      1/1       Running            0          2m</div><div class=\"line\"></div><div class=\"line\">xis-macbook-pro:~ xiningwang$ curl http://localhost:8001/api/v1/proxy/namespaces/default/pods/helloworld-2790924137-bvfhn/</div><div class=\"line\">Hello world !</div><div class=\"line\">hostname:helloworld-2790924137-bvfhn</div></pre></td></tr></table></figure></p>\n<h2 id=\"Pod\"><a href=\"#Pod\" class=\"headerlink\" title=\"Pod\"></a>Pod</h2><p>Pod是Kubernetes中一个非常重要的概念，也是区别于其他编排系统的一个设计. Deployment执行时并不是直接创建了容器实例，而是先在Node上面创建了Pod，然后再在Pod里面创建容器。那Pod到底是什么？Pod是Kubernetes里面抽象出来的一个概念，它是能够被创建、调度和管理的最小单元；每个Pod都有一个独立的IP；一个Pod由若干个容器构成。一个Pod之内的容器共享Pod的所有资源，这些资源主要包括：共享存储（以Volumes的形式）、共享网络、共享端口等。Kubernetes虽然也是一个容器编排系统，但不同于其他系统，它的最小操作单元不是单个容器，而是Pod。这个特性给Kubernetes带来了很多优势，比如最显而易见的是同一个Pod内的容器可以非常方便的互相访问（通过localhost就可以访问）和共享数据。</p>\n<blockquote>\n<p>A Pod is a group of one or more application containers (such as Docker or rkt) and includes shared storage (volumes), IP address and information about how to run them.</p>\n</blockquote>\n<p><img src=\"http://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_03_pods.svg\" alt=\"pod\"></p>\n<blockquote>\n<p>A Node is a group of one ore more pods and includes the kubelet and container engine.  </p>\n<p>Containers should only be scheduled together in a single Pod if they are tightly coupled and need to share resources such as disk.</p>\n</blockquote>\n<p><img src=\"http://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_03_nodes.svg\" alt=\"node\"></p>\n<h2 id=\"Service\"><a href=\"#Service\" class=\"headerlink\" title=\"Service\"></a>Service</h2><p>通过proxy实现集群外部可以访问的方式是不太适用于实际生产环境的。<a href=\"id:service\" target=\"_blank\" rel=\"external\">Service</a>是Kubernetes里面抽象出来的一层，它定义了由多个Pods组成的逻辑组（logical set），可以对组内的Pod做一些事情：</p>\n<ul>\n<li>对外暴露流量</li>\n<li>做负载均衡（load balancing）</li>\n<li>服务发现（service-discovery）</li>\n</ul>\n<blockquote>\n<p>A Kubernetes Service is an abstraction layer which defines a logical set of Pods and enables external traffic exposure, load balancing and service discovery for those Pods.</p>\n</blockquote>\n<p>而且每个Service都有一个集群内唯一的私有IP和对外的端口，用于接收流量。如果我们想将一个Service暴露到集群外，有两种方法：</p>\n<ul>\n<li>LoadBalancer - 提供一个公网的IP</li>\n<li>NodePort - 使用NAT将Service的端口暴露出去。Minikube只支持这种方式。</li>\n</ul>\n<p><img src=\"http://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_04_services.svg\" alt=\"service\"></p>\n<p>使用kubectl get service可以查看目前已有的service，Minikube默认创建了一个kubernetes Service。我们使用expose命令再创建一个Service：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div></pre></td><td class=\"code\"><pre><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl get service</div><div class=\"line\">NAME             CLUSTER-IP   EXTERNAL-IP   PORT(S)          AGE</div><div class=\"line\">hello-minikube   10.0.0.188   &lt;nodes&gt;       8080:32710/TCP   16h</div><div class=\"line\">kubernetes       10.0.0.1     &lt;none&gt;        443/TCP          16h</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl expose deployment/helloworld --type=&quot;NodePort&quot; --port 8090</div><div class=\"line\">service &quot;helloworld&quot; exposed</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl get service</div><div class=\"line\">NAME             CLUSTER-IP   EXTERNAL-IP   PORT(S)          AGE</div><div class=\"line\">hello-minikube   10.0.0.188   &lt;nodes&gt;       8080:32710/TCP   16h</div><div class=\"line\">helloworld       10.0.0.249   &lt;nodes&gt;       8090:31240/TCP   2m</div><div class=\"line\">kubernetes       10.0.0.1     &lt;none&gt;        443/TCP          16h</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl delete service hello-minikube</div><div class=\"line\">service &quot;hello-minikube&quot; deleted</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl get service</div><div class=\"line\">NAME         CLUSTER-IP   EXTERNAL-IP   PORT(S)          AGE</div><div class=\"line\">helloworld   10.0.0.249   &lt;nodes&gt;       8090:31240/TCP   2m</div><div class=\"line\">kubernetes   10.0.0.1     &lt;none&gt;        443/TCP          16h</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl describe service/helloworld</div><div class=\"line\">Name:  \t\t\thelloworld</div><div class=\"line\">Namespace:     \t\tdefault</div><div class=\"line\">Labels:\t\t\trun=helloworld</div><div class=\"line\">Annotations:   \t\t&lt;none&gt;</div><div class=\"line\">Selector:      \t\trun=helloworld</div><div class=\"line\">Type:  \t\t\tNodePort</div><div class=\"line\">IP:    \t\t\t10.0.0.249</div><div class=\"line\">Port:  \t\t\t&lt;unset&gt;\t8090/TCP</div><div class=\"line\">NodePort:      \t\t&lt;unset&gt;\t31240/TCP</div><div class=\"line\">Endpoints:     \t\t172.17.0.3:8090</div><div class=\"line\">Session Affinity:      \tNone</div><div class=\"line\">Events:\t\t\t&lt;none&gt;</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ minikube docker-env</div><div class=\"line\">export DOCKER_TLS_VERIFY=&quot;1&quot;</div><div class=\"line\">export DOCKER_HOST=&quot;tcp://192.168.99.100:2376&quot;</div><div class=\"line\">export DOCKER_CERT_PATH=&quot;/Users/xiningwang/.minikube/certs&quot;</div><div class=\"line\">export DOCKER_API_VERSION=&quot;1.23&quot;</div><div class=\"line\"># Run this command to configure your shell:</div><div class=\"line\"># eval $(minikube docker-env)</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ curl http://192.168.99.100:31240</div><div class=\"line\">Hello world !</div><div class=\"line\">hostname:helloworld-2790924137-bvfhn</div></pre></td></tr></table></figure></p>\n<h2 id=\"Label\"><a href=\"#Label\" class=\"headerlink\" title=\"Label\"></a>Label</h2><p>Service就是靠Label选择器（Label Selectors）来匹配组内的Pod的，而且很多命令都可以操作Label。Label是绑定在对象上（比如Pod）的键值对，主要用来把一些相关的对象组织在一起，并且对于用户来说label是有含义的，比如：</p>\n<ul>\n<li>Production environment (production, test, dev)</li>\n<li>Application version (beta, v1.3)</li>\n<li>Type of service/server (frontend, backend, database)</li>\n</ul>\n<blockquote>\n<p>   Labels are key/value pairs that are attached to objects</p>\n</blockquote>\n<p><img src=\"http://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_04_labels.svg\" alt=\"Label\"></p>\n<h3 id=\"Pod创建时默认创建的Label\"><a href=\"#Pod创建时默认创建的Label\" class=\"headerlink\" title=\"Pod创建时默认创建的Label\"></a>Pod创建时默认创建的Label</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl describe pod helloworld-2790924137-bvfhn</div><div class=\"line\">Name:  \t\thelloworld-2790924137-bvfhn</div><div class=\"line\">Namespace:     \tdefault</div><div class=\"line\">Node:  \t\tminikube/192.168.99.100</div><div class=\"line\">Start Time:    \tFri, 05 May 2017 14:03:56 +0800</div><div class=\"line\">Labels:\t\tpod-template-hash=2790924137</div><div class=\"line\">       \t\trun=helloworld</div></pre></td></tr></table></figure>\n<h3 id=\"新增一个Label\"><a href=\"#新增一个Label\" class=\"headerlink\" title=\"新增一个Label\"></a>新增一个Label</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl label pod helloworld-2790924137-bvfhn app=v1</div><div class=\"line\">pod &quot;helloworld-2790924137-bvfhn&quot; labeled</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl describe pod helloworld-2790924137-bvfhn</div><div class=\"line\">Name:  \t\thelloworld-2790924137-bvfhn</div><div class=\"line\">Namespace:     \tdefault</div><div class=\"line\">Node:  \t\tminikube/192.168.99.100</div><div class=\"line\">Start Time:    \tFri, 05 May 2017 14:03:56 +0800</div><div class=\"line\">Labels:\t\tapp=v1</div><div class=\"line\">       \t\tpod-template-hash=2790924137</div><div class=\"line\">       \t\trun=helloworld</div></pre></td></tr></table></figure>\n<h3 id=\"使用Label的例子\"><a href=\"#使用Label的例子\" class=\"headerlink\" title=\"使用Label的例子\"></a>使用Label的例子</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl get service</div><div class=\"line\">NAME         CLUSTER-IP   EXTERNAL-IP   PORT(S)          AGE</div><div class=\"line\">helloworld   10.0.0.249   &lt;nodes&gt;       8090:31240/TCP   46m</div><div class=\"line\">kubernetes   10.0.0.1     &lt;none&gt;        443/TCP          17h</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl get service  -l run=helloworld</div><div class=\"line\">NAME         CLUSTER-IP   EXTERNAL-IP   PORT(S)          AGE</div><div class=\"line\">helloworld   10.0.0.249   &lt;nodes&gt;       8090:31240/TCP   46m</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl get pod -l app=v1</div><div class=\"line\">NAME                          READY     STATUS    RESTARTS   AGE</div><div class=\"line\">helloworld-2790924137-bvfhn   1/1       Running   0          1h</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl get pod</div><div class=\"line\">NAME                             READY     STATUS             RESTARTS   AGE</div><div class=\"line\">hello-minikube-938614450-b7xwm   0/1       ImagePullBackOff   0          38m</div><div class=\"line\">helloworld-2790924137-bvfhn      1/1       Running            0          1h</div></pre></td></tr></table></figure>\n<h2 id=\"Scale\"><a href=\"#Scale\" class=\"headerlink\" title=\"Scale\"></a>Scale</h2><p>随着流量的增加，我们可能需要增加我们应用的规模来满足用户的需求。Kubernetes的Scale功能就可以实现这个需求。</p>\n<blockquote>\n<p>   Scaling is accomplished by changing the number of replicas in a Deployment.</p>\n</blockquote>\n<p>扩大应用的规模时，Kubernetes将会在Nodes上面使用可用的资源来创建新的Pod，并运行新增加的应用，缩小规模时做相反的操作。Kubernetes也支持自动规模化Pod。当然我们也可以将应用的数量变为0，这样就会终止所有部署该应用的Pods。应用数量增加后，Service内的负载均衡就会变得非常有用了.</p>\n<p><img src=\"https://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_05_scaling1.svg\" alt=\"scale\"></p>\n<p><img src=\"https://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_05_scaling2.svg\" alt=\"scale\"></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl get deployment</div><div class=\"line\">NAME         DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</div><div class=\"line\">helloworld   1         1         1            1           2h</div></pre></td></tr></table></figure>\n<p>可以看到，现在我们只有一个Pod，</p>\n<ul>\n<li>DESIRED字段表示我们配置的replicas的个数，即实例的个数。</li>\n<li>CURRENT字段表示目前处于running状态的replicas的个数。</li>\n<li>UP-TO-DATE字段表示表示和预先配置的期望状态相符的replicas的个数。</li>\n<li>AVAILABLE字段表示目前实际对用户可用的replicas的个数。</li>\n</ul>\n<p>下面我们使用kubectl scale命令将启动4个复制品，语法规则是kubectl scale deployment-type name replicas-number：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl scale deployment/helloworld --replicas=4</div><div class=\"line\">deployment &quot;helloworld&quot; scaled</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl get deployment</div><div class=\"line\">NAME         DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</div><div class=\"line\">helloworld   4         4         4            4           2h</div><div class=\"line\"></div><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl get pod -o wide</div><div class=\"line\">NAME                          READY     STATUS    RESTARTS   AGE       IP           NODE</div><div class=\"line\">helloworld-2790924137-2kg70   1/1       Running   0          3m        172.17.0.4   minikube</div><div class=\"line\">helloworld-2790924137-bvfhn   1/1       Running   0          2h        172.17.0.3   minikube</div><div class=\"line\">helloworld-2790924137-jg15m   1/1       Running   0          3m        172.17.0.5   minikube</div><div class=\"line\">helloworld-2790924137-tgqr9   1/1       Running   0          3m        172.17.0.2   minikube</div></pre></td></tr></table></figure></p>\n<p>验证一下这个Service是有负载均衡的：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div></pre></td><td class=\"code\"><pre><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl get deployment</div><div class=\"line\">NAME         DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</div><div class=\"line\">helloworld   4         4         4            4           2h</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ curl 192.168.99.100:31240</div><div class=\"line\">Hello world !</div><div class=\"line\">hostname:helloworld-2790924137-bvfhn</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ curl 192.168.99.100:31240</div><div class=\"line\">Hello world !</div><div class=\"line\">hostname:helloworld-2790924137-tgqr9</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ curl 192.168.99.100:31240</div><div class=\"line\">Hello world !</div><div class=\"line\">hostname:helloworld-2790924137-2kg70</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ curl 192.168.99.100:31240</div><div class=\"line\">Hello world !</div><div class=\"line\">hostname:helloworld-2790924137-bvfhn</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ curl 192.168.99.100:31240</div><div class=\"line\">Hello world !</div><div class=\"line\">hostname:helloworld-2790924137-tgqr9</div></pre></td></tr></table></figure></p>\n<h2 id=\"Rolling-Update\"><a href=\"#Rolling-Update\" class=\"headerlink\" title=\"Rolling Update\"></a>Rolling Update</h2><p>滚动更新（Rolling update）特性的好处就是我们不用停止服务就可以实现应用更新。默认更新的时候是一个Pod一个Pod更新的，所以整个过程服务不会中断。当然你也可以设置一次更新的Pod的百分比。而且更新过程中，Service只会将流量转发到可用的节点上面。更加重要的是，我们可以随时回退到旧版本。</p>\n<blockquote>\n<p>Rolling updates allow Deployments’ update to take place with zero downtime by incrementally updating Pods instances with new ones.<br>If a Deployment is exposed publicly, the Service will load-balance the traffic only to available Pods during the update.</p>\n</blockquote>\n<p><img src=\"https://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_06_rollingupdates1.svg\" alt=\"rollingupdate\"><br><img src=\"https://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_06_rollingupdates2.svg\" alt=\"rollingupdate\"><br><img src=\"https://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_06_rollingupdates3.svg\" alt=\"rollingupdate\"><br><img src=\"https://kubernetes.io/docs/tutorials/kubernetes-basics/public/images/module_06_rollingupdates4.svg\" alt=\"rollingupdate\"></p>\n<p>在原来程序的基础上，多输出一个v2作为新版本，使用set image命令指定新版本镜像.<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div></pre></td><td class=\"code\"><pre><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl set image deployments/helloworld helloworld=registry.hnaresearch.com/public/hello-world:v2.0</div><div class=\"line\">deployment &quot;helloworld&quot; image updated</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl get pods</div><div class=\"line\">NAME                          READY     STATUS              RESTARTS   AGE</div><div class=\"line\">helloworld-2790924137-2kg70   1/1       Running             0          54m</div><div class=\"line\">helloworld-2790924137-bvfhn   1/1       Running             0          3h</div><div class=\"line\">helloworld-2790924137-tgqr9   1/1       Running             0          54m</div><div class=\"line\">helloworld-2889228138-65lmj   0/1       ContainerCreating   0          9m</div><div class=\"line\">helloworld-2889228138-q68vx   0/1       ContainerCreating   0          9m</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl get pods</div><div class=\"line\">NAME                          READY     STATUS              RESTARTS   AGE</div><div class=\"line\">helloworld-2790924137-2kg70   1/1       Terminating         0          54m</div><div class=\"line\">helloworld-2790924137-bvfhn   1/1       Running             0          3h</div><div class=\"line\">helloworld-2790924137-tgqr9   0/1       Terminating         0          54m</div><div class=\"line\">helloworld-2889228138-65lmj   0/1       ContainerCreating   0          9m</div><div class=\"line\">helloworld-2889228138-bj38m   0/1       Pending             0          9m</div><div class=\"line\">helloworld-2889228138-dv3ch   1/1       Running             0          9m</div><div class=\"line\">helloworld-2889228138-q68vx   1/1       Running             0          9m</div><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl get pods</div><div class=\"line\">NAME                          READY     STATUS    RESTARTS   AGE</div><div class=\"line\">helloworld-2889228138-65lmj   1/1       Running   0          10m</div><div class=\"line\">helloworld-2889228138-bj38m   1/1       Running   0          10m</div><div class=\"line\">helloworld-2889228138-dv3ch   1/1       Running   0          10m</div><div class=\"line\">helloworld-2889228138-q68vx   1/1       Running   0          10m</div></pre></td></tr></table></figure></p>\n<p>使用kubectl rollout undo命令回滚到之前的版本：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">xis-macbook-pro:~ xiningwang$ kubectl rollout undo deployment/helloworld</div><div class=\"line\">deployment &quot;helloworld&quot; rolled back</div></pre></td></tr></table></figure></p>\n"},{"title":"Redis","_content":"\ndocker run --name myredis -v /Users/xiningwang/nosql/redis/redis-3.2.8/data:/data -p 6379:6379 -d redis redis-server --appendonly yes\n","source":"_posts/redis.md","raw":"---\ntitle: Redis\n---\n\ndocker run --name myredis -v /Users/xiningwang/nosql/redis/redis-3.2.8/data:/data -p 6379:6379 -d redis redis-server --appendonly yes\n","slug":"redis","published":1,"date":"2017-04-04T11:50:10.000Z","updated":"2017-05-08T13:32:07.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj2g8ok3z000idl72f32hmk26","content":"<p>docker run –name myredis -v /Users/xiningwang/nosql/redis/redis-3.2.8/data:/data -p 6379:6379 -d redis redis-server –appendonly yes</p>\n","site":{"data":{}},"excerpt":"","more":"<p>docker run –name myredis -v /Users/xiningwang/nosql/redis/redis-3.2.8/data:/data -p 6379:6379 -d redis redis-server –appendonly yes</p>\n"},{"title":"Running Spark on YARN","_content":"### To launch a Spark application in cluster/yarn mode:\n```\n$ ./bin/spark-submit --class path.to.your.Class --master yarn --deploy-mode cluster [options] <app jar> [app options]\n```\n\nFor example:\n```\n$ ./bin/spark-submit --class org.apache.spark.examples.SparkPi \\\n    --master yarn \\\n    --deploy-mode cluster \\\n    --driver-memory 4g \\\n    --executor-memory 2g \\\n    --executor-cores 1 \\\n    --queue thequeue \\\n    lib/spark-examples*.jar \\\n    10\n```\n\nSee the detail from:\nhttp://spark.apache.org/docs/latest/running-on-yarn.html\n","source":"_posts/running-spark-on-yarn.md","raw":"---\ntitle: Running Spark on YARN\n---\n### To launch a Spark application in cluster/yarn mode:\n```\n$ ./bin/spark-submit --class path.to.your.Class --master yarn --deploy-mode cluster [options] <app jar> [app options]\n```\n\nFor example:\n```\n$ ./bin/spark-submit --class org.apache.spark.examples.SparkPi \\\n    --master yarn \\\n    --deploy-mode cluster \\\n    --driver-memory 4g \\\n    --executor-memory 2g \\\n    --executor-cores 1 \\\n    --queue thequeue \\\n    lib/spark-examples*.jar \\\n    10\n```\n\nSee the detail from:\nhttp://spark.apache.org/docs/latest/running-on-yarn.html\n","slug":"running-spark-on-yarn","published":1,"date":"2017-03-31T16:44:49.000Z","updated":"2017-05-08T13:32:21.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj2g8ok40000jdl72va8cy39l","content":"<h3 id=\"To-launch-a-Spark-application-in-cluster-yarn-mode\"><a href=\"#To-launch-a-Spark-application-in-cluster-yarn-mode\" class=\"headerlink\" title=\"To launch a Spark application in cluster/yarn mode:\"></a>To launch a Spark application in cluster/yarn mode:</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ ./bin/spark-submit --class path.to.your.Class --master yarn --deploy-mode cluster [options] &lt;app jar&gt; [app options]</div></pre></td></tr></table></figure>\n<p>For example:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ ./bin/spark-submit --class org.apache.spark.examples.SparkPi \\</div><div class=\"line\">    --master yarn \\</div><div class=\"line\">    --deploy-mode cluster \\</div><div class=\"line\">    --driver-memory 4g \\</div><div class=\"line\">    --executor-memory 2g \\</div><div class=\"line\">    --executor-cores 1 \\</div><div class=\"line\">    --queue thequeue \\</div><div class=\"line\">    lib/spark-examples*.jar \\</div><div class=\"line\">    10</div></pre></td></tr></table></figure></p>\n<p>See the detail from:<br><a href=\"http://spark.apache.org/docs/latest/running-on-yarn.html\" target=\"_blank\" rel=\"external\">http://spark.apache.org/docs/latest/running-on-yarn.html</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"To-launch-a-Spark-application-in-cluster-yarn-mode\"><a href=\"#To-launch-a-Spark-application-in-cluster-yarn-mode\" class=\"headerlink\" title=\"To launch a Spark application in cluster/yarn mode:\"></a>To launch a Spark application in cluster/yarn mode:</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ ./bin/spark-submit --class path.to.your.Class --master yarn --deploy-mode cluster [options] &lt;app jar&gt; [app options]</div></pre></td></tr></table></figure>\n<p>For example:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ ./bin/spark-submit --class org.apache.spark.examples.SparkPi \\</div><div class=\"line\">    --master yarn \\</div><div class=\"line\">    --deploy-mode cluster \\</div><div class=\"line\">    --driver-memory 4g \\</div><div class=\"line\">    --executor-memory 2g \\</div><div class=\"line\">    --executor-cores 1 \\</div><div class=\"line\">    --queue thequeue \\</div><div class=\"line\">    lib/spark-examples*.jar \\</div><div class=\"line\">    10</div></pre></td></tr></table></figure></p>\n<p>See the detail from:<br><a href=\"http://spark.apache.org/docs/latest/running-on-yarn.html\" target=\"_blank\" rel=\"external\">http://spark.apache.org/docs/latest/running-on-yarn.html</a></p>\n"},{"title":"Spark","_content":"","source":"_posts/spark.md","raw":"---\ntitle: Spark\n---\n","slug":"spark","published":1,"date":"2017-04-10T15:15:00.000Z","updated":"2017-05-08T13:32:43.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj2g8ok41000kdl72slnphhwc","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"StatsD - Graphite - Grafana","_content":"#1. StatsD - metrics data collecting\n\n  - In your application code, use the StatsD client (e.g. Java client library) to collect and send the statistics and aggregation data to StatsD server;\n  - Not need to pre-define the metrics in anywhere, just place them into your application code;\n  - By default, stats data are aggregated and sent to Graphite server by every 10 seconds, so think this near-realtime;\n\n#2. Graphite - metrics data graphing and storage\n  - Store numeric time-series data: The metric data would be stored into Graphite server (include a Whisper database);\n  - Render the graph for metrics data per the metrics demand;\n  - The pre-built UI dashboard is not powerful shown as below, but can easily use it to view the metrics data;\n  -  For production environment, Graphite server should be running as cluster instead of stand-alone server;\n\n\n\n#3. Grafana - powerful dashboard for visualizing the metrics data\n  - easy to integrate with Graphite to visualize the metrics data;\n  - input the Graphite HTTP URL to link to Graphite as data source;\n  - powerful pre-built reporting charts and dashboard;\n\n#4.  Sample Code:\n - easy to feed the data to StatsD -> Graphite -> Grafana\n```\n private static final StatsDClient statsd = new NonBlockingStatsDClient(\"app.api-analytics.sample\", \"127.0.0.1\",\n      8125);\n statsd.count(\"get.request\", (long)(Math.random()* 10)); // Request count of this API\n```\n","source":"_posts/sgg.md","raw":"---\ntitle: StatsD - Graphite - Grafana\n---\n#1. StatsD - metrics data collecting\n\n  - In your application code, use the StatsD client (e.g. Java client library) to collect and send the statistics and aggregation data to StatsD server;\n  - Not need to pre-define the metrics in anywhere, just place them into your application code;\n  - By default, stats data are aggregated and sent to Graphite server by every 10 seconds, so think this near-realtime;\n\n#2. Graphite - metrics data graphing and storage\n  - Store numeric time-series data: The metric data would be stored into Graphite server (include a Whisper database);\n  - Render the graph for metrics data per the metrics demand;\n  - The pre-built UI dashboard is not powerful shown as below, but can easily use it to view the metrics data;\n  -  For production environment, Graphite server should be running as cluster instead of stand-alone server;\n\n\n\n#3. Grafana - powerful dashboard for visualizing the metrics data\n  - easy to integrate with Graphite to visualize the metrics data;\n  - input the Graphite HTTP URL to link to Graphite as data source;\n  - powerful pre-built reporting charts and dashboard;\n\n#4.  Sample Code:\n - easy to feed the data to StatsD -> Graphite -> Grafana\n```\n private static final StatsDClient statsd = new NonBlockingStatsDClient(\"app.api-analytics.sample\", \"127.0.0.1\",\n      8125);\n statsd.count(\"get.request\", (long)(Math.random()* 10)); // Request count of this API\n```\n","slug":"sgg","published":1,"date":"2017-03-08T14:16:23.000Z","updated":"2017-05-08T13:32:36.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj2g8ok43000ldl72jlyy7jd3","content":"<p>#1. StatsD - metrics data collecting</p>\n<ul>\n<li>In your application code, use the StatsD client (e.g. Java client library) to collect and send the statistics and aggregation data to StatsD server;</li>\n<li>Not need to pre-define the metrics in anywhere, just place them into your application code;</li>\n<li>By default, stats data are aggregated and sent to Graphite server by every 10 seconds, so think this near-realtime;</li>\n</ul>\n<p>#2. Graphite - metrics data graphing and storage</p>\n<ul>\n<li>Store numeric time-series data: The metric data would be stored into Graphite server (include a Whisper database);</li>\n<li>Render the graph for metrics data per the metrics demand;</li>\n<li>The pre-built UI dashboard is not powerful shown as below, but can easily use it to view the metrics data;</li>\n<li>For production environment, Graphite server should be running as cluster instead of stand-alone server;</li>\n</ul>\n<p>#3. Grafana - powerful dashboard for visualizing the metrics data</p>\n<ul>\n<li>easy to integrate with Graphite to visualize the metrics data;</li>\n<li>input the Graphite HTTP URL to link to Graphite as data source;</li>\n<li>powerful pre-built reporting charts and dashboard;</li>\n</ul>\n<p>#4.  Sample Code:</p>\n<ul>\n<li>easy to feed the data to StatsD -&gt; Graphite -&gt; Grafana<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">private static final StatsDClient statsd = new NonBlockingStatsDClient(&quot;app.api-analytics.sample&quot;, &quot;127.0.0.1&quot;,</div><div class=\"line\">     8125);</div><div class=\"line\">statsd.count(&quot;get.request&quot;, (long)(Math.random()* 10)); // Request count of this API</div></pre></td></tr></table></figure>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>#1. StatsD - metrics data collecting</p>\n<ul>\n<li>In your application code, use the StatsD client (e.g. Java client library) to collect and send the statistics and aggregation data to StatsD server;</li>\n<li>Not need to pre-define the metrics in anywhere, just place them into your application code;</li>\n<li>By default, stats data are aggregated and sent to Graphite server by every 10 seconds, so think this near-realtime;</li>\n</ul>\n<p>#2. Graphite - metrics data graphing and storage</p>\n<ul>\n<li>Store numeric time-series data: The metric data would be stored into Graphite server (include a Whisper database);</li>\n<li>Render the graph for metrics data per the metrics demand;</li>\n<li>The pre-built UI dashboard is not powerful shown as below, but can easily use it to view the metrics data;</li>\n<li>For production environment, Graphite server should be running as cluster instead of stand-alone server;</li>\n</ul>\n<p>#3. Grafana - powerful dashboard for visualizing the metrics data</p>\n<ul>\n<li>easy to integrate with Graphite to visualize the metrics data;</li>\n<li>input the Graphite HTTP URL to link to Graphite as data source;</li>\n<li>powerful pre-built reporting charts and dashboard;</li>\n</ul>\n<p>#4.  Sample Code:</p>\n<ul>\n<li>easy to feed the data to StatsD -&gt; Graphite -&gt; Grafana<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">private static final StatsDClient statsd = new NonBlockingStatsDClient(&quot;app.api-analytics.sample&quot;, &quot;127.0.0.1&quot;,</div><div class=\"line\">     8125);</div><div class=\"line\">statsd.count(&quot;get.request&quot;, (long)(Math.random()* 10)); // Request count of this API</div></pre></td></tr></table></figure>\n</li>\n</ul>\n"},{"title":"Writing YARN Applications","_content":"\n# Hadoop: Writing YARN Applications\n- 原生开发YARN应用\n  - 参考： http://hadoop.apache.org/docs/r3.0.0-alpha2/hadoop-yarn/hadoop-yarn-site/WritingYarnApplications.html\n  - 在YARN上编写一个应用程序，你需要开发Client和ApplicationMaster两个模块，并了解涉及到的几个协议的若干API和参数列表，其中ApplicationMaster还要负责资源申请，任务调度、容错等，总之，整个过程非常复杂。\n- 基于Twill开发\n  - 参考： http://twill.apache.org/GettingStarted.html\n  - 优点： 简化了YARN开发的复杂性；\n  - 缺点： 不容易trouble shooting,封装部分不易detect问题，另外也不能支持最新的Hadoop cluster；文档也太少；\n- 基于Slider开发\n  - 参考： http://slider.incubator.apache.org\n  - 优点： 简化了YARN开发的复杂性；\n  - 缺点： 不容易trouble shooting,封装部分不易detect问题，另外也不能支持最新的Hadoop cluster；本身的框架也很复杂，\n- 基于Spring Hadoop开发\n  - 参考： https://spring.io/guides/gs/yarn-basic/\n  - 优点： 简化了YARN开发的复杂性；\n  - 缺点： 不容易trouble shooting,封装部分不易detect问题，另外也不能支持最新的Hadoop cluster；\n\n## 开发Client和ApplicationMaster\n当用户向YARN中提交一个应用程序后，YARN将分两个阶段运行该应用程序： 第一个阶段是启动ApplicationMaster； 第二个阶段是由ApplicationMaster创建应用程序，为它申请资源，并监控它的整个运行过程，直到运行完成。\n### 1.开发Client启动AM\nClient部分是用于将应用提交到YARN, 从而可以启动application master.\n客户端通常只需与ResourceManager交互，期间涉及到多个数据结构和一个RPC协议，具体如下：\n\n![](images/yarn-dev1.png)\n- 客户端通过RPC协议ApplicationClientProtocol向ResourceManager(也称之为ApplicationsManager、ASM)发送应用程序提交请求GetNewApplicationRequest，ResourceManager为其返回应答GetNewApplicationResponse，该数据结构中包含多种信息，包括ApplicationId、可资源使用上限和下限等。初始化并启动一个yarnClient:\n```\nYarnClient yarnClient = YarnClient.createYarnClient();\nyarnClient.init(conf);\nyarnClient.start();\nYarnClientApplication app = yarnClient.createApplication();\nGetNewApplicationResponse appResponse = app.getNewApplicationResponse();\n```\n- Client部分最关键的是构建一个ApplicationSubmissionContext。启动ApplicationMaster所需的所有信息打包到数据结构ApplicationSubmissionContext中，主要包括以下几种信息：\n  - (1) application id\n  - (2) application 名称\n  - (3) application优先级\n  - (4) application 所属队列\n  - (5) application 启动用户名\n  - (6)  ApplicationMaster对应的Container信息ContainerLaunchContext，包括：启动ApplicationMaster所需各种文件资源、jar包、环境变量、启动命令、运行ApplicationMaster所需的资源（主要指内存）等。\n\n  ```\n  // set the application name\n  ApplicationSubmissionContext appContext = app.getApplicationSubmissionContext();\n  ApplicationId appId = appContext.getApplicationId();\n\n  appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n  appContext.setApplicationName(appName);\n  // Set up the container launch context for the application master\n  ContainerLaunchContext amContainer = ContainerLaunchContext.newInstance(\n    localResources, env, commands, null, null, null);\n\n  // Set up resource type requirements\n  // For now, both memory and vcores are supported, so we set memory and\n  // vcores requirements\n  Resource capability = Resource.newInstance(amMemory, amVCores);\n  appContext.setResource(capability);\n  ```\n\n- 客户端调用ClientRMProtocol#submitApplication(ApplicationSubmissionContext)将ApplicationMaster提交到ResourceManager上。ResourceManager收到请求后，会为ApplicationMaster寻找合适的节点，并在该节点上启动它。\n  ```\n  LOG.info(\"Submitting application to ASM\");\n  yarnClient.submitApplication(appContext);\n  ```\n\n- 客户端可通过多种方式查询应用程序的运行状态，其中一种是调用RPC函数ClientRMProtocol#getApplicationReport获取一个应用程序当前运行状况报告，该报告内容包括应用程序名称、所属用户、所在队列、ApplicationMaster所在节点、一些诊断信息、启动时间等。\n  ```\n  // Get application report for the appId we are interested in\n  ApplicationReport report = yarnClient.getApplicationReport(appId);\n\n  LOG.info(\"Got application report from ASM for\"\n      + \", appId=\" + appId.getId()\n      + \", clientToAMToken=\" + report.getClientToAMToken()\n      + \", appDiagnostics=\" + report.getDiagnostics()\n      + \", appMasterHost=\" + report.getHost()\n      + \", appQueue=\" + report.getQueue()\n      + \", appMasterRpcPort=\" + report.getRpcPort()\n      + \", appStartTime=\" + report.getStartTime()\n      + \", yarnAppState=\" + report.getYarnApplicationState().toString()\n      + \", distributedFinalState=\" + report.getFinalApplicationStatus().toString()\n      + \", appTrackingUrl=\" + report.getTrackingUrl()\n      + \", appUser=\" + report.getUser());\n\n  YarnApplicationState state = report.getYarnApplicationState();\n  FinalApplicationStatus dsStatus = report.getFinalApplicationStatus();\n  ```\n- 如果有异常或者其他情况，可以通过yarnClient.killApplication(appId);来kill掉应用；\n\n### 2.开发ApplicationMaster\nApplicationMaster需要与ResoureManager和NodeManager交互，以申请资源和启动Container，期间涉及到多个数据结构和两个RPC协议。具体步骤如下：\n- ApplicationMaster首先需通过RPC协议AMRMProtocol向ResourceManager发送注册请求RegisterApplicationMasterRequest，该数据结构中包含ApplicationMaster所在节点的host、RPC port和TrackingUrl等信息，而ResourceManager将返回RegisterApplicationMasterResponse，该数据结构中包含多种信息，包括该应用程序的ACL列表、可资源使用上限和下限等。\n\n![](images/yarn-dev2.png)\n\n- ApplicationMaster与RM之间的心跳：整个运行过程中，ApplicationMaster需通过心跳与ResourceManager保持联系，这是因为，如果一段时间内（默认是10min），ResourceManager未收到ApplicationMaster信息，则认为它死掉了，会重新调度或者让其失败。通常而言，ApplicationMaster周期性调用RPC函数ApplicationMasterProtocol.allocate向其发送空的AllocateRequest请求即可。\n\n- 构造Container：根据每个任务的资源需求，ApplicationMaster可向ResourceManager申请一系列用于运行任务的Container，ApplicationMaster使用ResourceRequest类描述每个Container（一个container只能运行一个任务）：\n  - 1）Hostname：期望Container所在的节点，如果是*，表示可以为任意节点。\n  - 2）Resource capability：运行该任务所需的资源量，如(memory/disk/cpu)。\n  - 3）Priority：任务优先级。一个应用程序中的任务可能有多种优先级，ResourceManager会优先为高优先级的任务分配资源。\n  - 4）numContainers：符合以上条件的container数目。\n\n\n- 申请资源分配Container：一旦为任务构造了Container后，ApplicationMaster会使用RPC函数AMRMProtocol#allocate向ResourceManager发送一个AllocateRequest对象，以请求分配这些Container，AllocateRequest中包含以下信息：\n  - 1）Requested containers：所需的Container列表\n  - 2）Released containers：有些情况下，比如有些任务在某些节点上失败过，则ApplicationMaster不想再在这些节点上运行任务，此时可要求释放这些节点上的Container。\n  - 3）Progress update information：应用程序执行进度\n  - 4）ResponseId：RPC响应ID，每次调用RPC，该值会加1。\n- ResourceManager会为ApplicationMaster返回一个AllocateResponse对象，该对象中主要信息包含在AMResponse中：\n  - 1）reboot：ApplicationMaster是否需要重新初始化.当ResourceManager端出现不一致状态时，会要求对应的ApplicationMaster重新初始化。\n  - 2）Allocated Containers：新分配的container列表。\n  - 3）Completed Containers：已运行完成的container列表，该列表中包含运行成功和未成功的Container，ApplicationMaster可能需要重新运行那些未运行成功的Container。\n- ApplicationMaster会不断追踪已经获取的container，且只有当需求发生变化时，才允许重新为Container申请资源。\n\n![](images/yarn-dev3.png)\n\n- 启动Container：当ApplicationMaster（从ResourceManager端）收到新分配的Container列表后，会使用ContainerManagementProtocol#startContainer向对应的NodeManager发送ContainerLaunchContext以启动Container，ContainerLaunchContext包含以下内容：\n  - 1）ContainerId：Container id\n  - 2）Resource：该Container可使用的资源量（当前仅支持内存）\n  - 3）User：Container所属用户\n  - 4）Security tokens：安全令牌，只有持有该令牌才可启动container\n  - 5）LocalResource：运行Container所需的本地资源，比如jar包、二进制文件、其他外部文件等。\n  - 6）ServiceData：应用程序可能使用其他外部服务，这些服务相关的数据通过该参数指定。\n  - 7）Environment：启动container所需的环境变量\n  - 8）command：启动container的命令\n\n\n- 监控Container：ApplicationMaster可以通过2种途径监控启动的Container：\n  - 使用ApplicationMasterProtocol.allocate向ResourceManager发送查询请求；\n  - 使用ContainerManagementProtocol查询指定的ContainerId对应的Container的状态；\n\n\n- ApplicationMaster会不断重复前面的步骤，直到所有任务运行成功，此时，它会发送FinishApplicationMasterRequest，以告诉ResourceManage自己运行结束。\n\n## 基于Twill开发\nApache Twill这个项目则是为简化YARN上应用程序开发而成立的项目，该项目把与YARN相关的重复性的工作封装成库，使得用户可以专注于自己的应用程序逻辑。\n\n下面代码示例是使用Apache Twill开发一个运行在YARN上的helloworld程序：\n```\npublic class HelloWorld {\n static Logger LOG = LoggerFactory.getLogger(HelloWorld.class);\n static class HelloWorldRunnable extends AbstractTwillRunnable {\n\n public void run() {\n   OG.info(\"Hello World\");\n   }\n }\n\npublic static void main(String[] args) throws Exception {\n YarnConfiguration conf = new YarnConfiguration();\n TwillRunnerService runner = new YarnTwillRunnerService(conf, \"localhost:2181\");\n runner.startAndWait();\n\n HelloWorldRunnable helloworldRunner = new HelloWorldRunnable();\n TwillController controller = runner.prepare(helloworldRunner).start();\n Services.getCompletionFuture(controller).get();\n}\n```\n#### 编译Twill\n```\nmvn clean install -DskipTests=true\n```\n\n#### 启动zookeeper\nStart a Zookeeper server instance\n```\n$ docker run --name zk1 --restart always -d -P zookeeper\n```\n\nThis image includes EXPOSE 2181 2888 3888 (the zookeeper client port, follower port, election port respectively), so standard container linking will make it automatically available to the linked containers. Since the Zookeeper \"fails fast\" it's better to always restart it.\n\n#### Run Twill sample\n```\n$ export CP=twill-examples-yarn-0.11.0-SNAPSHOT.jar:`/Users/xiningwang/hadoop/hadoop-2.7.3/bin/hadoop classpath`\n\n$ java -cp $CP org.apache.twill.example.yarn.HelloWorld {zookeeper_host:port}\n```\n#### BundledJarExample Application\n\nThe BundledJarExample application demonstrates the Twill functionality that allows you to run any Java application in Twill without worrying about library version conflicts between your application and Hadoop. The example calls the main class in a sample application Echo, which simply logs the command line argument(s) passed to it. The Echo application uses a different version of Guava from Twill and Hadoop distributions. BundledJarExample looks for the dependency in a lib folder packaged at the root of the Echo jar.\n\nYou can run the BundleJarExample application from any node of the Hadoop cluster using the below command (be sure to add your ZooKeeper Host and Port):\n```\n$ export CP=twill-examples-yarn-0.10.0.jar:`hadoop classpath`\n\n$ java -cp $CP org.apache.twill.example.yarn.BundledJarExample {zookeeper_host:port} \\\n    twill-examples-echo-0.10.0.jar echo.EchoMain arg1\n```\n\n## Slider\n由SliderAM负责给cluster申请资源，并负责容错（component挂掉之后，SliderAM重新找RM申请资源，并进行相应的分配），每个component的实例运行在YARN container中，一个cluster在YARN中的运行流程大致如下：\n\n![Slider](images/slider.png)\n\n## Spring Hadoop\n\n![spring-hadoop](https://spring.io/guides/gs/yarn-basic/images/rm-ui.png)\n","source":"_posts/yarn-appdev.md","raw":"---\ntitle: Writing YARN Applications\n---\n\n# Hadoop: Writing YARN Applications\n- 原生开发YARN应用\n  - 参考： http://hadoop.apache.org/docs/r3.0.0-alpha2/hadoop-yarn/hadoop-yarn-site/WritingYarnApplications.html\n  - 在YARN上编写一个应用程序，你需要开发Client和ApplicationMaster两个模块，并了解涉及到的几个协议的若干API和参数列表，其中ApplicationMaster还要负责资源申请，任务调度、容错等，总之，整个过程非常复杂。\n- 基于Twill开发\n  - 参考： http://twill.apache.org/GettingStarted.html\n  - 优点： 简化了YARN开发的复杂性；\n  - 缺点： 不容易trouble shooting,封装部分不易detect问题，另外也不能支持最新的Hadoop cluster；文档也太少；\n- 基于Slider开发\n  - 参考： http://slider.incubator.apache.org\n  - 优点： 简化了YARN开发的复杂性；\n  - 缺点： 不容易trouble shooting,封装部分不易detect问题，另外也不能支持最新的Hadoop cluster；本身的框架也很复杂，\n- 基于Spring Hadoop开发\n  - 参考： https://spring.io/guides/gs/yarn-basic/\n  - 优点： 简化了YARN开发的复杂性；\n  - 缺点： 不容易trouble shooting,封装部分不易detect问题，另外也不能支持最新的Hadoop cluster；\n\n## 开发Client和ApplicationMaster\n当用户向YARN中提交一个应用程序后，YARN将分两个阶段运行该应用程序： 第一个阶段是启动ApplicationMaster； 第二个阶段是由ApplicationMaster创建应用程序，为它申请资源，并监控它的整个运行过程，直到运行完成。\n### 1.开发Client启动AM\nClient部分是用于将应用提交到YARN, 从而可以启动application master.\n客户端通常只需与ResourceManager交互，期间涉及到多个数据结构和一个RPC协议，具体如下：\n\n![](images/yarn-dev1.png)\n- 客户端通过RPC协议ApplicationClientProtocol向ResourceManager(也称之为ApplicationsManager、ASM)发送应用程序提交请求GetNewApplicationRequest，ResourceManager为其返回应答GetNewApplicationResponse，该数据结构中包含多种信息，包括ApplicationId、可资源使用上限和下限等。初始化并启动一个yarnClient:\n```\nYarnClient yarnClient = YarnClient.createYarnClient();\nyarnClient.init(conf);\nyarnClient.start();\nYarnClientApplication app = yarnClient.createApplication();\nGetNewApplicationResponse appResponse = app.getNewApplicationResponse();\n```\n- Client部分最关键的是构建一个ApplicationSubmissionContext。启动ApplicationMaster所需的所有信息打包到数据结构ApplicationSubmissionContext中，主要包括以下几种信息：\n  - (1) application id\n  - (2) application 名称\n  - (3) application优先级\n  - (4) application 所属队列\n  - (5) application 启动用户名\n  - (6)  ApplicationMaster对应的Container信息ContainerLaunchContext，包括：启动ApplicationMaster所需各种文件资源、jar包、环境变量、启动命令、运行ApplicationMaster所需的资源（主要指内存）等。\n\n  ```\n  // set the application name\n  ApplicationSubmissionContext appContext = app.getApplicationSubmissionContext();\n  ApplicationId appId = appContext.getApplicationId();\n\n  appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n  appContext.setApplicationName(appName);\n  // Set up the container launch context for the application master\n  ContainerLaunchContext amContainer = ContainerLaunchContext.newInstance(\n    localResources, env, commands, null, null, null);\n\n  // Set up resource type requirements\n  // For now, both memory and vcores are supported, so we set memory and\n  // vcores requirements\n  Resource capability = Resource.newInstance(amMemory, amVCores);\n  appContext.setResource(capability);\n  ```\n\n- 客户端调用ClientRMProtocol#submitApplication(ApplicationSubmissionContext)将ApplicationMaster提交到ResourceManager上。ResourceManager收到请求后，会为ApplicationMaster寻找合适的节点，并在该节点上启动它。\n  ```\n  LOG.info(\"Submitting application to ASM\");\n  yarnClient.submitApplication(appContext);\n  ```\n\n- 客户端可通过多种方式查询应用程序的运行状态，其中一种是调用RPC函数ClientRMProtocol#getApplicationReport获取一个应用程序当前运行状况报告，该报告内容包括应用程序名称、所属用户、所在队列、ApplicationMaster所在节点、一些诊断信息、启动时间等。\n  ```\n  // Get application report for the appId we are interested in\n  ApplicationReport report = yarnClient.getApplicationReport(appId);\n\n  LOG.info(\"Got application report from ASM for\"\n      + \", appId=\" + appId.getId()\n      + \", clientToAMToken=\" + report.getClientToAMToken()\n      + \", appDiagnostics=\" + report.getDiagnostics()\n      + \", appMasterHost=\" + report.getHost()\n      + \", appQueue=\" + report.getQueue()\n      + \", appMasterRpcPort=\" + report.getRpcPort()\n      + \", appStartTime=\" + report.getStartTime()\n      + \", yarnAppState=\" + report.getYarnApplicationState().toString()\n      + \", distributedFinalState=\" + report.getFinalApplicationStatus().toString()\n      + \", appTrackingUrl=\" + report.getTrackingUrl()\n      + \", appUser=\" + report.getUser());\n\n  YarnApplicationState state = report.getYarnApplicationState();\n  FinalApplicationStatus dsStatus = report.getFinalApplicationStatus();\n  ```\n- 如果有异常或者其他情况，可以通过yarnClient.killApplication(appId);来kill掉应用；\n\n### 2.开发ApplicationMaster\nApplicationMaster需要与ResoureManager和NodeManager交互，以申请资源和启动Container，期间涉及到多个数据结构和两个RPC协议。具体步骤如下：\n- ApplicationMaster首先需通过RPC协议AMRMProtocol向ResourceManager发送注册请求RegisterApplicationMasterRequest，该数据结构中包含ApplicationMaster所在节点的host、RPC port和TrackingUrl等信息，而ResourceManager将返回RegisterApplicationMasterResponse，该数据结构中包含多种信息，包括该应用程序的ACL列表、可资源使用上限和下限等。\n\n![](images/yarn-dev2.png)\n\n- ApplicationMaster与RM之间的心跳：整个运行过程中，ApplicationMaster需通过心跳与ResourceManager保持联系，这是因为，如果一段时间内（默认是10min），ResourceManager未收到ApplicationMaster信息，则认为它死掉了，会重新调度或者让其失败。通常而言，ApplicationMaster周期性调用RPC函数ApplicationMasterProtocol.allocate向其发送空的AllocateRequest请求即可。\n\n- 构造Container：根据每个任务的资源需求，ApplicationMaster可向ResourceManager申请一系列用于运行任务的Container，ApplicationMaster使用ResourceRequest类描述每个Container（一个container只能运行一个任务）：\n  - 1）Hostname：期望Container所在的节点，如果是*，表示可以为任意节点。\n  - 2）Resource capability：运行该任务所需的资源量，如(memory/disk/cpu)。\n  - 3）Priority：任务优先级。一个应用程序中的任务可能有多种优先级，ResourceManager会优先为高优先级的任务分配资源。\n  - 4）numContainers：符合以上条件的container数目。\n\n\n- 申请资源分配Container：一旦为任务构造了Container后，ApplicationMaster会使用RPC函数AMRMProtocol#allocate向ResourceManager发送一个AllocateRequest对象，以请求分配这些Container，AllocateRequest中包含以下信息：\n  - 1）Requested containers：所需的Container列表\n  - 2）Released containers：有些情况下，比如有些任务在某些节点上失败过，则ApplicationMaster不想再在这些节点上运行任务，此时可要求释放这些节点上的Container。\n  - 3）Progress update information：应用程序执行进度\n  - 4）ResponseId：RPC响应ID，每次调用RPC，该值会加1。\n- ResourceManager会为ApplicationMaster返回一个AllocateResponse对象，该对象中主要信息包含在AMResponse中：\n  - 1）reboot：ApplicationMaster是否需要重新初始化.当ResourceManager端出现不一致状态时，会要求对应的ApplicationMaster重新初始化。\n  - 2）Allocated Containers：新分配的container列表。\n  - 3）Completed Containers：已运行完成的container列表，该列表中包含运行成功和未成功的Container，ApplicationMaster可能需要重新运行那些未运行成功的Container。\n- ApplicationMaster会不断追踪已经获取的container，且只有当需求发生变化时，才允许重新为Container申请资源。\n\n![](images/yarn-dev3.png)\n\n- 启动Container：当ApplicationMaster（从ResourceManager端）收到新分配的Container列表后，会使用ContainerManagementProtocol#startContainer向对应的NodeManager发送ContainerLaunchContext以启动Container，ContainerLaunchContext包含以下内容：\n  - 1）ContainerId：Container id\n  - 2）Resource：该Container可使用的资源量（当前仅支持内存）\n  - 3）User：Container所属用户\n  - 4）Security tokens：安全令牌，只有持有该令牌才可启动container\n  - 5）LocalResource：运行Container所需的本地资源，比如jar包、二进制文件、其他外部文件等。\n  - 6）ServiceData：应用程序可能使用其他外部服务，这些服务相关的数据通过该参数指定。\n  - 7）Environment：启动container所需的环境变量\n  - 8）command：启动container的命令\n\n\n- 监控Container：ApplicationMaster可以通过2种途径监控启动的Container：\n  - 使用ApplicationMasterProtocol.allocate向ResourceManager发送查询请求；\n  - 使用ContainerManagementProtocol查询指定的ContainerId对应的Container的状态；\n\n\n- ApplicationMaster会不断重复前面的步骤，直到所有任务运行成功，此时，它会发送FinishApplicationMasterRequest，以告诉ResourceManage自己运行结束。\n\n## 基于Twill开发\nApache Twill这个项目则是为简化YARN上应用程序开发而成立的项目，该项目把与YARN相关的重复性的工作封装成库，使得用户可以专注于自己的应用程序逻辑。\n\n下面代码示例是使用Apache Twill开发一个运行在YARN上的helloworld程序：\n```\npublic class HelloWorld {\n static Logger LOG = LoggerFactory.getLogger(HelloWorld.class);\n static class HelloWorldRunnable extends AbstractTwillRunnable {\n\n public void run() {\n   OG.info(\"Hello World\");\n   }\n }\n\npublic static void main(String[] args) throws Exception {\n YarnConfiguration conf = new YarnConfiguration();\n TwillRunnerService runner = new YarnTwillRunnerService(conf, \"localhost:2181\");\n runner.startAndWait();\n\n HelloWorldRunnable helloworldRunner = new HelloWorldRunnable();\n TwillController controller = runner.prepare(helloworldRunner).start();\n Services.getCompletionFuture(controller).get();\n}\n```\n#### 编译Twill\n```\nmvn clean install -DskipTests=true\n```\n\n#### 启动zookeeper\nStart a Zookeeper server instance\n```\n$ docker run --name zk1 --restart always -d -P zookeeper\n```\n\nThis image includes EXPOSE 2181 2888 3888 (the zookeeper client port, follower port, election port respectively), so standard container linking will make it automatically available to the linked containers. Since the Zookeeper \"fails fast\" it's better to always restart it.\n\n#### Run Twill sample\n```\n$ export CP=twill-examples-yarn-0.11.0-SNAPSHOT.jar:`/Users/xiningwang/hadoop/hadoop-2.7.3/bin/hadoop classpath`\n\n$ java -cp $CP org.apache.twill.example.yarn.HelloWorld {zookeeper_host:port}\n```\n#### BundledJarExample Application\n\nThe BundledJarExample application demonstrates the Twill functionality that allows you to run any Java application in Twill without worrying about library version conflicts between your application and Hadoop. The example calls the main class in a sample application Echo, which simply logs the command line argument(s) passed to it. The Echo application uses a different version of Guava from Twill and Hadoop distributions. BundledJarExample looks for the dependency in a lib folder packaged at the root of the Echo jar.\n\nYou can run the BundleJarExample application from any node of the Hadoop cluster using the below command (be sure to add your ZooKeeper Host and Port):\n```\n$ export CP=twill-examples-yarn-0.10.0.jar:`hadoop classpath`\n\n$ java -cp $CP org.apache.twill.example.yarn.BundledJarExample {zookeeper_host:port} \\\n    twill-examples-echo-0.10.0.jar echo.EchoMain arg1\n```\n\n## Slider\n由SliderAM负责给cluster申请资源，并负责容错（component挂掉之后，SliderAM重新找RM申请资源，并进行相应的分配），每个component的实例运行在YARN container中，一个cluster在YARN中的运行流程大致如下：\n\n![Slider](images/slider.png)\n\n## Spring Hadoop\n\n![spring-hadoop](https://spring.io/guides/gs/yarn-basic/images/rm-ui.png)\n","slug":"yarn-appdev","published":1,"date":"2017-03-28T14:17:15.000Z","updated":"2017-05-08T13:32:54.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj2g8ok43000mdl721t8lb5bb","content":"<h1 id=\"Hadoop-Writing-YARN-Applications\"><a href=\"#Hadoop-Writing-YARN-Applications\" class=\"headerlink\" title=\"Hadoop: Writing YARN Applications\"></a>Hadoop: Writing YARN Applications</h1><ul>\n<li>原生开发YARN应用<ul>\n<li>参考： <a href=\"http://hadoop.apache.org/docs/r3.0.0-alpha2/hadoop-yarn/hadoop-yarn-site/WritingYarnApplications.html\" target=\"_blank\" rel=\"external\">http://hadoop.apache.org/docs/r3.0.0-alpha2/hadoop-yarn/hadoop-yarn-site/WritingYarnApplications.html</a></li>\n<li>在YARN上编写一个应用程序，你需要开发Client和ApplicationMaster两个模块，并了解涉及到的几个协议的若干API和参数列表，其中ApplicationMaster还要负责资源申请，任务调度、容错等，总之，整个过程非常复杂。</li>\n</ul>\n</li>\n<li>基于Twill开发<ul>\n<li>参考： <a href=\"http://twill.apache.org/GettingStarted.html\" target=\"_blank\" rel=\"external\">http://twill.apache.org/GettingStarted.html</a></li>\n<li>优点： 简化了YARN开发的复杂性；</li>\n<li>缺点： 不容易trouble shooting,封装部分不易detect问题，另外也不能支持最新的Hadoop cluster；文档也太少；</li>\n</ul>\n</li>\n<li>基于Slider开发<ul>\n<li>参考： <a href=\"http://slider.incubator.apache.org\" target=\"_blank\" rel=\"external\">http://slider.incubator.apache.org</a></li>\n<li>优点： 简化了YARN开发的复杂性；</li>\n<li>缺点： 不容易trouble shooting,封装部分不易detect问题，另外也不能支持最新的Hadoop cluster；本身的框架也很复杂，</li>\n</ul>\n</li>\n<li>基于Spring Hadoop开发<ul>\n<li>参考： <a href=\"https://spring.io/guides/gs/yarn-basic/\" target=\"_blank\" rel=\"external\">https://spring.io/guides/gs/yarn-basic/</a></li>\n<li>优点： 简化了YARN开发的复杂性；</li>\n<li>缺点： 不容易trouble shooting,封装部分不易detect问题，另外也不能支持最新的Hadoop cluster；</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"开发Client和ApplicationMaster\"><a href=\"#开发Client和ApplicationMaster\" class=\"headerlink\" title=\"开发Client和ApplicationMaster\"></a>开发Client和ApplicationMaster</h2><p>当用户向YARN中提交一个应用程序后，YARN将分两个阶段运行该应用程序： 第一个阶段是启动ApplicationMaster； 第二个阶段是由ApplicationMaster创建应用程序，为它申请资源，并监控它的整个运行过程，直到运行完成。</p>\n<h3 id=\"1-开发Client启动AM\"><a href=\"#1-开发Client启动AM\" class=\"headerlink\" title=\"1.开发Client启动AM\"></a>1.开发Client启动AM</h3><p>Client部分是用于将应用提交到YARN, 从而可以启动application master.<br>客户端通常只需与ResourceManager交互，期间涉及到多个数据结构和一个RPC协议，具体如下：</p>\n<p><img src=\"images/yarn-dev1.png\" alt=\"\"></p>\n<ul>\n<li><p>客户端通过RPC协议ApplicationClientProtocol向ResourceManager(也称之为ApplicationsManager、ASM)发送应用程序提交请求GetNewApplicationRequest，ResourceManager为其返回应答GetNewApplicationResponse，该数据结构中包含多种信息，包括ApplicationId、可资源使用上限和下限等。初始化并启动一个yarnClient:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">YarnClient yarnClient = YarnClient.createYarnClient();</div><div class=\"line\">yarnClient.init(conf);</div><div class=\"line\">yarnClient.start();</div><div class=\"line\">YarnClientApplication app = yarnClient.createApplication();</div><div class=\"line\">GetNewApplicationResponse appResponse = app.getNewApplicationResponse();</div></pre></td></tr></table></figure>\n</li>\n<li><p>Client部分最关键的是构建一个ApplicationSubmissionContext。启动ApplicationMaster所需的所有信息打包到数据结构ApplicationSubmissionContext中，主要包括以下几种信息：</p>\n<ul>\n<li>(1) application id</li>\n<li>(2) application 名称</li>\n<li>(3) application优先级</li>\n<li>(4) application 所属队列</li>\n<li>(5) application 启动用户名</li>\n<li>(6)  ApplicationMaster对应的Container信息ContainerLaunchContext，包括：启动ApplicationMaster所需各种文件资源、jar包、环境变量、启动命令、运行ApplicationMaster所需的资源（主要指内存）等。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">// set the application name</div><div class=\"line\">ApplicationSubmissionContext appContext = app.getApplicationSubmissionContext();</div><div class=\"line\">ApplicationId appId = appContext.getApplicationId();</div><div class=\"line\"></div><div class=\"line\">appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);</div><div class=\"line\">appContext.setApplicationName(appName);</div><div class=\"line\">// Set up the container launch context for the application master</div><div class=\"line\">ContainerLaunchContext amContainer = ContainerLaunchContext.newInstance(</div><div class=\"line\">  localResources, env, commands, null, null, null);</div><div class=\"line\"></div><div class=\"line\">// Set up resource type requirements</div><div class=\"line\">// For now, both memory and vcores are supported, so we set memory and</div><div class=\"line\">// vcores requirements</div><div class=\"line\">Resource capability = Resource.newInstance(amMemory, amVCores);</div><div class=\"line\">appContext.setResource(capability);</div></pre></td></tr></table></figure>\n</li>\n<li><p>客户端调用ClientRMProtocol#submitApplication(ApplicationSubmissionContext)将ApplicationMaster提交到ResourceManager上。ResourceManager收到请求后，会为ApplicationMaster寻找合适的节点，并在该节点上启动它。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">LOG.info(&quot;Submitting application to ASM&quot;);</div><div class=\"line\">yarnClient.submitApplication(appContext);</div></pre></td></tr></table></figure>\n</li>\n<li><p>客户端可通过多种方式查询应用程序的运行状态，其中一种是调用RPC函数ClientRMProtocol#getApplicationReport获取一个应用程序当前运行状况报告，该报告内容包括应用程序名称、所属用户、所在队列、ApplicationMaster所在节点、一些诊断信息、启动时间等。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div></pre></td><td class=\"code\"><pre><div class=\"line\">// Get application report for the appId we are interested in</div><div class=\"line\">ApplicationReport report = yarnClient.getApplicationReport(appId);</div><div class=\"line\"></div><div class=\"line\">LOG.info(&quot;Got application report from ASM for&quot;</div><div class=\"line\">    + &quot;, appId=&quot; + appId.getId()</div><div class=\"line\">    + &quot;, clientToAMToken=&quot; + report.getClientToAMToken()</div><div class=\"line\">    + &quot;, appDiagnostics=&quot; + report.getDiagnostics()</div><div class=\"line\">    + &quot;, appMasterHost=&quot; + report.getHost()</div><div class=\"line\">    + &quot;, appQueue=&quot; + report.getQueue()</div><div class=\"line\">    + &quot;, appMasterRpcPort=&quot; + report.getRpcPort()</div><div class=\"line\">    + &quot;, appStartTime=&quot; + report.getStartTime()</div><div class=\"line\">    + &quot;, yarnAppState=&quot; + report.getYarnApplicationState().toString()</div><div class=\"line\">    + &quot;, distributedFinalState=&quot; + report.getFinalApplicationStatus().toString()</div><div class=\"line\">    + &quot;, appTrackingUrl=&quot; + report.getTrackingUrl()</div><div class=\"line\">    + &quot;, appUser=&quot; + report.getUser());</div><div class=\"line\"></div><div class=\"line\">YarnApplicationState state = report.getYarnApplicationState();</div><div class=\"line\">FinalApplicationStatus dsStatus = report.getFinalApplicationStatus();</div></pre></td></tr></table></figure>\n</li>\n<li><p>如果有异常或者其他情况，可以通过yarnClient.killApplication(appId);来kill掉应用；</p>\n</li>\n</ul>\n<h3 id=\"2-开发ApplicationMaster\"><a href=\"#2-开发ApplicationMaster\" class=\"headerlink\" title=\"2.开发ApplicationMaster\"></a>2.开发ApplicationMaster</h3><p>ApplicationMaster需要与ResoureManager和NodeManager交互，以申请资源和启动Container，期间涉及到多个数据结构和两个RPC协议。具体步骤如下：</p>\n<ul>\n<li>ApplicationMaster首先需通过RPC协议AMRMProtocol向ResourceManager发送注册请求RegisterApplicationMasterRequest，该数据结构中包含ApplicationMaster所在节点的host、RPC port和TrackingUrl等信息，而ResourceManager将返回RegisterApplicationMasterResponse，该数据结构中包含多种信息，包括该应用程序的ACL列表、可资源使用上限和下限等。</li>\n</ul>\n<p><img src=\"images/yarn-dev2.png\" alt=\"\"></p>\n<ul>\n<li><p>ApplicationMaster与RM之间的心跳：整个运行过程中，ApplicationMaster需通过心跳与ResourceManager保持联系，这是因为，如果一段时间内（默认是10min），ResourceManager未收到ApplicationMaster信息，则认为它死掉了，会重新调度或者让其失败。通常而言，ApplicationMaster周期性调用RPC函数ApplicationMasterProtocol.allocate向其发送空的AllocateRequest请求即可。</p>\n</li>\n<li><p>构造Container：根据每个任务的资源需求，ApplicationMaster可向ResourceManager申请一系列用于运行任务的Container，ApplicationMaster使用ResourceRequest类描述每个Container（一个container只能运行一个任务）：</p>\n<ul>\n<li>1）Hostname：期望Container所在的节点，如果是*，表示可以为任意节点。</li>\n<li>2）Resource capability：运行该任务所需的资源量，如(memory/disk/cpu)。</li>\n<li>3）Priority：任务优先级。一个应用程序中的任务可能有多种优先级，ResourceManager会优先为高优先级的任务分配资源。</li>\n<li>4）numContainers：符合以上条件的container数目。</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>申请资源分配Container：一旦为任务构造了Container后，ApplicationMaster会使用RPC函数AMRMProtocol#allocate向ResourceManager发送一个AllocateRequest对象，以请求分配这些Container，AllocateRequest中包含以下信息：<ul>\n<li>1）Requested containers：所需的Container列表</li>\n<li>2）Released containers：有些情况下，比如有些任务在某些节点上失败过，则ApplicationMaster不想再在这些节点上运行任务，此时可要求释放这些节点上的Container。</li>\n<li>3）Progress update information：应用程序执行进度</li>\n<li>4）ResponseId：RPC响应ID，每次调用RPC，该值会加1。</li>\n</ul>\n</li>\n<li>ResourceManager会为ApplicationMaster返回一个AllocateResponse对象，该对象中主要信息包含在AMResponse中：<ul>\n<li>1）reboot：ApplicationMaster是否需要重新初始化.当ResourceManager端出现不一致状态时，会要求对应的ApplicationMaster重新初始化。</li>\n<li>2）Allocated Containers：新分配的container列表。</li>\n<li>3）Completed Containers：已运行完成的container列表，该列表中包含运行成功和未成功的Container，ApplicationMaster可能需要重新运行那些未运行成功的Container。</li>\n</ul>\n</li>\n<li>ApplicationMaster会不断追踪已经获取的container，且只有当需求发生变化时，才允许重新为Container申请资源。</li>\n</ul>\n<p><img src=\"images/yarn-dev3.png\" alt=\"\"></p>\n<ul>\n<li>启动Container：当ApplicationMaster（从ResourceManager端）收到新分配的Container列表后，会使用ContainerManagementProtocol#startContainer向对应的NodeManager发送ContainerLaunchContext以启动Container，ContainerLaunchContext包含以下内容：<ul>\n<li>1）ContainerId：Container id</li>\n<li>2）Resource：该Container可使用的资源量（当前仅支持内存）</li>\n<li>3）User：Container所属用户</li>\n<li>4）Security tokens：安全令牌，只有持有该令牌才可启动container</li>\n<li>5）LocalResource：运行Container所需的本地资源，比如jar包、二进制文件、其他外部文件等。</li>\n<li>6）ServiceData：应用程序可能使用其他外部服务，这些服务相关的数据通过该参数指定。</li>\n<li>7）Environment：启动container所需的环境变量</li>\n<li>8）command：启动container的命令</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>监控Container：ApplicationMaster可以通过2种途径监控启动的Container：<ul>\n<li>使用ApplicationMasterProtocol.allocate向ResourceManager发送查询请求；</li>\n<li>使用ContainerManagementProtocol查询指定的ContainerId对应的Container的状态；</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>ApplicationMaster会不断重复前面的步骤，直到所有任务运行成功，此时，它会发送FinishApplicationMasterRequest，以告诉ResourceManage自己运行结束。</li>\n</ul>\n<h2 id=\"基于Twill开发\"><a href=\"#基于Twill开发\" class=\"headerlink\" title=\"基于Twill开发\"></a>基于Twill开发</h2><p>Apache Twill这个项目则是为简化YARN上应用程序开发而成立的项目，该项目把与YARN相关的重复性的工作封装成库，使得用户可以专注于自己的应用程序逻辑。</p>\n<p>下面代码示例是使用Apache Twill开发一个运行在YARN上的helloworld程序：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div></pre></td><td class=\"code\"><pre><div class=\"line\">public class HelloWorld &#123;</div><div class=\"line\"> static Logger LOG = LoggerFactory.getLogger(HelloWorld.class);</div><div class=\"line\"> static class HelloWorldRunnable extends AbstractTwillRunnable &#123;</div><div class=\"line\"></div><div class=\"line\"> public void run() &#123;</div><div class=\"line\">   OG.info(&quot;Hello World&quot;);</div><div class=\"line\">   &#125;</div><div class=\"line\"> &#125;</div><div class=\"line\"></div><div class=\"line\">public static void main(String[] args) throws Exception &#123;</div><div class=\"line\"> YarnConfiguration conf = new YarnConfiguration();</div><div class=\"line\"> TwillRunnerService runner = new YarnTwillRunnerService(conf, &quot;localhost:2181&quot;);</div><div class=\"line\"> runner.startAndWait();</div><div class=\"line\"></div><div class=\"line\"> HelloWorldRunnable helloworldRunner = new HelloWorldRunnable();</div><div class=\"line\"> TwillController controller = runner.prepare(helloworldRunner).start();</div><div class=\"line\"> Services.getCompletionFuture(controller).get();</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h4 id=\"编译Twill\"><a href=\"#编译Twill\" class=\"headerlink\" title=\"编译Twill\"></a>编译Twill</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">mvn clean install -DskipTests=true</div></pre></td></tr></table></figure>\n<h4 id=\"启动zookeeper\"><a href=\"#启动zookeeper\" class=\"headerlink\" title=\"启动zookeeper\"></a>启动zookeeper</h4><p>Start a Zookeeper server instance<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ docker run --name zk1 --restart always -d -P zookeeper</div></pre></td></tr></table></figure></p>\n<p>This image includes EXPOSE 2181 2888 3888 (the zookeeper client port, follower port, election port respectively), so standard container linking will make it automatically available to the linked containers. Since the Zookeeper “fails fast” it’s better to always restart it.</p>\n<h4 id=\"Run-Twill-sample\"><a href=\"#Run-Twill-sample\" class=\"headerlink\" title=\"Run Twill sample\"></a>Run Twill sample</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ export CP=twill-examples-yarn-0.11.0-SNAPSHOT.jar:`/Users/xiningwang/hadoop/hadoop-2.7.3/bin/hadoop classpath`</div><div class=\"line\"></div><div class=\"line\">$ java -cp $CP org.apache.twill.example.yarn.HelloWorld &#123;zookeeper_host:port&#125;</div></pre></td></tr></table></figure>\n<h4 id=\"BundledJarExample-Application\"><a href=\"#BundledJarExample-Application\" class=\"headerlink\" title=\"BundledJarExample Application\"></a>BundledJarExample Application</h4><p>The BundledJarExample application demonstrates the Twill functionality that allows you to run any Java application in Twill without worrying about library version conflicts between your application and Hadoop. The example calls the main class in a sample application Echo, which simply logs the command line argument(s) passed to it. The Echo application uses a different version of Guava from Twill and Hadoop distributions. BundledJarExample looks for the dependency in a lib folder packaged at the root of the Echo jar.</p>\n<p>You can run the BundleJarExample application from any node of the Hadoop cluster using the below command (be sure to add your ZooKeeper Host and Port):<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ export CP=twill-examples-yarn-0.10.0.jar:`hadoop classpath`</div><div class=\"line\"></div><div class=\"line\">$ java -cp $CP org.apache.twill.example.yarn.BundledJarExample &#123;zookeeper_host:port&#125; \\</div><div class=\"line\">    twill-examples-echo-0.10.0.jar echo.EchoMain arg1</div></pre></td></tr></table></figure></p>\n<h2 id=\"Slider\"><a href=\"#Slider\" class=\"headerlink\" title=\"Slider\"></a>Slider</h2><p>由SliderAM负责给cluster申请资源，并负责容错（component挂掉之后，SliderAM重新找RM申请资源，并进行相应的分配），每个component的实例运行在YARN container中，一个cluster在YARN中的运行流程大致如下：</p>\n<p><img src=\"images/slider.png\" alt=\"Slider\"></p>\n<h2 id=\"Spring-Hadoop\"><a href=\"#Spring-Hadoop\" class=\"headerlink\" title=\"Spring Hadoop\"></a>Spring Hadoop</h2><p><img src=\"https://spring.io/guides/gs/yarn-basic/images/rm-ui.png\" alt=\"spring-hadoop\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Hadoop-Writing-YARN-Applications\"><a href=\"#Hadoop-Writing-YARN-Applications\" class=\"headerlink\" title=\"Hadoop: Writing YARN Applications\"></a>Hadoop: Writing YARN Applications</h1><ul>\n<li>原生开发YARN应用<ul>\n<li>参考： <a href=\"http://hadoop.apache.org/docs/r3.0.0-alpha2/hadoop-yarn/hadoop-yarn-site/WritingYarnApplications.html\" target=\"_blank\" rel=\"external\">http://hadoop.apache.org/docs/r3.0.0-alpha2/hadoop-yarn/hadoop-yarn-site/WritingYarnApplications.html</a></li>\n<li>在YARN上编写一个应用程序，你需要开发Client和ApplicationMaster两个模块，并了解涉及到的几个协议的若干API和参数列表，其中ApplicationMaster还要负责资源申请，任务调度、容错等，总之，整个过程非常复杂。</li>\n</ul>\n</li>\n<li>基于Twill开发<ul>\n<li>参考： <a href=\"http://twill.apache.org/GettingStarted.html\" target=\"_blank\" rel=\"external\">http://twill.apache.org/GettingStarted.html</a></li>\n<li>优点： 简化了YARN开发的复杂性；</li>\n<li>缺点： 不容易trouble shooting,封装部分不易detect问题，另外也不能支持最新的Hadoop cluster；文档也太少；</li>\n</ul>\n</li>\n<li>基于Slider开发<ul>\n<li>参考： <a href=\"http://slider.incubator.apache.org\" target=\"_blank\" rel=\"external\">http://slider.incubator.apache.org</a></li>\n<li>优点： 简化了YARN开发的复杂性；</li>\n<li>缺点： 不容易trouble shooting,封装部分不易detect问题，另外也不能支持最新的Hadoop cluster；本身的框架也很复杂，</li>\n</ul>\n</li>\n<li>基于Spring Hadoop开发<ul>\n<li>参考： <a href=\"https://spring.io/guides/gs/yarn-basic/\" target=\"_blank\" rel=\"external\">https://spring.io/guides/gs/yarn-basic/</a></li>\n<li>优点： 简化了YARN开发的复杂性；</li>\n<li>缺点： 不容易trouble shooting,封装部分不易detect问题，另外也不能支持最新的Hadoop cluster；</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"开发Client和ApplicationMaster\"><a href=\"#开发Client和ApplicationMaster\" class=\"headerlink\" title=\"开发Client和ApplicationMaster\"></a>开发Client和ApplicationMaster</h2><p>当用户向YARN中提交一个应用程序后，YARN将分两个阶段运行该应用程序： 第一个阶段是启动ApplicationMaster； 第二个阶段是由ApplicationMaster创建应用程序，为它申请资源，并监控它的整个运行过程，直到运行完成。</p>\n<h3 id=\"1-开发Client启动AM\"><a href=\"#1-开发Client启动AM\" class=\"headerlink\" title=\"1.开发Client启动AM\"></a>1.开发Client启动AM</h3><p>Client部分是用于将应用提交到YARN, 从而可以启动application master.<br>客户端通常只需与ResourceManager交互，期间涉及到多个数据结构和一个RPC协议，具体如下：</p>\n<p><img src=\"images/yarn-dev1.png\" alt=\"\"></p>\n<ul>\n<li><p>客户端通过RPC协议ApplicationClientProtocol向ResourceManager(也称之为ApplicationsManager、ASM)发送应用程序提交请求GetNewApplicationRequest，ResourceManager为其返回应答GetNewApplicationResponse，该数据结构中包含多种信息，包括ApplicationId、可资源使用上限和下限等。初始化并启动一个yarnClient:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">YarnClient yarnClient = YarnClient.createYarnClient();</div><div class=\"line\">yarnClient.init(conf);</div><div class=\"line\">yarnClient.start();</div><div class=\"line\">YarnClientApplication app = yarnClient.createApplication();</div><div class=\"line\">GetNewApplicationResponse appResponse = app.getNewApplicationResponse();</div></pre></td></tr></table></figure>\n</li>\n<li><p>Client部分最关键的是构建一个ApplicationSubmissionContext。启动ApplicationMaster所需的所有信息打包到数据结构ApplicationSubmissionContext中，主要包括以下几种信息：</p>\n<ul>\n<li>(1) application id</li>\n<li>(2) application 名称</li>\n<li>(3) application优先级</li>\n<li>(4) application 所属队列</li>\n<li>(5) application 启动用户名</li>\n<li>(6)  ApplicationMaster对应的Container信息ContainerLaunchContext，包括：启动ApplicationMaster所需各种文件资源、jar包、环境变量、启动命令、运行ApplicationMaster所需的资源（主要指内存）等。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">// set the application name</div><div class=\"line\">ApplicationSubmissionContext appContext = app.getApplicationSubmissionContext();</div><div class=\"line\">ApplicationId appId = appContext.getApplicationId();</div><div class=\"line\"></div><div class=\"line\">appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);</div><div class=\"line\">appContext.setApplicationName(appName);</div><div class=\"line\">// Set up the container launch context for the application master</div><div class=\"line\">ContainerLaunchContext amContainer = ContainerLaunchContext.newInstance(</div><div class=\"line\">  localResources, env, commands, null, null, null);</div><div class=\"line\"></div><div class=\"line\">// Set up resource type requirements</div><div class=\"line\">// For now, both memory and vcores are supported, so we set memory and</div><div class=\"line\">// vcores requirements</div><div class=\"line\">Resource capability = Resource.newInstance(amMemory, amVCores);</div><div class=\"line\">appContext.setResource(capability);</div></pre></td></tr></table></figure>\n</li>\n<li><p>客户端调用ClientRMProtocol#submitApplication(ApplicationSubmissionContext)将ApplicationMaster提交到ResourceManager上。ResourceManager收到请求后，会为ApplicationMaster寻找合适的节点，并在该节点上启动它。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">LOG.info(&quot;Submitting application to ASM&quot;);</div><div class=\"line\">yarnClient.submitApplication(appContext);</div></pre></td></tr></table></figure>\n</li>\n<li><p>客户端可通过多种方式查询应用程序的运行状态，其中一种是调用RPC函数ClientRMProtocol#getApplicationReport获取一个应用程序当前运行状况报告，该报告内容包括应用程序名称、所属用户、所在队列、ApplicationMaster所在节点、一些诊断信息、启动时间等。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div></pre></td><td class=\"code\"><pre><div class=\"line\">// Get application report for the appId we are interested in</div><div class=\"line\">ApplicationReport report = yarnClient.getApplicationReport(appId);</div><div class=\"line\"></div><div class=\"line\">LOG.info(&quot;Got application report from ASM for&quot;</div><div class=\"line\">    + &quot;, appId=&quot; + appId.getId()</div><div class=\"line\">    + &quot;, clientToAMToken=&quot; + report.getClientToAMToken()</div><div class=\"line\">    + &quot;, appDiagnostics=&quot; + report.getDiagnostics()</div><div class=\"line\">    + &quot;, appMasterHost=&quot; + report.getHost()</div><div class=\"line\">    + &quot;, appQueue=&quot; + report.getQueue()</div><div class=\"line\">    + &quot;, appMasterRpcPort=&quot; + report.getRpcPort()</div><div class=\"line\">    + &quot;, appStartTime=&quot; + report.getStartTime()</div><div class=\"line\">    + &quot;, yarnAppState=&quot; + report.getYarnApplicationState().toString()</div><div class=\"line\">    + &quot;, distributedFinalState=&quot; + report.getFinalApplicationStatus().toString()</div><div class=\"line\">    + &quot;, appTrackingUrl=&quot; + report.getTrackingUrl()</div><div class=\"line\">    + &quot;, appUser=&quot; + report.getUser());</div><div class=\"line\"></div><div class=\"line\">YarnApplicationState state = report.getYarnApplicationState();</div><div class=\"line\">FinalApplicationStatus dsStatus = report.getFinalApplicationStatus();</div></pre></td></tr></table></figure>\n</li>\n<li><p>如果有异常或者其他情况，可以通过yarnClient.killApplication(appId);来kill掉应用；</p>\n</li>\n</ul>\n<h3 id=\"2-开发ApplicationMaster\"><a href=\"#2-开发ApplicationMaster\" class=\"headerlink\" title=\"2.开发ApplicationMaster\"></a>2.开发ApplicationMaster</h3><p>ApplicationMaster需要与ResoureManager和NodeManager交互，以申请资源和启动Container，期间涉及到多个数据结构和两个RPC协议。具体步骤如下：</p>\n<ul>\n<li>ApplicationMaster首先需通过RPC协议AMRMProtocol向ResourceManager发送注册请求RegisterApplicationMasterRequest，该数据结构中包含ApplicationMaster所在节点的host、RPC port和TrackingUrl等信息，而ResourceManager将返回RegisterApplicationMasterResponse，该数据结构中包含多种信息，包括该应用程序的ACL列表、可资源使用上限和下限等。</li>\n</ul>\n<p><img src=\"images/yarn-dev2.png\" alt=\"\"></p>\n<ul>\n<li><p>ApplicationMaster与RM之间的心跳：整个运行过程中，ApplicationMaster需通过心跳与ResourceManager保持联系，这是因为，如果一段时间内（默认是10min），ResourceManager未收到ApplicationMaster信息，则认为它死掉了，会重新调度或者让其失败。通常而言，ApplicationMaster周期性调用RPC函数ApplicationMasterProtocol.allocate向其发送空的AllocateRequest请求即可。</p>\n</li>\n<li><p>构造Container：根据每个任务的资源需求，ApplicationMaster可向ResourceManager申请一系列用于运行任务的Container，ApplicationMaster使用ResourceRequest类描述每个Container（一个container只能运行一个任务）：</p>\n<ul>\n<li>1）Hostname：期望Container所在的节点，如果是*，表示可以为任意节点。</li>\n<li>2）Resource capability：运行该任务所需的资源量，如(memory/disk/cpu)。</li>\n<li>3）Priority：任务优先级。一个应用程序中的任务可能有多种优先级，ResourceManager会优先为高优先级的任务分配资源。</li>\n<li>4）numContainers：符合以上条件的container数目。</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>申请资源分配Container：一旦为任务构造了Container后，ApplicationMaster会使用RPC函数AMRMProtocol#allocate向ResourceManager发送一个AllocateRequest对象，以请求分配这些Container，AllocateRequest中包含以下信息：<ul>\n<li>1）Requested containers：所需的Container列表</li>\n<li>2）Released containers：有些情况下，比如有些任务在某些节点上失败过，则ApplicationMaster不想再在这些节点上运行任务，此时可要求释放这些节点上的Container。</li>\n<li>3）Progress update information：应用程序执行进度</li>\n<li>4）ResponseId：RPC响应ID，每次调用RPC，该值会加1。</li>\n</ul>\n</li>\n<li>ResourceManager会为ApplicationMaster返回一个AllocateResponse对象，该对象中主要信息包含在AMResponse中：<ul>\n<li>1）reboot：ApplicationMaster是否需要重新初始化.当ResourceManager端出现不一致状态时，会要求对应的ApplicationMaster重新初始化。</li>\n<li>2）Allocated Containers：新分配的container列表。</li>\n<li>3）Completed Containers：已运行完成的container列表，该列表中包含运行成功和未成功的Container，ApplicationMaster可能需要重新运行那些未运行成功的Container。</li>\n</ul>\n</li>\n<li>ApplicationMaster会不断追踪已经获取的container，且只有当需求发生变化时，才允许重新为Container申请资源。</li>\n</ul>\n<p><img src=\"images/yarn-dev3.png\" alt=\"\"></p>\n<ul>\n<li>启动Container：当ApplicationMaster（从ResourceManager端）收到新分配的Container列表后，会使用ContainerManagementProtocol#startContainer向对应的NodeManager发送ContainerLaunchContext以启动Container，ContainerLaunchContext包含以下内容：<ul>\n<li>1）ContainerId：Container id</li>\n<li>2）Resource：该Container可使用的资源量（当前仅支持内存）</li>\n<li>3）User：Container所属用户</li>\n<li>4）Security tokens：安全令牌，只有持有该令牌才可启动container</li>\n<li>5）LocalResource：运行Container所需的本地资源，比如jar包、二进制文件、其他外部文件等。</li>\n<li>6）ServiceData：应用程序可能使用其他外部服务，这些服务相关的数据通过该参数指定。</li>\n<li>7）Environment：启动container所需的环境变量</li>\n<li>8）command：启动container的命令</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>监控Container：ApplicationMaster可以通过2种途径监控启动的Container：<ul>\n<li>使用ApplicationMasterProtocol.allocate向ResourceManager发送查询请求；</li>\n<li>使用ContainerManagementProtocol查询指定的ContainerId对应的Container的状态；</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>ApplicationMaster会不断重复前面的步骤，直到所有任务运行成功，此时，它会发送FinishApplicationMasterRequest，以告诉ResourceManage自己运行结束。</li>\n</ul>\n<h2 id=\"基于Twill开发\"><a href=\"#基于Twill开发\" class=\"headerlink\" title=\"基于Twill开发\"></a>基于Twill开发</h2><p>Apache Twill这个项目则是为简化YARN上应用程序开发而成立的项目，该项目把与YARN相关的重复性的工作封装成库，使得用户可以专注于自己的应用程序逻辑。</p>\n<p>下面代码示例是使用Apache Twill开发一个运行在YARN上的helloworld程序：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div></pre></td><td class=\"code\"><pre><div class=\"line\">public class HelloWorld &#123;</div><div class=\"line\"> static Logger LOG = LoggerFactory.getLogger(HelloWorld.class);</div><div class=\"line\"> static class HelloWorldRunnable extends AbstractTwillRunnable &#123;</div><div class=\"line\"></div><div class=\"line\"> public void run() &#123;</div><div class=\"line\">   OG.info(&quot;Hello World&quot;);</div><div class=\"line\">   &#125;</div><div class=\"line\"> &#125;</div><div class=\"line\"></div><div class=\"line\">public static void main(String[] args) throws Exception &#123;</div><div class=\"line\"> YarnConfiguration conf = new YarnConfiguration();</div><div class=\"line\"> TwillRunnerService runner = new YarnTwillRunnerService(conf, &quot;localhost:2181&quot;);</div><div class=\"line\"> runner.startAndWait();</div><div class=\"line\"></div><div class=\"line\"> HelloWorldRunnable helloworldRunner = new HelloWorldRunnable();</div><div class=\"line\"> TwillController controller = runner.prepare(helloworldRunner).start();</div><div class=\"line\"> Services.getCompletionFuture(controller).get();</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h4 id=\"编译Twill\"><a href=\"#编译Twill\" class=\"headerlink\" title=\"编译Twill\"></a>编译Twill</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">mvn clean install -DskipTests=true</div></pre></td></tr></table></figure>\n<h4 id=\"启动zookeeper\"><a href=\"#启动zookeeper\" class=\"headerlink\" title=\"启动zookeeper\"></a>启动zookeeper</h4><p>Start a Zookeeper server instance<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ docker run --name zk1 --restart always -d -P zookeeper</div></pre></td></tr></table></figure></p>\n<p>This image includes EXPOSE 2181 2888 3888 (the zookeeper client port, follower port, election port respectively), so standard container linking will make it automatically available to the linked containers. Since the Zookeeper “fails fast” it’s better to always restart it.</p>\n<h4 id=\"Run-Twill-sample\"><a href=\"#Run-Twill-sample\" class=\"headerlink\" title=\"Run Twill sample\"></a>Run Twill sample</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ export CP=twill-examples-yarn-0.11.0-SNAPSHOT.jar:`/Users/xiningwang/hadoop/hadoop-2.7.3/bin/hadoop classpath`</div><div class=\"line\"></div><div class=\"line\">$ java -cp $CP org.apache.twill.example.yarn.HelloWorld &#123;zookeeper_host:port&#125;</div></pre></td></tr></table></figure>\n<h4 id=\"BundledJarExample-Application\"><a href=\"#BundledJarExample-Application\" class=\"headerlink\" title=\"BundledJarExample Application\"></a>BundledJarExample Application</h4><p>The BundledJarExample application demonstrates the Twill functionality that allows you to run any Java application in Twill without worrying about library version conflicts between your application and Hadoop. The example calls the main class in a sample application Echo, which simply logs the command line argument(s) passed to it. The Echo application uses a different version of Guava from Twill and Hadoop distributions. BundledJarExample looks for the dependency in a lib folder packaged at the root of the Echo jar.</p>\n<p>You can run the BundleJarExample application from any node of the Hadoop cluster using the below command (be sure to add your ZooKeeper Host and Port):<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ export CP=twill-examples-yarn-0.10.0.jar:`hadoop classpath`</div><div class=\"line\"></div><div class=\"line\">$ java -cp $CP org.apache.twill.example.yarn.BundledJarExample &#123;zookeeper_host:port&#125; \\</div><div class=\"line\">    twill-examples-echo-0.10.0.jar echo.EchoMain arg1</div></pre></td></tr></table></figure></p>\n<h2 id=\"Slider\"><a href=\"#Slider\" class=\"headerlink\" title=\"Slider\"></a>Slider</h2><p>由SliderAM负责给cluster申请资源，并负责容错（component挂掉之后，SliderAM重新找RM申请资源，并进行相应的分配），每个component的实例运行在YARN container中，一个cluster在YARN中的运行流程大致如下：</p>\n<p><img src=\"images/slider.png\" alt=\"Slider\"></p>\n<h2 id=\"Spring-Hadoop\"><a href=\"#Spring-Hadoop\" class=\"headerlink\" title=\"Spring Hadoop\"></a>Spring Hadoop</h2><p><img src=\"https://spring.io/guides/gs/yarn-basic/images/rm-ui.png\" alt=\"spring-hadoop\"></p>\n"},{"title":"YARN基本架构","_content":"\n###  YARN基本架构\nYARN是Hadoop 2.0中的资源管理系统，它的基本设计思想是将MRv1中的JobTracker拆分成了两个独立的服务：\n  - 一个全局的资源管理器ResourceManager\n  - 每个应用程序特有的ApplicationMaster。\n\n  其中ResourceManager负责整个系统的资源管理和分配，而ApplicationMaster负责单个应用程序的管理。\n\nYARN 总体上仍然是Master/Slave结构，在整个资源管理框架中，ResourceManager为Master，NodeManager为 Slave，ResourceManager负责对各个NodeManager上的资源进行统一管理和调度。当用户提交一个应用程序时，需要提供一个用以 跟踪和管理这个程序的ApplicationMaster，它负责向ResourceManager申请资源，并要求NodeManger启动可以占用一 定资源的任务。由于不同的ApplicationMaster被分布到不同的节点上，因此它们之间不会相互影响。\n![yarn_architecture](http://hadoop.apache.org/docs/r3.0.0-alpha2/hadoop-yarn/hadoop-yarn-site/yarn_architecture.gif)\n\n#### 1.ResourceManager(RM)\nRM是一个全局的资源管理器，负责整个系统的资源管理和分配。它主要由两个组件构成：调度器（Scheduler）和应用程序管理器（Applications Manager，AM）。\n\n(1)：调度器\n\n调度器根据容量、队列等限制条件（如每个队列分配一定的资源，最多执行一定数量的作业等），将系统中的资源分配给各个正在运行的应用程序。需要注意的是，该调度器是一个“纯调度器”，它不再从事任何与具体应用程序相关的工作，比如不负责监控或者跟踪应用的执行状态等，也不负责重新启动因应用执 行失败或者硬件故障而产生的失败任务，这些均交由应用程序相关的ApplicationMaster完成。调度器仅根据各个应用程序的资源需求进行资源分 配，而资源分配单位用一个抽象概念“资源容器”（Resource Container，简称Container）表示，Container是一个动态资源分配单位，它将内存、 CPU、磁盘、网络等资源封装在一起，从而限定每个任务使用的资源量。此外，该调度器是一个可插拔的组件，用户可根据自己的需要设计新的调度器，YARN 提供了多种直接可用的调度器，比如Fair Scheduler和Capacity Scheduler等。\n\n（2）:应用程序管理器\n\n应用程序管理器负责管理整个系统中所有应用程序，包括应用程序提交、与调度器协商资源以启动ApplicationMaster、监控ApplicationMaster运行状态并在失败时重新启动它等。\n\n#### 2.ApplicationMaster(AM)\n用户提交的每个应用程序均包含1个AM，主要功能包括：\n\n与RM调度器协商以获取资源（用Container表示）；\n\n将得到的任务进一步分配给内部的任务；\n\n与NM通信以启动/停止任务；\n\n监控所有任务运行状态，并在任务运行失败时重新为任务申请资源以重启任务。\n\n#### 3.NodeManager(NM)\nNM是每个节点上的资源和任务管理器，一方面，它会定时地向RM汇报本节点上的资源使用情况和各个Container的运行状态；另一方面，它接收并处理来自AM的Container启动/停止等各种请求。\n\n#### 4.Container\nContainer 是YARN中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等，当AM向RM申请资源时，RM为AM返回的资源便是用 Container表示的。YARN会为每个任务分配一个Container，且该任务只能使用该Container中描述的资源。\n目前，YARN仅支持CPU和内存两种资源，且使用了轻量级资源隔离机制Cgroups进行资源隔离。\n\n### YARN工作流程\n当用户向YARN中提交一个应用程序后，YARN将分两个阶段运行该应用程序：\n第一个阶段是启动ApplicationMaster；\n第二个阶段是由ApplicationMaster创建应用程序，为它申请资源，并监控它的整个运行过程，直到运行完成。\n\nYARN的工作流程分为以下几个步骤：\n- 步骤1：　用户向YARN中提交应用程序，其中包括ApplicationMaster程序、启动ApplicationMaster的命令、用户程序等。\n- 步骤2：　ResourceManager为该应用程序分配第一个Container，并与对应的NodeManager通信，要求它在这个Container中启动应用程序的ApplicationMaster。\n- 步骤3：　ApplicationMaster首先向ResourceManager注册，这样用户可以直接通过ResourceManager查看应用程序的运行状态，然后它将为各个任务申请资源，并监控它的运行状态，直到运行结束，即重复步骤4~7。\n- 步骤4：　ApplicationMaster采用轮询的方式通过RPC协议向ResourceManager申请和领取资源。\n- 步骤5：　一旦ApplicationMaster申请到资源后，便与对应的NodeManager通信，要求它启动任务。\n- 步骤6：　NodeManager为任务设置好运行环境（包括环境变量、JAR包、二进制程序等）后，将任务启动命令写到一个脚本中，并通过运行该脚本启动任务。\n- 步骤7：　各个任务通过某个RPC协议向ApplicationMaster汇报自己的状态和进度，以让ApplicationMaster随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务。在应用程序运行过程中，用户可随时通过RPC向ApplicationMaster查询应用程序的当前运行状态。\n- 步骤8：　应用程序运行完成后，ApplicationMaster向ResourceManager注销并关闭自己。\n\n### Hadoop: Writing YARN Applications\nsee http://hadoop.apache.org/docs/r3.0.0-alpha2/hadoop-yarn/hadoop-yarn-site/WritingYarnApplications.html\n\n#### 1. 文件格式化与启动namenode&DataNode\n```\n$ bin/hdfs namenode -format\n\n$ sbin/start-dfs.sh\n\n```\n#### 2. 启动RM&NM\n```\n$ sbin/start-yarn.sh\n\nResourceManager - http://localhost:8088/\n```\n\n#### 3. 例子：\n包含了实现一个application的三个要求:\n- 客户端和RM （Client.Java）\n  - 客户端提交application\n- AM和RM （ApplicationMaster.java）\n  - 注册AM，申请分配container\n- AM和NM （ApplicationMaster.java）\n  - 启动container\n\n执行命令：\n```\nhadoop jar hadoop-yarn-applications-distributedshell-3.0.0-alpha2.jar org.apache.hadoop.yarn.applications.distributedshell.Client -jar hadoop-yarn-applications-distributedshell-3.0.0-alpha2.jar -shell_command '/bin/date'\n```\n启动10个container，每个都执行`date`命令\n执行代码流程:\n1. 客户端通过org.apache.hadoop.yarn.applications.distributedshell.Client提交application到RM，需提供ApplicationSubmissionContext\n2. org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster提交containers请求，执行用户提交的命令ContainerLaunchContext.commands\n\n客户端(Client.java):\n1. YarnClient.getNewApplication\n2. 填充ApplicationSubmissionContext,ContainerLaunchContext（启动AM的Container）​\n3. YarnClient.submitApplication​\n4. 每隔一段时间调用YarnClient.getApplicationReport获得Application Status\n\n```\n  // 创建AM的上下文信息  \n  ContainerLaunchContext amContainer = Records.newRecord(ContainerLaunchContext.class);  \n  // 设置本地资源，AppMaster.jar包，log4j.properties  \n  amContainer.setLocalResources(localResources);  \n  // 环境变量,shell脚本在hdfs的地址, CLASSPATH  \n  amContainer.setEnvironment(env);  \n  // 设置启动AM的命令和参数  \n  Vector<CharSequence> vargs = new Vector<CharSequence>(30);  \n  vargs.add(\"${JAVA_HOME}\" + \"/bin/java\");  \n  vargs.add(\"-Xmx\" + amMemory + \"m\");  \n  // AM主类  \n  vargs.add(\"org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster?\");  \n  vargs.add(\"--container_memory \" + String.valueOf(containerMemory));  \n  vargs.add(\"--num_containers \" + String.valueOf(numContainers));  \n  vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));  \n  if (!shellCommand.isEmpty()) {  \n  vargs.add(\"--shell_command \" + shellCommand + \"\");  \n  }  \n  if (!shellArgs.isEmpty()) {  \n  vargs.add(\"--shell_args \" + shellArgs + \"\");  \n  }  \n  for (Map.Entry<String, String> entry : shellEnv.entrySet()) {  \n  vargs.add(\"--shell_env \" + entry.getKey() + \"=\" + entry.getValue());  \n  }  \n  vargs.add(\"1>\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");  \n  vargs.add(\"2>\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");  \n\n  amContainer.setCommands(commands);  \n  // 设置Resource需求，目前只设置memory  \n  capability.setMemory(amMemory);  \n  amContainer.setResource(capability);  \n  appContext.setAMContainerSpec(amContainer);  \n  // 提交application到RM  \n  super.submitApplication(appContext);\n```\nApplicationMaster(ApplicationMaster.java​)\n1. AMRMClient.registerApplicationMaster​​\n2. 提供ContainerRequest到AMRMClient.addContainerRequest​\n3. 通过AMRMClient.allocate获得container\n4. container放入新建的LaunchContainerRunnable线程内执行\n5. 创建ContainerLaunchContext​，设置localResource，shellcommand, shellArgs等​​container启动信息\n6. ContainerManager.startContainer(startReq)​​\n7. 下次RPC call后得到的Response信息，AMResponse.getCompletedContainersStatuses​​\n8. AMRMClient.unregisterApplicationMaster​​\n\n```\n  // 新建AMRMClient，2.1beta版本实现了异步AMRMClient，这里还是同步的方式  \n  resourceManager = new AMRMClientImpl(appAttemptID);  \n  resourceManager.init(conf);  \n  resourceManager.start();  \n  // 向RM注册自己  \n  RegisterApplicationMasterResponse response = resourceManager  \n    .registerApplicationMaster(appMasterHostname, appMasterRpcPort,  \n        appMasterTrackingUrl);  \n  while (numCompletedContainers.get() < numTotalContainers && !appDone) {  \n  // 封装Container请求，设置Resource需求，这边只设置了memory  \n  ContainerRequest containerAsk = setupContainerAskForRM(askCount);  \n  resourceManager.addContainerRequest(containerAsk);  \n\n  // Send the request to RM  \n  LOG.info(\"Asking RM for containers\" + \", askCount=\" + askCount);  \n  AMResponse amResp = sendContainerAskToRM();  \n\n  // Retrieve list of allocated containers from the response  \n  List<Container> allocatedContainers = amResp.getAllocatedContainers();  \n  for (Container allocatedContainer : allocatedContainers) {  \n      //新建一个线程来提交container启动请求，这样主线程就不会被block住了  \n      LaunchContainerRunnable runnableLaunchContainer = new LaunchContainerRunnable(  \n        allocatedContainer);  \n      Thread launchThread = new Thread(runnableLaunchContainer);  \n      launchThreads.add(launchThread);  \n      launchThread.start();  \n  }  \n  List<ContainerStatus> completedContainers = amResp.getCompletedContainersStatuses();  \n  }  \n  // 向RM注销自己  \n  resourceManager.unregisterApplicationMaster(appStatus, appMessage, null);  \n```\n","source":"_posts/yarn.md","raw":"---\ntitle: YARN基本架构\n---\n\n###  YARN基本架构\nYARN是Hadoop 2.0中的资源管理系统，它的基本设计思想是将MRv1中的JobTracker拆分成了两个独立的服务：\n  - 一个全局的资源管理器ResourceManager\n  - 每个应用程序特有的ApplicationMaster。\n\n  其中ResourceManager负责整个系统的资源管理和分配，而ApplicationMaster负责单个应用程序的管理。\n\nYARN 总体上仍然是Master/Slave结构，在整个资源管理框架中，ResourceManager为Master，NodeManager为 Slave，ResourceManager负责对各个NodeManager上的资源进行统一管理和调度。当用户提交一个应用程序时，需要提供一个用以 跟踪和管理这个程序的ApplicationMaster，它负责向ResourceManager申请资源，并要求NodeManger启动可以占用一 定资源的任务。由于不同的ApplicationMaster被分布到不同的节点上，因此它们之间不会相互影响。\n![yarn_architecture](http://hadoop.apache.org/docs/r3.0.0-alpha2/hadoop-yarn/hadoop-yarn-site/yarn_architecture.gif)\n\n#### 1.ResourceManager(RM)\nRM是一个全局的资源管理器，负责整个系统的资源管理和分配。它主要由两个组件构成：调度器（Scheduler）和应用程序管理器（Applications Manager，AM）。\n\n(1)：调度器\n\n调度器根据容量、队列等限制条件（如每个队列分配一定的资源，最多执行一定数量的作业等），将系统中的资源分配给各个正在运行的应用程序。需要注意的是，该调度器是一个“纯调度器”，它不再从事任何与具体应用程序相关的工作，比如不负责监控或者跟踪应用的执行状态等，也不负责重新启动因应用执 行失败或者硬件故障而产生的失败任务，这些均交由应用程序相关的ApplicationMaster完成。调度器仅根据各个应用程序的资源需求进行资源分 配，而资源分配单位用一个抽象概念“资源容器”（Resource Container，简称Container）表示，Container是一个动态资源分配单位，它将内存、 CPU、磁盘、网络等资源封装在一起，从而限定每个任务使用的资源量。此外，该调度器是一个可插拔的组件，用户可根据自己的需要设计新的调度器，YARN 提供了多种直接可用的调度器，比如Fair Scheduler和Capacity Scheduler等。\n\n（2）:应用程序管理器\n\n应用程序管理器负责管理整个系统中所有应用程序，包括应用程序提交、与调度器协商资源以启动ApplicationMaster、监控ApplicationMaster运行状态并在失败时重新启动它等。\n\n#### 2.ApplicationMaster(AM)\n用户提交的每个应用程序均包含1个AM，主要功能包括：\n\n与RM调度器协商以获取资源（用Container表示）；\n\n将得到的任务进一步分配给内部的任务；\n\n与NM通信以启动/停止任务；\n\n监控所有任务运行状态，并在任务运行失败时重新为任务申请资源以重启任务。\n\n#### 3.NodeManager(NM)\nNM是每个节点上的资源和任务管理器，一方面，它会定时地向RM汇报本节点上的资源使用情况和各个Container的运行状态；另一方面，它接收并处理来自AM的Container启动/停止等各种请求。\n\n#### 4.Container\nContainer 是YARN中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等，当AM向RM申请资源时，RM为AM返回的资源便是用 Container表示的。YARN会为每个任务分配一个Container，且该任务只能使用该Container中描述的资源。\n目前，YARN仅支持CPU和内存两种资源，且使用了轻量级资源隔离机制Cgroups进行资源隔离。\n\n### YARN工作流程\n当用户向YARN中提交一个应用程序后，YARN将分两个阶段运行该应用程序：\n第一个阶段是启动ApplicationMaster；\n第二个阶段是由ApplicationMaster创建应用程序，为它申请资源，并监控它的整个运行过程，直到运行完成。\n\nYARN的工作流程分为以下几个步骤：\n- 步骤1：　用户向YARN中提交应用程序，其中包括ApplicationMaster程序、启动ApplicationMaster的命令、用户程序等。\n- 步骤2：　ResourceManager为该应用程序分配第一个Container，并与对应的NodeManager通信，要求它在这个Container中启动应用程序的ApplicationMaster。\n- 步骤3：　ApplicationMaster首先向ResourceManager注册，这样用户可以直接通过ResourceManager查看应用程序的运行状态，然后它将为各个任务申请资源，并监控它的运行状态，直到运行结束，即重复步骤4~7。\n- 步骤4：　ApplicationMaster采用轮询的方式通过RPC协议向ResourceManager申请和领取资源。\n- 步骤5：　一旦ApplicationMaster申请到资源后，便与对应的NodeManager通信，要求它启动任务。\n- 步骤6：　NodeManager为任务设置好运行环境（包括环境变量、JAR包、二进制程序等）后，将任务启动命令写到一个脚本中，并通过运行该脚本启动任务。\n- 步骤7：　各个任务通过某个RPC协议向ApplicationMaster汇报自己的状态和进度，以让ApplicationMaster随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务。在应用程序运行过程中，用户可随时通过RPC向ApplicationMaster查询应用程序的当前运行状态。\n- 步骤8：　应用程序运行完成后，ApplicationMaster向ResourceManager注销并关闭自己。\n\n### Hadoop: Writing YARN Applications\nsee http://hadoop.apache.org/docs/r3.0.0-alpha2/hadoop-yarn/hadoop-yarn-site/WritingYarnApplications.html\n\n#### 1. 文件格式化与启动namenode&DataNode\n```\n$ bin/hdfs namenode -format\n\n$ sbin/start-dfs.sh\n\n```\n#### 2. 启动RM&NM\n```\n$ sbin/start-yarn.sh\n\nResourceManager - http://localhost:8088/\n```\n\n#### 3. 例子：\n包含了实现一个application的三个要求:\n- 客户端和RM （Client.Java）\n  - 客户端提交application\n- AM和RM （ApplicationMaster.java）\n  - 注册AM，申请分配container\n- AM和NM （ApplicationMaster.java）\n  - 启动container\n\n执行命令：\n```\nhadoop jar hadoop-yarn-applications-distributedshell-3.0.0-alpha2.jar org.apache.hadoop.yarn.applications.distributedshell.Client -jar hadoop-yarn-applications-distributedshell-3.0.0-alpha2.jar -shell_command '/bin/date'\n```\n启动10个container，每个都执行`date`命令\n执行代码流程:\n1. 客户端通过org.apache.hadoop.yarn.applications.distributedshell.Client提交application到RM，需提供ApplicationSubmissionContext\n2. org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster提交containers请求，执行用户提交的命令ContainerLaunchContext.commands\n\n客户端(Client.java):\n1. YarnClient.getNewApplication\n2. 填充ApplicationSubmissionContext,ContainerLaunchContext（启动AM的Container）​\n3. YarnClient.submitApplication​\n4. 每隔一段时间调用YarnClient.getApplicationReport获得Application Status\n\n```\n  // 创建AM的上下文信息  \n  ContainerLaunchContext amContainer = Records.newRecord(ContainerLaunchContext.class);  \n  // 设置本地资源，AppMaster.jar包，log4j.properties  \n  amContainer.setLocalResources(localResources);  \n  // 环境变量,shell脚本在hdfs的地址, CLASSPATH  \n  amContainer.setEnvironment(env);  \n  // 设置启动AM的命令和参数  \n  Vector<CharSequence> vargs = new Vector<CharSequence>(30);  \n  vargs.add(\"${JAVA_HOME}\" + \"/bin/java\");  \n  vargs.add(\"-Xmx\" + amMemory + \"m\");  \n  // AM主类  \n  vargs.add(\"org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster?\");  \n  vargs.add(\"--container_memory \" + String.valueOf(containerMemory));  \n  vargs.add(\"--num_containers \" + String.valueOf(numContainers));  \n  vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));  \n  if (!shellCommand.isEmpty()) {  \n  vargs.add(\"--shell_command \" + shellCommand + \"\");  \n  }  \n  if (!shellArgs.isEmpty()) {  \n  vargs.add(\"--shell_args \" + shellArgs + \"\");  \n  }  \n  for (Map.Entry<String, String> entry : shellEnv.entrySet()) {  \n  vargs.add(\"--shell_env \" + entry.getKey() + \"=\" + entry.getValue());  \n  }  \n  vargs.add(\"1>\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");  \n  vargs.add(\"2>\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");  \n\n  amContainer.setCommands(commands);  \n  // 设置Resource需求，目前只设置memory  \n  capability.setMemory(amMemory);  \n  amContainer.setResource(capability);  \n  appContext.setAMContainerSpec(amContainer);  \n  // 提交application到RM  \n  super.submitApplication(appContext);\n```\nApplicationMaster(ApplicationMaster.java​)\n1. AMRMClient.registerApplicationMaster​​\n2. 提供ContainerRequest到AMRMClient.addContainerRequest​\n3. 通过AMRMClient.allocate获得container\n4. container放入新建的LaunchContainerRunnable线程内执行\n5. 创建ContainerLaunchContext​，设置localResource，shellcommand, shellArgs等​​container启动信息\n6. ContainerManager.startContainer(startReq)​​\n7. 下次RPC call后得到的Response信息，AMResponse.getCompletedContainersStatuses​​\n8. AMRMClient.unregisterApplicationMaster​​\n\n```\n  // 新建AMRMClient，2.1beta版本实现了异步AMRMClient，这里还是同步的方式  \n  resourceManager = new AMRMClientImpl(appAttemptID);  \n  resourceManager.init(conf);  \n  resourceManager.start();  \n  // 向RM注册自己  \n  RegisterApplicationMasterResponse response = resourceManager  \n    .registerApplicationMaster(appMasterHostname, appMasterRpcPort,  \n        appMasterTrackingUrl);  \n  while (numCompletedContainers.get() < numTotalContainers && !appDone) {  \n  // 封装Container请求，设置Resource需求，这边只设置了memory  \n  ContainerRequest containerAsk = setupContainerAskForRM(askCount);  \n  resourceManager.addContainerRequest(containerAsk);  \n\n  // Send the request to RM  \n  LOG.info(\"Asking RM for containers\" + \", askCount=\" + askCount);  \n  AMResponse amResp = sendContainerAskToRM();  \n\n  // Retrieve list of allocated containers from the response  \n  List<Container> allocatedContainers = amResp.getAllocatedContainers();  \n  for (Container allocatedContainer : allocatedContainers) {  \n      //新建一个线程来提交container启动请求，这样主线程就不会被block住了  \n      LaunchContainerRunnable runnableLaunchContainer = new LaunchContainerRunnable(  \n        allocatedContainer);  \n      Thread launchThread = new Thread(runnableLaunchContainer);  \n      launchThreads.add(launchThread);  \n      launchThread.start();  \n  }  \n  List<ContainerStatus> completedContainers = amResp.getCompletedContainersStatuses();  \n  }  \n  // 向RM注销自己  \n  resourceManager.unregisterApplicationMaster(appStatus, appMessage, null);  \n```\n","slug":"yarn","published":1,"date":"2017-03-26T14:39:26.000Z","updated":"2017-05-08T13:33:06.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj2g8ok45000ndl72q5xemxjz","content":"<h3 id=\"YARN基本架构\"><a href=\"#YARN基本架构\" class=\"headerlink\" title=\"YARN基本架构\"></a>YARN基本架构</h3><p>YARN是Hadoop 2.0中的资源管理系统，它的基本设计思想是将MRv1中的JobTracker拆分成了两个独立的服务：</p>\n<ul>\n<li>一个全局的资源管理器ResourceManager</li>\n<li><p>每个应用程序特有的ApplicationMaster。</p>\n<p>其中ResourceManager负责整个系统的资源管理和分配，而ApplicationMaster负责单个应用程序的管理。</p>\n</li>\n</ul>\n<p>YARN 总体上仍然是Master/Slave结构，在整个资源管理框架中，ResourceManager为Master，NodeManager为 Slave，ResourceManager负责对各个NodeManager上的资源进行统一管理和调度。当用户提交一个应用程序时，需要提供一个用以 跟踪和管理这个程序的ApplicationMaster，它负责向ResourceManager申请资源，并要求NodeManger启动可以占用一 定资源的任务。由于不同的ApplicationMaster被分布到不同的节点上，因此它们之间不会相互影响。<br><img src=\"http://hadoop.apache.org/docs/r3.0.0-alpha2/hadoop-yarn/hadoop-yarn-site/yarn_architecture.gif\" alt=\"yarn_architecture\"></p>\n<h4 id=\"1-ResourceManager-RM\"><a href=\"#1-ResourceManager-RM\" class=\"headerlink\" title=\"1.ResourceManager(RM)\"></a>1.ResourceManager(RM)</h4><p>RM是一个全局的资源管理器，负责整个系统的资源管理和分配。它主要由两个组件构成：调度器（Scheduler）和应用程序管理器（Applications Manager，AM）。</p>\n<p>(1)：调度器</p>\n<p>调度器根据容量、队列等限制条件（如每个队列分配一定的资源，最多执行一定数量的作业等），将系统中的资源分配给各个正在运行的应用程序。需要注意的是，该调度器是一个“纯调度器”，它不再从事任何与具体应用程序相关的工作，比如不负责监控或者跟踪应用的执行状态等，也不负责重新启动因应用执 行失败或者硬件故障而产生的失败任务，这些均交由应用程序相关的ApplicationMaster完成。调度器仅根据各个应用程序的资源需求进行资源分 配，而资源分配单位用一个抽象概念“资源容器”（Resource Container，简称Container）表示，Container是一个动态资源分配单位，它将内存、 CPU、磁盘、网络等资源封装在一起，从而限定每个任务使用的资源量。此外，该调度器是一个可插拔的组件，用户可根据自己的需要设计新的调度器，YARN 提供了多种直接可用的调度器，比如Fair Scheduler和Capacity Scheduler等。</p>\n<p>（2）:应用程序管理器</p>\n<p>应用程序管理器负责管理整个系统中所有应用程序，包括应用程序提交、与调度器协商资源以启动ApplicationMaster、监控ApplicationMaster运行状态并在失败时重新启动它等。</p>\n<h4 id=\"2-ApplicationMaster-AM\"><a href=\"#2-ApplicationMaster-AM\" class=\"headerlink\" title=\"2.ApplicationMaster(AM)\"></a>2.ApplicationMaster(AM)</h4><p>用户提交的每个应用程序均包含1个AM，主要功能包括：</p>\n<p>与RM调度器协商以获取资源（用Container表示）；</p>\n<p>将得到的任务进一步分配给内部的任务；</p>\n<p>与NM通信以启动/停止任务；</p>\n<p>监控所有任务运行状态，并在任务运行失败时重新为任务申请资源以重启任务。</p>\n<h4 id=\"3-NodeManager-NM\"><a href=\"#3-NodeManager-NM\" class=\"headerlink\" title=\"3.NodeManager(NM)\"></a>3.NodeManager(NM)</h4><p>NM是每个节点上的资源和任务管理器，一方面，它会定时地向RM汇报本节点上的资源使用情况和各个Container的运行状态；另一方面，它接收并处理来自AM的Container启动/停止等各种请求。</p>\n<h4 id=\"4-Container\"><a href=\"#4-Container\" class=\"headerlink\" title=\"4.Container\"></a>4.Container</h4><p>Container 是YARN中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等，当AM向RM申请资源时，RM为AM返回的资源便是用 Container表示的。YARN会为每个任务分配一个Container，且该任务只能使用该Container中描述的资源。<br>目前，YARN仅支持CPU和内存两种资源，且使用了轻量级资源隔离机制Cgroups进行资源隔离。</p>\n<h3 id=\"YARN工作流程\"><a href=\"#YARN工作流程\" class=\"headerlink\" title=\"YARN工作流程\"></a>YARN工作流程</h3><p>当用户向YARN中提交一个应用程序后，YARN将分两个阶段运行该应用程序：<br>第一个阶段是启动ApplicationMaster；<br>第二个阶段是由ApplicationMaster创建应用程序，为它申请资源，并监控它的整个运行过程，直到运行完成。</p>\n<p>YARN的工作流程分为以下几个步骤：</p>\n<ul>\n<li>步骤1：　用户向YARN中提交应用程序，其中包括ApplicationMaster程序、启动ApplicationMaster的命令、用户程序等。</li>\n<li>步骤2：　ResourceManager为该应用程序分配第一个Container，并与对应的NodeManager通信，要求它在这个Container中启动应用程序的ApplicationMaster。</li>\n<li>步骤3：　ApplicationMaster首先向ResourceManager注册，这样用户可以直接通过ResourceManager查看应用程序的运行状态，然后它将为各个任务申请资源，并监控它的运行状态，直到运行结束，即重复步骤4~7。</li>\n<li>步骤4：　ApplicationMaster采用轮询的方式通过RPC协议向ResourceManager申请和领取资源。</li>\n<li>步骤5：　一旦ApplicationMaster申请到资源后，便与对应的NodeManager通信，要求它启动任务。</li>\n<li>步骤6：　NodeManager为任务设置好运行环境（包括环境变量、JAR包、二进制程序等）后，将任务启动命令写到一个脚本中，并通过运行该脚本启动任务。</li>\n<li>步骤7：　各个任务通过某个RPC协议向ApplicationMaster汇报自己的状态和进度，以让ApplicationMaster随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务。在应用程序运行过程中，用户可随时通过RPC向ApplicationMaster查询应用程序的当前运行状态。</li>\n<li>步骤8：　应用程序运行完成后，ApplicationMaster向ResourceManager注销并关闭自己。</li>\n</ul>\n<h3 id=\"Hadoop-Writing-YARN-Applications\"><a href=\"#Hadoop-Writing-YARN-Applications\" class=\"headerlink\" title=\"Hadoop: Writing YARN Applications\"></a>Hadoop: Writing YARN Applications</h3><p>see <a href=\"http://hadoop.apache.org/docs/r3.0.0-alpha2/hadoop-yarn/hadoop-yarn-site/WritingYarnApplications.html\" target=\"_blank\" rel=\"external\">http://hadoop.apache.org/docs/r3.0.0-alpha2/hadoop-yarn/hadoop-yarn-site/WritingYarnApplications.html</a></p>\n<h4 id=\"1-文件格式化与启动namenode-amp-DataNode\"><a href=\"#1-文件格式化与启动namenode-amp-DataNode\" class=\"headerlink\" title=\"1. 文件格式化与启动namenode&amp;DataNode\"></a>1. 文件格式化与启动namenode&amp;DataNode</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ bin/hdfs namenode -format</div><div class=\"line\"></div><div class=\"line\">$ sbin/start-dfs.sh</div></pre></td></tr></table></figure>\n<h4 id=\"2-启动RM-amp-NM\"><a href=\"#2-启动RM-amp-NM\" class=\"headerlink\" title=\"2. 启动RM&amp;NM\"></a>2. 启动RM&amp;NM</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ sbin/start-yarn.sh</div><div class=\"line\"></div><div class=\"line\">ResourceManager - http://localhost:8088/</div></pre></td></tr></table></figure>\n<h4 id=\"3-例子：\"><a href=\"#3-例子：\" class=\"headerlink\" title=\"3. 例子：\"></a>3. 例子：</h4><p>包含了实现一个application的三个要求:</p>\n<ul>\n<li>客户端和RM （Client.Java）<ul>\n<li>客户端提交application</li>\n</ul>\n</li>\n<li>AM和RM （ApplicationMaster.java）<ul>\n<li>注册AM，申请分配container</li>\n</ul>\n</li>\n<li>AM和NM （ApplicationMaster.java）<ul>\n<li>启动container</li>\n</ul>\n</li>\n</ul>\n<p>执行命令：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">hadoop jar hadoop-yarn-applications-distributedshell-3.0.0-alpha2.jar org.apache.hadoop.yarn.applications.distributedshell.Client -jar hadoop-yarn-applications-distributedshell-3.0.0-alpha2.jar -shell_command &apos;/bin/date&apos;</div></pre></td></tr></table></figure></p>\n<p>启动10个container，每个都执行<code>date</code>命令<br>执行代码流程:</p>\n<ol>\n<li>客户端通过org.apache.hadoop.yarn.applications.distributedshell.Client提交application到RM，需提供ApplicationSubmissionContext</li>\n<li>org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster提交containers请求，执行用户提交的命令ContainerLaunchContext.commands</li>\n</ol>\n<p>客户端(Client.java):</p>\n<ol>\n<li>YarnClient.getNewApplication</li>\n<li>填充ApplicationSubmissionContext,ContainerLaunchContext（启动AM的Container）​</li>\n<li>YarnClient.submitApplication​</li>\n<li>每隔一段时间调用YarnClient.getApplicationReport获得Application Status</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div></pre></td><td class=\"code\"><pre><div class=\"line\">// 创建AM的上下文信息  </div><div class=\"line\">ContainerLaunchContext amContainer = Records.newRecord(ContainerLaunchContext.class);  </div><div class=\"line\">// 设置本地资源，AppMaster.jar包，log4j.properties  </div><div class=\"line\">amContainer.setLocalResources(localResources);  </div><div class=\"line\">// 环境变量,shell脚本在hdfs的地址, CLASSPATH  </div><div class=\"line\">amContainer.setEnvironment(env);  </div><div class=\"line\">// 设置启动AM的命令和参数  </div><div class=\"line\">Vector&lt;CharSequence&gt; vargs = new Vector&lt;CharSequence&gt;(30);  </div><div class=\"line\">vargs.add(&quot;$&#123;JAVA_HOME&#125;&quot; + &quot;/bin/java&quot;);  </div><div class=\"line\">vargs.add(&quot;-Xmx&quot; + amMemory + &quot;m&quot;);  </div><div class=\"line\">// AM主类  </div><div class=\"line\">vargs.add(&quot;org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster?&quot;);  </div><div class=\"line\">vargs.add(&quot;--container_memory &quot; + String.valueOf(containerMemory));  </div><div class=\"line\">vargs.add(&quot;--num_containers &quot; + String.valueOf(numContainers));  </div><div class=\"line\">vargs.add(&quot;--priority &quot; + String.valueOf(shellCmdPriority));  </div><div class=\"line\">if (!shellCommand.isEmpty()) &#123;  </div><div class=\"line\">vargs.add(&quot;--shell_command &quot; + shellCommand + &quot;&quot;);  </div><div class=\"line\">&#125;  </div><div class=\"line\">if (!shellArgs.isEmpty()) &#123;  </div><div class=\"line\">vargs.add(&quot;--shell_args &quot; + shellArgs + &quot;&quot;);  </div><div class=\"line\">&#125;  </div><div class=\"line\">for (Map.Entry&lt;String, String&gt; entry : shellEnv.entrySet()) &#123;  </div><div class=\"line\">vargs.add(&quot;--shell_env &quot; + entry.getKey() + &quot;=&quot; + entry.getValue());  </div><div class=\"line\">&#125;  </div><div class=\"line\">vargs.add(&quot;1&gt;&quot; + ApplicationConstants.LOG_DIR_EXPANSION_VAR + &quot;/AppMaster.stdout&quot;);  </div><div class=\"line\">vargs.add(&quot;2&gt;&quot; + ApplicationConstants.LOG_DIR_EXPANSION_VAR + &quot;/AppMaster.stderr&quot;);  </div><div class=\"line\"></div><div class=\"line\">amContainer.setCommands(commands);  </div><div class=\"line\">// 设置Resource需求，目前只设置memory  </div><div class=\"line\">capability.setMemory(amMemory);  </div><div class=\"line\">amContainer.setResource(capability);  </div><div class=\"line\">appContext.setAMContainerSpec(amContainer);  </div><div class=\"line\">// 提交application到RM  </div><div class=\"line\">super.submitApplication(appContext);</div></pre></td></tr></table></figure>\n<p>ApplicationMaster(ApplicationMaster.java​)</p>\n<ol>\n<li>AMRMClient.registerApplicationMaster​​</li>\n<li>提供ContainerRequest到AMRMClient.addContainerRequest​</li>\n<li>通过AMRMClient.allocate获得container</li>\n<li>container放入新建的LaunchContainerRunnable线程内执行</li>\n<li>创建ContainerLaunchContext​，设置localResource，shellcommand, shellArgs等​​container启动信息</li>\n<li>ContainerManager.startContainer(startReq)​​</li>\n<li>下次RPC call后得到的Response信息，AMResponse.getCompletedContainersStatuses​​</li>\n<li>AMRMClient.unregisterApplicationMaster​​</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div></pre></td><td class=\"code\"><pre><div class=\"line\">// 新建AMRMClient，2.1beta版本实现了异步AMRMClient，这里还是同步的方式  </div><div class=\"line\">resourceManager = new AMRMClientImpl(appAttemptID);  </div><div class=\"line\">resourceManager.init(conf);  </div><div class=\"line\">resourceManager.start();  </div><div class=\"line\">// 向RM注册自己  </div><div class=\"line\">RegisterApplicationMasterResponse response = resourceManager  </div><div class=\"line\">  .registerApplicationMaster(appMasterHostname, appMasterRpcPort,  </div><div class=\"line\">      appMasterTrackingUrl);  </div><div class=\"line\">while (numCompletedContainers.get() &lt; numTotalContainers &amp;&amp; !appDone) &#123;  </div><div class=\"line\">// 封装Container请求，设置Resource需求，这边只设置了memory  </div><div class=\"line\">ContainerRequest containerAsk = setupContainerAskForRM(askCount);  </div><div class=\"line\">resourceManager.addContainerRequest(containerAsk);  </div><div class=\"line\"></div><div class=\"line\">// Send the request to RM  </div><div class=\"line\">LOG.info(&quot;Asking RM for containers&quot; + &quot;, askCount=&quot; + askCount);  </div><div class=\"line\">AMResponse amResp = sendContainerAskToRM();  </div><div class=\"line\"></div><div class=\"line\">// Retrieve list of allocated containers from the response  </div><div class=\"line\">List&lt;Container&gt; allocatedContainers = amResp.getAllocatedContainers();  </div><div class=\"line\">for (Container allocatedContainer : allocatedContainers) &#123;  </div><div class=\"line\">    //新建一个线程来提交container启动请求，这样主线程就不会被block住了  </div><div class=\"line\">    LaunchContainerRunnable runnableLaunchContainer = new LaunchContainerRunnable(  </div><div class=\"line\">      allocatedContainer);  </div><div class=\"line\">    Thread launchThread = new Thread(runnableLaunchContainer);  </div><div class=\"line\">    launchThreads.add(launchThread);  </div><div class=\"line\">    launchThread.start();  </div><div class=\"line\">&#125;  </div><div class=\"line\">List&lt;ContainerStatus&gt; completedContainers = amResp.getCompletedContainersStatuses();  </div><div class=\"line\">&#125;  </div><div class=\"line\">// 向RM注销自己  </div><div class=\"line\">resourceManager.unregisterApplicationMaster(appStatus, appMessage, null);</div></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"YARN基本架构\"><a href=\"#YARN基本架构\" class=\"headerlink\" title=\"YARN基本架构\"></a>YARN基本架构</h3><p>YARN是Hadoop 2.0中的资源管理系统，它的基本设计思想是将MRv1中的JobTracker拆分成了两个独立的服务：</p>\n<ul>\n<li>一个全局的资源管理器ResourceManager</li>\n<li><p>每个应用程序特有的ApplicationMaster。</p>\n<p>其中ResourceManager负责整个系统的资源管理和分配，而ApplicationMaster负责单个应用程序的管理。</p>\n</li>\n</ul>\n<p>YARN 总体上仍然是Master/Slave结构，在整个资源管理框架中，ResourceManager为Master，NodeManager为 Slave，ResourceManager负责对各个NodeManager上的资源进行统一管理和调度。当用户提交一个应用程序时，需要提供一个用以 跟踪和管理这个程序的ApplicationMaster，它负责向ResourceManager申请资源，并要求NodeManger启动可以占用一 定资源的任务。由于不同的ApplicationMaster被分布到不同的节点上，因此它们之间不会相互影响。<br><img src=\"http://hadoop.apache.org/docs/r3.0.0-alpha2/hadoop-yarn/hadoop-yarn-site/yarn_architecture.gif\" alt=\"yarn_architecture\"></p>\n<h4 id=\"1-ResourceManager-RM\"><a href=\"#1-ResourceManager-RM\" class=\"headerlink\" title=\"1.ResourceManager(RM)\"></a>1.ResourceManager(RM)</h4><p>RM是一个全局的资源管理器，负责整个系统的资源管理和分配。它主要由两个组件构成：调度器（Scheduler）和应用程序管理器（Applications Manager，AM）。</p>\n<p>(1)：调度器</p>\n<p>调度器根据容量、队列等限制条件（如每个队列分配一定的资源，最多执行一定数量的作业等），将系统中的资源分配给各个正在运行的应用程序。需要注意的是，该调度器是一个“纯调度器”，它不再从事任何与具体应用程序相关的工作，比如不负责监控或者跟踪应用的执行状态等，也不负责重新启动因应用执 行失败或者硬件故障而产生的失败任务，这些均交由应用程序相关的ApplicationMaster完成。调度器仅根据各个应用程序的资源需求进行资源分 配，而资源分配单位用一个抽象概念“资源容器”（Resource Container，简称Container）表示，Container是一个动态资源分配单位，它将内存、 CPU、磁盘、网络等资源封装在一起，从而限定每个任务使用的资源量。此外，该调度器是一个可插拔的组件，用户可根据自己的需要设计新的调度器，YARN 提供了多种直接可用的调度器，比如Fair Scheduler和Capacity Scheduler等。</p>\n<p>（2）:应用程序管理器</p>\n<p>应用程序管理器负责管理整个系统中所有应用程序，包括应用程序提交、与调度器协商资源以启动ApplicationMaster、监控ApplicationMaster运行状态并在失败时重新启动它等。</p>\n<h4 id=\"2-ApplicationMaster-AM\"><a href=\"#2-ApplicationMaster-AM\" class=\"headerlink\" title=\"2.ApplicationMaster(AM)\"></a>2.ApplicationMaster(AM)</h4><p>用户提交的每个应用程序均包含1个AM，主要功能包括：</p>\n<p>与RM调度器协商以获取资源（用Container表示）；</p>\n<p>将得到的任务进一步分配给内部的任务；</p>\n<p>与NM通信以启动/停止任务；</p>\n<p>监控所有任务运行状态，并在任务运行失败时重新为任务申请资源以重启任务。</p>\n<h4 id=\"3-NodeManager-NM\"><a href=\"#3-NodeManager-NM\" class=\"headerlink\" title=\"3.NodeManager(NM)\"></a>3.NodeManager(NM)</h4><p>NM是每个节点上的资源和任务管理器，一方面，它会定时地向RM汇报本节点上的资源使用情况和各个Container的运行状态；另一方面，它接收并处理来自AM的Container启动/停止等各种请求。</p>\n<h4 id=\"4-Container\"><a href=\"#4-Container\" class=\"headerlink\" title=\"4.Container\"></a>4.Container</h4><p>Container 是YARN中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等，当AM向RM申请资源时，RM为AM返回的资源便是用 Container表示的。YARN会为每个任务分配一个Container，且该任务只能使用该Container中描述的资源。<br>目前，YARN仅支持CPU和内存两种资源，且使用了轻量级资源隔离机制Cgroups进行资源隔离。</p>\n<h3 id=\"YARN工作流程\"><a href=\"#YARN工作流程\" class=\"headerlink\" title=\"YARN工作流程\"></a>YARN工作流程</h3><p>当用户向YARN中提交一个应用程序后，YARN将分两个阶段运行该应用程序：<br>第一个阶段是启动ApplicationMaster；<br>第二个阶段是由ApplicationMaster创建应用程序，为它申请资源，并监控它的整个运行过程，直到运行完成。</p>\n<p>YARN的工作流程分为以下几个步骤：</p>\n<ul>\n<li>步骤1：　用户向YARN中提交应用程序，其中包括ApplicationMaster程序、启动ApplicationMaster的命令、用户程序等。</li>\n<li>步骤2：　ResourceManager为该应用程序分配第一个Container，并与对应的NodeManager通信，要求它在这个Container中启动应用程序的ApplicationMaster。</li>\n<li>步骤3：　ApplicationMaster首先向ResourceManager注册，这样用户可以直接通过ResourceManager查看应用程序的运行状态，然后它将为各个任务申请资源，并监控它的运行状态，直到运行结束，即重复步骤4~7。</li>\n<li>步骤4：　ApplicationMaster采用轮询的方式通过RPC协议向ResourceManager申请和领取资源。</li>\n<li>步骤5：　一旦ApplicationMaster申请到资源后，便与对应的NodeManager通信，要求它启动任务。</li>\n<li>步骤6：　NodeManager为任务设置好运行环境（包括环境变量、JAR包、二进制程序等）后，将任务启动命令写到一个脚本中，并通过运行该脚本启动任务。</li>\n<li>步骤7：　各个任务通过某个RPC协议向ApplicationMaster汇报自己的状态和进度，以让ApplicationMaster随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务。在应用程序运行过程中，用户可随时通过RPC向ApplicationMaster查询应用程序的当前运行状态。</li>\n<li>步骤8：　应用程序运行完成后，ApplicationMaster向ResourceManager注销并关闭自己。</li>\n</ul>\n<h3 id=\"Hadoop-Writing-YARN-Applications\"><a href=\"#Hadoop-Writing-YARN-Applications\" class=\"headerlink\" title=\"Hadoop: Writing YARN Applications\"></a>Hadoop: Writing YARN Applications</h3><p>see <a href=\"http://hadoop.apache.org/docs/r3.0.0-alpha2/hadoop-yarn/hadoop-yarn-site/WritingYarnApplications.html\" target=\"_blank\" rel=\"external\">http://hadoop.apache.org/docs/r3.0.0-alpha2/hadoop-yarn/hadoop-yarn-site/WritingYarnApplications.html</a></p>\n<h4 id=\"1-文件格式化与启动namenode-amp-DataNode\"><a href=\"#1-文件格式化与启动namenode-amp-DataNode\" class=\"headerlink\" title=\"1. 文件格式化与启动namenode&amp;DataNode\"></a>1. 文件格式化与启动namenode&amp;DataNode</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ bin/hdfs namenode -format</div><div class=\"line\"></div><div class=\"line\">$ sbin/start-dfs.sh</div></pre></td></tr></table></figure>\n<h4 id=\"2-启动RM-amp-NM\"><a href=\"#2-启动RM-amp-NM\" class=\"headerlink\" title=\"2. 启动RM&amp;NM\"></a>2. 启动RM&amp;NM</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ sbin/start-yarn.sh</div><div class=\"line\"></div><div class=\"line\">ResourceManager - http://localhost:8088/</div></pre></td></tr></table></figure>\n<h4 id=\"3-例子：\"><a href=\"#3-例子：\" class=\"headerlink\" title=\"3. 例子：\"></a>3. 例子：</h4><p>包含了实现一个application的三个要求:</p>\n<ul>\n<li>客户端和RM （Client.Java）<ul>\n<li>客户端提交application</li>\n</ul>\n</li>\n<li>AM和RM （ApplicationMaster.java）<ul>\n<li>注册AM，申请分配container</li>\n</ul>\n</li>\n<li>AM和NM （ApplicationMaster.java）<ul>\n<li>启动container</li>\n</ul>\n</li>\n</ul>\n<p>执行命令：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">hadoop jar hadoop-yarn-applications-distributedshell-3.0.0-alpha2.jar org.apache.hadoop.yarn.applications.distributedshell.Client -jar hadoop-yarn-applications-distributedshell-3.0.0-alpha2.jar -shell_command &apos;/bin/date&apos;</div></pre></td></tr></table></figure></p>\n<p>启动10个container，每个都执行<code>date</code>命令<br>执行代码流程:</p>\n<ol>\n<li>客户端通过org.apache.hadoop.yarn.applications.distributedshell.Client提交application到RM，需提供ApplicationSubmissionContext</li>\n<li>org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster提交containers请求，执行用户提交的命令ContainerLaunchContext.commands</li>\n</ol>\n<p>客户端(Client.java):</p>\n<ol>\n<li>YarnClient.getNewApplication</li>\n<li>填充ApplicationSubmissionContext,ContainerLaunchContext（启动AM的Container）​</li>\n<li>YarnClient.submitApplication​</li>\n<li>每隔一段时间调用YarnClient.getApplicationReport获得Application Status</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div></pre></td><td class=\"code\"><pre><div class=\"line\">// 创建AM的上下文信息  </div><div class=\"line\">ContainerLaunchContext amContainer = Records.newRecord(ContainerLaunchContext.class);  </div><div class=\"line\">// 设置本地资源，AppMaster.jar包，log4j.properties  </div><div class=\"line\">amContainer.setLocalResources(localResources);  </div><div class=\"line\">// 环境变量,shell脚本在hdfs的地址, CLASSPATH  </div><div class=\"line\">amContainer.setEnvironment(env);  </div><div class=\"line\">// 设置启动AM的命令和参数  </div><div class=\"line\">Vector&lt;CharSequence&gt; vargs = new Vector&lt;CharSequence&gt;(30);  </div><div class=\"line\">vargs.add(&quot;$&#123;JAVA_HOME&#125;&quot; + &quot;/bin/java&quot;);  </div><div class=\"line\">vargs.add(&quot;-Xmx&quot; + amMemory + &quot;m&quot;);  </div><div class=\"line\">// AM主类  </div><div class=\"line\">vargs.add(&quot;org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster?&quot;);  </div><div class=\"line\">vargs.add(&quot;--container_memory &quot; + String.valueOf(containerMemory));  </div><div class=\"line\">vargs.add(&quot;--num_containers &quot; + String.valueOf(numContainers));  </div><div class=\"line\">vargs.add(&quot;--priority &quot; + String.valueOf(shellCmdPriority));  </div><div class=\"line\">if (!shellCommand.isEmpty()) &#123;  </div><div class=\"line\">vargs.add(&quot;--shell_command &quot; + shellCommand + &quot;&quot;);  </div><div class=\"line\">&#125;  </div><div class=\"line\">if (!shellArgs.isEmpty()) &#123;  </div><div class=\"line\">vargs.add(&quot;--shell_args &quot; + shellArgs + &quot;&quot;);  </div><div class=\"line\">&#125;  </div><div class=\"line\">for (Map.Entry&lt;String, String&gt; entry : shellEnv.entrySet()) &#123;  </div><div class=\"line\">vargs.add(&quot;--shell_env &quot; + entry.getKey() + &quot;=&quot; + entry.getValue());  </div><div class=\"line\">&#125;  </div><div class=\"line\">vargs.add(&quot;1&gt;&quot; + ApplicationConstants.LOG_DIR_EXPANSION_VAR + &quot;/AppMaster.stdout&quot;);  </div><div class=\"line\">vargs.add(&quot;2&gt;&quot; + ApplicationConstants.LOG_DIR_EXPANSION_VAR + &quot;/AppMaster.stderr&quot;);  </div><div class=\"line\"></div><div class=\"line\">amContainer.setCommands(commands);  </div><div class=\"line\">// 设置Resource需求，目前只设置memory  </div><div class=\"line\">capability.setMemory(amMemory);  </div><div class=\"line\">amContainer.setResource(capability);  </div><div class=\"line\">appContext.setAMContainerSpec(amContainer);  </div><div class=\"line\">// 提交application到RM  </div><div class=\"line\">super.submitApplication(appContext);</div></pre></td></tr></table></figure>\n<p>ApplicationMaster(ApplicationMaster.java​)</p>\n<ol>\n<li>AMRMClient.registerApplicationMaster​​</li>\n<li>提供ContainerRequest到AMRMClient.addContainerRequest​</li>\n<li>通过AMRMClient.allocate获得container</li>\n<li>container放入新建的LaunchContainerRunnable线程内执行</li>\n<li>创建ContainerLaunchContext​，设置localResource，shellcommand, shellArgs等​​container启动信息</li>\n<li>ContainerManager.startContainer(startReq)​​</li>\n<li>下次RPC call后得到的Response信息，AMResponse.getCompletedContainersStatuses​​</li>\n<li>AMRMClient.unregisterApplicationMaster​​</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div></pre></td><td class=\"code\"><pre><div class=\"line\">// 新建AMRMClient，2.1beta版本实现了异步AMRMClient，这里还是同步的方式  </div><div class=\"line\">resourceManager = new AMRMClientImpl(appAttemptID);  </div><div class=\"line\">resourceManager.init(conf);  </div><div class=\"line\">resourceManager.start();  </div><div class=\"line\">// 向RM注册自己  </div><div class=\"line\">RegisterApplicationMasterResponse response = resourceManager  </div><div class=\"line\">  .registerApplicationMaster(appMasterHostname, appMasterRpcPort,  </div><div class=\"line\">      appMasterTrackingUrl);  </div><div class=\"line\">while (numCompletedContainers.get() &lt; numTotalContainers &amp;&amp; !appDone) &#123;  </div><div class=\"line\">// 封装Container请求，设置Resource需求，这边只设置了memory  </div><div class=\"line\">ContainerRequest containerAsk = setupContainerAskForRM(askCount);  </div><div class=\"line\">resourceManager.addContainerRequest(containerAsk);  </div><div class=\"line\"></div><div class=\"line\">// Send the request to RM  </div><div class=\"line\">LOG.info(&quot;Asking RM for containers&quot; + &quot;, askCount=&quot; + askCount);  </div><div class=\"line\">AMResponse amResp = sendContainerAskToRM();  </div><div class=\"line\"></div><div class=\"line\">// Retrieve list of allocated containers from the response  </div><div class=\"line\">List&lt;Container&gt; allocatedContainers = amResp.getAllocatedContainers();  </div><div class=\"line\">for (Container allocatedContainer : allocatedContainers) &#123;  </div><div class=\"line\">    //新建一个线程来提交container启动请求，这样主线程就不会被block住了  </div><div class=\"line\">    LaunchContainerRunnable runnableLaunchContainer = new LaunchContainerRunnable(  </div><div class=\"line\">      allocatedContainer);  </div><div class=\"line\">    Thread launchThread = new Thread(runnableLaunchContainer);  </div><div class=\"line\">    launchThreads.add(launchThread);  </div><div class=\"line\">    launchThread.start();  </div><div class=\"line\">&#125;  </div><div class=\"line\">List&lt;ContainerStatus&gt; completedContainers = amResp.getCompletedContainersStatuses();  </div><div class=\"line\">&#125;  </div><div class=\"line\">// 向RM注销自己  </div><div class=\"line\">resourceManager.unregisterApplicationMaster(appStatus, appMessage, null);</div></pre></td></tr></table></figure>\n"},{"title":"分布式跟踪系统","_content":"\n### Architecture Overview\n\n![zipkin](http://zipkin.io/public/img/web-screenshot.png)\n\nTracers live in your applications and record timing and metadata about operations that took place. They often instrument libraries, so that their use is transparent to users. For example, an instrumented web server records when it received a request and when it sent a response. The trace data collected is called a Span.\n\nInstrumentation is written to be safe in production and have little overhead. For this reason, they only propagate IDs in-band, to tell the receiver there’s a trace in progress. Completed spans are reported to Zipkin out-of-band, similar to how applications report metrics asynchronously.\n\nFor example, when an operation is being traced and it needs to make an outgoing http request, a few headers are added to propagate IDs. Headers are not used to send details such as the operation name.\n\nThe component in an instrumented app that sends data to Zipkin is called a Reporter. Reporters send trace data via one of several transports to Zipkin collectors, which persist trace data to storage. Later, storage is queried by the API to provide data to the UI.\n\nHere’s a diagram describing this flow:\n\n![](http://zipkin.io/public/img/architecture-1.png)\n\n### Zipkin architecture\n\nTo see if an instrumentation library already exists for your platform, see the list of existing instrumentations.\n\n### Example flow\nAs mentioned in the overview, identifiers are sent in-band and details are sent out-of-band to Zipkin. In both cases, trace instrumentation is responsible for creating valid traces and rendering them properly. For example, a tracer ensures parity between the data it sends in-band (downstream) and out-of-band (async to Zipkin).\n\nHere’s an example sequence of http tracing where user code calls the resource /foo. This results in a single span, sent asynchronously to Zipkin after user code receives the http response.\n\n┌─────────────┐ ┌───────────────────────┐  ┌─────────────┐  ┌──────────────────┐\n│ User Code   │ │ Trace Instrumentation │  │ Http Client │  │ Zipkin Collector │\n└─────────────┘ └───────────────────────┘  └─────────────┘  └──────────────────┘\n       │                 │                         │                 │\n           ┌─────────┐\n       │ ──┤GET /foo ├─▶ │ ────┐                   │                 │\n           └─────────┘         │ record tags\n       │                 │ ◀───┘                   │                 │\n                           ────┐\n       │                 │     │ add trace headers │                 │\n                           ◀───┘\n       │                 │ ────┐                   │                 │\n                               │ record timestamp\n       │                 │ ◀───┘                   │                 │\n                             ┌─────────────────┐\n       │                 │ ──┤GET /foo         ├─▶ │                 │\n                             │X-B3-TraceId: aa │     ────┐\n       │                 │   │X-B3-SpanId: 6b  │   │     │           │\n                             └─────────────────┘         │ invoke\n       │                 │                         │     │ request   │\n                                                         │\n       │                 │                         │     │           │\n                                 ┌────────┐          ◀───┘\n       │                 │ ◀─────┤200 OK  ├─────── │                 │\n                           ────┐ └────────┘\n       │                 │     │ record duration   │                 │\n            ┌────────┐     ◀───┘\n       │ ◀──┤200 OK  ├── │                         │                 │\n            └────────┘       ┌────────────────────────────────┐\n       │                 │ ──┤ asynchronously report span     ├────▶ │\n                             │                                │\n                             │{                               │\n                             │  \"traceId\": \"aa\",              │\n                             │  \"id\": \"6b\",                   │\n                             │  \"name\": \"get\",                │\n                             │  \"timestamp\": 1483945573944000,│\n                             │  \"duration\": 386000,           │\n                             │  \"annotations\": [              │\n                             │--snip--                        │\n                             └────────────────────────────────┘\nTrace instrumentation report spans asynchronously to prevent delays or failures relating to the tracing system from delaying or breaking user code.\n\n### Transport\nSpans sent by the instrumented library must be transported from the services being traced to Zipkin collectors. There are three primary transports: HTTP, Kafka and Scribe. See Span Receivers for more information.\n\nThere are 4 components that make up Zipkin:\n\n - collector\n - storage\n - search\n - web UI\n\n### Zipkin Collector\nOnce the trace data arrives at the Zipkin collector daemon, it is validated, stored, and indexed for lookups by the Zipkin collector.\n\n### Storage\nZipkin was initially built to store data on Cassandra since Cassandra is scalable, has a flexible schema, and is heavily used within Twitter. However, we made this component pluggable. In addition to Cassandra, we natively support ElasticSearch and MySQL. Other back-ends might be offered as third party extensions.\n\n### Zipkin Query Service\nOnce the data is stored and indexed, we need a way to extract it. The query daemon provides a simple JSON API for finding and retrieving traces. The primary consumer of this API is the Web UI.\n\n### Web UI\nWe created a GUI that presents a nice interface for viewing traces. The web UI provides a method for viewing traces based on service, time, and annotations. Note: there is no built-in authentication in the UI!\n\n### 例子\n\n```\n<dependency>\n\t\t\t<groupId>org.springframework.cloud</groupId>\n\t\t\t<artifactId>spring-cloud-starter-sleuth</artifactId>\n\t\t\t<version>1.1.2.RELEASE</version>\n\t\t</dependency>\n\t\t<!-- https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-sleuth-zipkin -->\n\t\t<dependency>\n\t\t\t<groupId>org.springframework.cloud</groupId>\n\t\t\t<artifactId>spring-cloud-sleuth-zipkin</artifactId>\n\t\t\t<version>1.1.2.RELEASE</version>\n\t\t</dependency>\n```\n\n属性文件：\n```\nspring.application.name=ServiceRegistryUsingConsulAndDistributedTrace\nlogging.level.org.springframework.web.servlet.DispatcherServlet=INFO\nspring.zipkin.baseUrl=http://localhost:9411/\nspring.sleuth.sampler.percentage=1.0\nsample.zipkin.enabled=true\n```\n\n```\n//Use this for debugging (or if there is no Zipkin server running on port 9411)\n  @Bean\n  @ConditionalOnProperty(value = \"sample.zipkin.enabled\", havingValue = \"false\")\n  public ZipkinSpanReporter spanCollector() {\n      return new ZipkinSpanReporter() {\n          @Override\n          public void report(zipkin.Span span) {\n//              log.info(String.format(\"Reporting span [%s]\", span));\n          }\n      };\n  }\n```\n","source":"_posts/zipkin.md","raw":"---\ntitle: 分布式跟踪系统\n---\n\n### Architecture Overview\n\n![zipkin](http://zipkin.io/public/img/web-screenshot.png)\n\nTracers live in your applications and record timing and metadata about operations that took place. They often instrument libraries, so that their use is transparent to users. For example, an instrumented web server records when it received a request and when it sent a response. The trace data collected is called a Span.\n\nInstrumentation is written to be safe in production and have little overhead. For this reason, they only propagate IDs in-band, to tell the receiver there’s a trace in progress. Completed spans are reported to Zipkin out-of-band, similar to how applications report metrics asynchronously.\n\nFor example, when an operation is being traced and it needs to make an outgoing http request, a few headers are added to propagate IDs. Headers are not used to send details such as the operation name.\n\nThe component in an instrumented app that sends data to Zipkin is called a Reporter. Reporters send trace data via one of several transports to Zipkin collectors, which persist trace data to storage. Later, storage is queried by the API to provide data to the UI.\n\nHere’s a diagram describing this flow:\n\n![](http://zipkin.io/public/img/architecture-1.png)\n\n### Zipkin architecture\n\nTo see if an instrumentation library already exists for your platform, see the list of existing instrumentations.\n\n### Example flow\nAs mentioned in the overview, identifiers are sent in-band and details are sent out-of-band to Zipkin. In both cases, trace instrumentation is responsible for creating valid traces and rendering them properly. For example, a tracer ensures parity between the data it sends in-band (downstream) and out-of-band (async to Zipkin).\n\nHere’s an example sequence of http tracing where user code calls the resource /foo. This results in a single span, sent asynchronously to Zipkin after user code receives the http response.\n\n┌─────────────┐ ┌───────────────────────┐  ┌─────────────┐  ┌──────────────────┐\n│ User Code   │ │ Trace Instrumentation │  │ Http Client │  │ Zipkin Collector │\n└─────────────┘ └───────────────────────┘  └─────────────┘  └──────────────────┘\n       │                 │                         │                 │\n           ┌─────────┐\n       │ ──┤GET /foo ├─▶ │ ────┐                   │                 │\n           └─────────┘         │ record tags\n       │                 │ ◀───┘                   │                 │\n                           ────┐\n       │                 │     │ add trace headers │                 │\n                           ◀───┘\n       │                 │ ────┐                   │                 │\n                               │ record timestamp\n       │                 │ ◀───┘                   │                 │\n                             ┌─────────────────┐\n       │                 │ ──┤GET /foo         ├─▶ │                 │\n                             │X-B3-TraceId: aa │     ────┐\n       │                 │   │X-B3-SpanId: 6b  │   │     │           │\n                             └─────────────────┘         │ invoke\n       │                 │                         │     │ request   │\n                                                         │\n       │                 │                         │     │           │\n                                 ┌────────┐          ◀───┘\n       │                 │ ◀─────┤200 OK  ├─────── │                 │\n                           ────┐ └────────┘\n       │                 │     │ record duration   │                 │\n            ┌────────┐     ◀───┘\n       │ ◀──┤200 OK  ├── │                         │                 │\n            └────────┘       ┌────────────────────────────────┐\n       │                 │ ──┤ asynchronously report span     ├────▶ │\n                             │                                │\n                             │{                               │\n                             │  \"traceId\": \"aa\",              │\n                             │  \"id\": \"6b\",                   │\n                             │  \"name\": \"get\",                │\n                             │  \"timestamp\": 1483945573944000,│\n                             │  \"duration\": 386000,           │\n                             │  \"annotations\": [              │\n                             │--snip--                        │\n                             └────────────────────────────────┘\nTrace instrumentation report spans asynchronously to prevent delays or failures relating to the tracing system from delaying or breaking user code.\n\n### Transport\nSpans sent by the instrumented library must be transported from the services being traced to Zipkin collectors. There are three primary transports: HTTP, Kafka and Scribe. See Span Receivers for more information.\n\nThere are 4 components that make up Zipkin:\n\n - collector\n - storage\n - search\n - web UI\n\n### Zipkin Collector\nOnce the trace data arrives at the Zipkin collector daemon, it is validated, stored, and indexed for lookups by the Zipkin collector.\n\n### Storage\nZipkin was initially built to store data on Cassandra since Cassandra is scalable, has a flexible schema, and is heavily used within Twitter. However, we made this component pluggable. In addition to Cassandra, we natively support ElasticSearch and MySQL. Other back-ends might be offered as third party extensions.\n\n### Zipkin Query Service\nOnce the data is stored and indexed, we need a way to extract it. The query daemon provides a simple JSON API for finding and retrieving traces. The primary consumer of this API is the Web UI.\n\n### Web UI\nWe created a GUI that presents a nice interface for viewing traces. The web UI provides a method for viewing traces based on service, time, and annotations. Note: there is no built-in authentication in the UI!\n\n### 例子\n\n```\n<dependency>\n\t\t\t<groupId>org.springframework.cloud</groupId>\n\t\t\t<artifactId>spring-cloud-starter-sleuth</artifactId>\n\t\t\t<version>1.1.2.RELEASE</version>\n\t\t</dependency>\n\t\t<!-- https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-sleuth-zipkin -->\n\t\t<dependency>\n\t\t\t<groupId>org.springframework.cloud</groupId>\n\t\t\t<artifactId>spring-cloud-sleuth-zipkin</artifactId>\n\t\t\t<version>1.1.2.RELEASE</version>\n\t\t</dependency>\n```\n\n属性文件：\n```\nspring.application.name=ServiceRegistryUsingConsulAndDistributedTrace\nlogging.level.org.springframework.web.servlet.DispatcherServlet=INFO\nspring.zipkin.baseUrl=http://localhost:9411/\nspring.sleuth.sampler.percentage=1.0\nsample.zipkin.enabled=true\n```\n\n```\n//Use this for debugging (or if there is no Zipkin server running on port 9411)\n  @Bean\n  @ConditionalOnProperty(value = \"sample.zipkin.enabled\", havingValue = \"false\")\n  public ZipkinSpanReporter spanCollector() {\n      return new ZipkinSpanReporter() {\n          @Override\n          public void report(zipkin.Span span) {\n//              log.info(String.format(\"Reporting span [%s]\", span));\n          }\n      };\n  }\n```\n","slug":"zipkin","published":1,"date":"2017-03-08T14:26:13.000Z","updated":"2017-05-08T13:33:41.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj2g8ok46000odl72pmbwfdsd","content":"<h3 id=\"Architecture-Overview\"><a href=\"#Architecture-Overview\" class=\"headerlink\" title=\"Architecture Overview\"></a>Architecture Overview</h3><p><img src=\"http://zipkin.io/public/img/web-screenshot.png\" alt=\"zipkin\"></p>\n<p>Tracers live in your applications and record timing and metadata about operations that took place. They often instrument libraries, so that their use is transparent to users. For example, an instrumented web server records when it received a request and when it sent a response. The trace data collected is called a Span.</p>\n<p>Instrumentation is written to be safe in production and have little overhead. For this reason, they only propagate IDs in-band, to tell the receiver there’s a trace in progress. Completed spans are reported to Zipkin out-of-band, similar to how applications report metrics asynchronously.</p>\n<p>For example, when an operation is being traced and it needs to make an outgoing http request, a few headers are added to propagate IDs. Headers are not used to send details such as the operation name.</p>\n<p>The component in an instrumented app that sends data to Zipkin is called a Reporter. Reporters send trace data via one of several transports to Zipkin collectors, which persist trace data to storage. Later, storage is queried by the API to provide data to the UI.</p>\n<p>Here’s a diagram describing this flow:</p>\n<p><img src=\"http://zipkin.io/public/img/architecture-1.png\" alt=\"\"></p>\n<h3 id=\"Zipkin-architecture\"><a href=\"#Zipkin-architecture\" class=\"headerlink\" title=\"Zipkin architecture\"></a>Zipkin architecture</h3><p>To see if an instrumentation library already exists for your platform, see the list of existing instrumentations.</p>\n<h3 id=\"Example-flow\"><a href=\"#Example-flow\" class=\"headerlink\" title=\"Example flow\"></a>Example flow</h3><p>As mentioned in the overview, identifiers are sent in-band and details are sent out-of-band to Zipkin. In both cases, trace instrumentation is responsible for creating valid traces and rendering them properly. For example, a tracer ensures parity between the data it sends in-band (downstream) and out-of-band (async to Zipkin).</p>\n<p>Here’s an example sequence of http tracing where user code calls the resource /foo. This results in a single span, sent asynchronously to Zipkin after user code receives the http response.</p>\n<p>┌─────────────┐ ┌───────────────────────┐  ┌─────────────┐  ┌──────────────────┐<br>│ User Code   │ │ Trace Instrumentation │  │ Http Client │  │ Zipkin Collector │<br>└─────────────┘ └───────────────────────┘  └─────────────┘  └──────────────────┘<br>       │                 │                         │                 │<br>           ┌─────────┐<br>       │ ──┤GET /foo ├─▶ │ ────┐                   │                 │<br>           └─────────┘         │ record tags<br>       │                 │ ◀───┘                   │                 │<br>                           ────┐<br>       │                 │     │ add trace headers │                 │<br>                           ◀───┘<br>       │                 │ ────┐                   │                 │<br>                               │ record timestamp<br>       │                 │ ◀───┘                   │                 │<br>                             ┌─────────────────┐<br>       │                 │ ──┤GET /foo         ├─▶ │                 │<br>                             │X-B3-TraceId: aa │     ────┐<br>       │                 │   │X-B3-SpanId: 6b  │   │     │           │<br>                             └─────────────────┘         │ invoke<br>       │                 │                         │     │ request   │<br>                                                         │<br>       │                 │                         │     │           │<br>                                 ┌────────┐          ◀───┘<br>       │                 │ ◀─────┤200 OK  ├─────── │                 │<br>                           ────┐ └────────┘<br>       │                 │     │ record duration   │                 │<br>            ┌────────┐     ◀───┘<br>       │ ◀──┤200 OK  ├── │                         │                 │<br>            └────────┘       ┌────────────────────────────────┐<br>       │                 │ ──┤ asynchronously report span     ├────▶ │<br>                             │                                │<br>                             │{                               │<br>                             │  “traceId”: “aa”,              │<br>                             │  “id”: “6b”,                   │<br>                             │  “name”: “get”,                │<br>                             │  “timestamp”: 1483945573944000,│<br>                             │  “duration”: 386000,           │<br>                             │  “annotations”: [              │<br>                             │–snip–                        │<br>                             └────────────────────────────────┘<br>Trace instrumentation report spans asynchronously to prevent delays or failures relating to the tracing system from delaying or breaking user code.</p>\n<h3 id=\"Transport\"><a href=\"#Transport\" class=\"headerlink\" title=\"Transport\"></a>Transport</h3><p>Spans sent by the instrumented library must be transported from the services being traced to Zipkin collectors. There are three primary transports: HTTP, Kafka and Scribe. See Span Receivers for more information.</p>\n<p>There are 4 components that make up Zipkin:</p>\n<ul>\n<li>collector</li>\n<li>storage</li>\n<li>search</li>\n<li>web UI</li>\n</ul>\n<h3 id=\"Zipkin-Collector\"><a href=\"#Zipkin-Collector\" class=\"headerlink\" title=\"Zipkin Collector\"></a>Zipkin Collector</h3><p>Once the trace data arrives at the Zipkin collector daemon, it is validated, stored, and indexed for lookups by the Zipkin collector.</p>\n<h3 id=\"Storage\"><a href=\"#Storage\" class=\"headerlink\" title=\"Storage\"></a>Storage</h3><p>Zipkin was initially built to store data on Cassandra since Cassandra is scalable, has a flexible schema, and is heavily used within Twitter. However, we made this component pluggable. In addition to Cassandra, we natively support ElasticSearch and MySQL. Other back-ends might be offered as third party extensions.</p>\n<h3 id=\"Zipkin-Query-Service\"><a href=\"#Zipkin-Query-Service\" class=\"headerlink\" title=\"Zipkin Query Service\"></a>Zipkin Query Service</h3><p>Once the data is stored and indexed, we need a way to extract it. The query daemon provides a simple JSON API for finding and retrieving traces. The primary consumer of this API is the Web UI.</p>\n<h3 id=\"Web-UI\"><a href=\"#Web-UI\" class=\"headerlink\" title=\"Web UI\"></a>Web UI</h3><p>We created a GUI that presents a nice interface for viewing traces. The web UI provides a method for viewing traces based on service, time, and annotations. Note: there is no built-in authentication in the UI!</p>\n<h3 id=\"例子\"><a href=\"#例子\" class=\"headerlink\" title=\"例子\"></a>例子</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;dependency&gt;</div><div class=\"line\">\t\t\t&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class=\"line\">\t\t\t&lt;artifactId&gt;spring-cloud-starter-sleuth&lt;/artifactId&gt;</div><div class=\"line\">\t\t\t&lt;version&gt;1.1.2.RELEASE&lt;/version&gt;</div><div class=\"line\">\t\t&lt;/dependency&gt;</div><div class=\"line\">\t\t&lt;!-- https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-sleuth-zipkin --&gt;</div><div class=\"line\">\t\t&lt;dependency&gt;</div><div class=\"line\">\t\t\t&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class=\"line\">\t\t\t&lt;artifactId&gt;spring-cloud-sleuth-zipkin&lt;/artifactId&gt;</div><div class=\"line\">\t\t\t&lt;version&gt;1.1.2.RELEASE&lt;/version&gt;</div><div class=\"line\">\t\t&lt;/dependency&gt;</div></pre></td></tr></table></figure>\n<p>属性文件：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">spring.application.name=ServiceRegistryUsingConsulAndDistributedTrace</div><div class=\"line\">logging.level.org.springframework.web.servlet.DispatcherServlet=INFO</div><div class=\"line\">spring.zipkin.baseUrl=http://localhost:9411/</div><div class=\"line\">spring.sleuth.sampler.percentage=1.0</div><div class=\"line\">sample.zipkin.enabled=true</div></pre></td></tr></table></figure></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">//Use this for debugging (or if there is no Zipkin server running on port 9411)</div><div class=\"line\">  @Bean</div><div class=\"line\">  @ConditionalOnProperty(value = &quot;sample.zipkin.enabled&quot;, havingValue = &quot;false&quot;)</div><div class=\"line\">  public ZipkinSpanReporter spanCollector() &#123;</div><div class=\"line\">      return new ZipkinSpanReporter() &#123;</div><div class=\"line\">          @Override</div><div class=\"line\">          public void report(zipkin.Span span) &#123;</div><div class=\"line\">//              log.info(String.format(&quot;Reporting span [%s]&quot;, span));</div><div class=\"line\">          &#125;</div><div class=\"line\">      &#125;;</div><div class=\"line\">  &#125;</div></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"Architecture-Overview\"><a href=\"#Architecture-Overview\" class=\"headerlink\" title=\"Architecture Overview\"></a>Architecture Overview</h3><p><img src=\"http://zipkin.io/public/img/web-screenshot.png\" alt=\"zipkin\"></p>\n<p>Tracers live in your applications and record timing and metadata about operations that took place. They often instrument libraries, so that their use is transparent to users. For example, an instrumented web server records when it received a request and when it sent a response. The trace data collected is called a Span.</p>\n<p>Instrumentation is written to be safe in production and have little overhead. For this reason, they only propagate IDs in-band, to tell the receiver there’s a trace in progress. Completed spans are reported to Zipkin out-of-band, similar to how applications report metrics asynchronously.</p>\n<p>For example, when an operation is being traced and it needs to make an outgoing http request, a few headers are added to propagate IDs. Headers are not used to send details such as the operation name.</p>\n<p>The component in an instrumented app that sends data to Zipkin is called a Reporter. Reporters send trace data via one of several transports to Zipkin collectors, which persist trace data to storage. Later, storage is queried by the API to provide data to the UI.</p>\n<p>Here’s a diagram describing this flow:</p>\n<p><img src=\"http://zipkin.io/public/img/architecture-1.png\" alt=\"\"></p>\n<h3 id=\"Zipkin-architecture\"><a href=\"#Zipkin-architecture\" class=\"headerlink\" title=\"Zipkin architecture\"></a>Zipkin architecture</h3><p>To see if an instrumentation library already exists for your platform, see the list of existing instrumentations.</p>\n<h3 id=\"Example-flow\"><a href=\"#Example-flow\" class=\"headerlink\" title=\"Example flow\"></a>Example flow</h3><p>As mentioned in the overview, identifiers are sent in-band and details are sent out-of-band to Zipkin. In both cases, trace instrumentation is responsible for creating valid traces and rendering them properly. For example, a tracer ensures parity between the data it sends in-band (downstream) and out-of-band (async to Zipkin).</p>\n<p>Here’s an example sequence of http tracing where user code calls the resource /foo. This results in a single span, sent asynchronously to Zipkin after user code receives the http response.</p>\n<p>┌─────────────┐ ┌───────────────────────┐  ┌─────────────┐  ┌──────────────────┐<br>│ User Code   │ │ Trace Instrumentation │  │ Http Client │  │ Zipkin Collector │<br>└─────────────┘ └───────────────────────┘  └─────────────┘  └──────────────────┘<br>       │                 │                         │                 │<br>           ┌─────────┐<br>       │ ──┤GET /foo ├─▶ │ ────┐                   │                 │<br>           └─────────┘         │ record tags<br>       │                 │ ◀───┘                   │                 │<br>                           ────┐<br>       │                 │     │ add trace headers │                 │<br>                           ◀───┘<br>       │                 │ ────┐                   │                 │<br>                               │ record timestamp<br>       │                 │ ◀───┘                   │                 │<br>                             ┌─────────────────┐<br>       │                 │ ──┤GET /foo         ├─▶ │                 │<br>                             │X-B3-TraceId: aa │     ────┐<br>       │                 │   │X-B3-SpanId: 6b  │   │     │           │<br>                             └─────────────────┘         │ invoke<br>       │                 │                         │     │ request   │<br>                                                         │<br>       │                 │                         │     │           │<br>                                 ┌────────┐          ◀───┘<br>       │                 │ ◀─────┤200 OK  ├─────── │                 │<br>                           ────┐ └────────┘<br>       │                 │     │ record duration   │                 │<br>            ┌────────┐     ◀───┘<br>       │ ◀──┤200 OK  ├── │                         │                 │<br>            └────────┘       ┌────────────────────────────────┐<br>       │                 │ ──┤ asynchronously report span     ├────▶ │<br>                             │                                │<br>                             │{                               │<br>                             │  “traceId”: “aa”,              │<br>                             │  “id”: “6b”,                   │<br>                             │  “name”: “get”,                │<br>                             │  “timestamp”: 1483945573944000,│<br>                             │  “duration”: 386000,           │<br>                             │  “annotations”: [              │<br>                             │–snip–                        │<br>                             └────────────────────────────────┘<br>Trace instrumentation report spans asynchronously to prevent delays or failures relating to the tracing system from delaying or breaking user code.</p>\n<h3 id=\"Transport\"><a href=\"#Transport\" class=\"headerlink\" title=\"Transport\"></a>Transport</h3><p>Spans sent by the instrumented library must be transported from the services being traced to Zipkin collectors. There are three primary transports: HTTP, Kafka and Scribe. See Span Receivers for more information.</p>\n<p>There are 4 components that make up Zipkin:</p>\n<ul>\n<li>collector</li>\n<li>storage</li>\n<li>search</li>\n<li>web UI</li>\n</ul>\n<h3 id=\"Zipkin-Collector\"><a href=\"#Zipkin-Collector\" class=\"headerlink\" title=\"Zipkin Collector\"></a>Zipkin Collector</h3><p>Once the trace data arrives at the Zipkin collector daemon, it is validated, stored, and indexed for lookups by the Zipkin collector.</p>\n<h3 id=\"Storage\"><a href=\"#Storage\" class=\"headerlink\" title=\"Storage\"></a>Storage</h3><p>Zipkin was initially built to store data on Cassandra since Cassandra is scalable, has a flexible schema, and is heavily used within Twitter. However, we made this component pluggable. In addition to Cassandra, we natively support ElasticSearch and MySQL. Other back-ends might be offered as third party extensions.</p>\n<h3 id=\"Zipkin-Query-Service\"><a href=\"#Zipkin-Query-Service\" class=\"headerlink\" title=\"Zipkin Query Service\"></a>Zipkin Query Service</h3><p>Once the data is stored and indexed, we need a way to extract it. The query daemon provides a simple JSON API for finding and retrieving traces. The primary consumer of this API is the Web UI.</p>\n<h3 id=\"Web-UI\"><a href=\"#Web-UI\" class=\"headerlink\" title=\"Web UI\"></a>Web UI</h3><p>We created a GUI that presents a nice interface for viewing traces. The web UI provides a method for viewing traces based on service, time, and annotations. Note: there is no built-in authentication in the UI!</p>\n<h3 id=\"例子\"><a href=\"#例子\" class=\"headerlink\" title=\"例子\"></a>例子</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;dependency&gt;</div><div class=\"line\">\t\t\t&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class=\"line\">\t\t\t&lt;artifactId&gt;spring-cloud-starter-sleuth&lt;/artifactId&gt;</div><div class=\"line\">\t\t\t&lt;version&gt;1.1.2.RELEASE&lt;/version&gt;</div><div class=\"line\">\t\t&lt;/dependency&gt;</div><div class=\"line\">\t\t&lt;!-- https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-sleuth-zipkin --&gt;</div><div class=\"line\">\t\t&lt;dependency&gt;</div><div class=\"line\">\t\t\t&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class=\"line\">\t\t\t&lt;artifactId&gt;spring-cloud-sleuth-zipkin&lt;/artifactId&gt;</div><div class=\"line\">\t\t\t&lt;version&gt;1.1.2.RELEASE&lt;/version&gt;</div><div class=\"line\">\t\t&lt;/dependency&gt;</div></pre></td></tr></table></figure>\n<p>属性文件：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">spring.application.name=ServiceRegistryUsingConsulAndDistributedTrace</div><div class=\"line\">logging.level.org.springframework.web.servlet.DispatcherServlet=INFO</div><div class=\"line\">spring.zipkin.baseUrl=http://localhost:9411/</div><div class=\"line\">spring.sleuth.sampler.percentage=1.0</div><div class=\"line\">sample.zipkin.enabled=true</div></pre></td></tr></table></figure></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">//Use this for debugging (or if there is no Zipkin server running on port 9411)</div><div class=\"line\">  @Bean</div><div class=\"line\">  @ConditionalOnProperty(value = &quot;sample.zipkin.enabled&quot;, havingValue = &quot;false&quot;)</div><div class=\"line\">  public ZipkinSpanReporter spanCollector() &#123;</div><div class=\"line\">      return new ZipkinSpanReporter() &#123;</div><div class=\"line\">          @Override</div><div class=\"line\">          public void report(zipkin.Span span) &#123;</div><div class=\"line\">//              log.info(String.format(&quot;Reporting span [%s]&quot;, span));</div><div class=\"line\">          &#125;</div><div class=\"line\">      &#125;;</div><div class=\"line\">  &#125;</div></pre></td></tr></table></figure>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cj2g8ok3e0000dl72g85xmbzs","category_id":"cj2g8ok3m0004dl72uzerqh8o","_id":"cj2g8ok3w000cdl72bhofnr8o"}],"PostTag":[{"post_id":"cj2g8ok3e0000dl72g85xmbzs","tag_id":"cj2g8ok3p0005dl72erjx0i8w","_id":"cj2g8ok3x000fdl72vwiep267"},{"post_id":"cj2g8ok3e0000dl72g85xmbzs","tag_id":"cj2g8ok3v000adl72mnn99fs2","_id":"cj2g8ok3z000hdl72lj0lemy7"}],"Tag":[{"name":"分布式","_id":"cj2g8ok3p0005dl72erjx0i8w"},{"name":"架构设计","_id":"cj2g8ok3v000adl72mnn99fs2"}]}}